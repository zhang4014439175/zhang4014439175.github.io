<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Java框架-Spring设计思想</title><url>https://zhang4014439175.github.io/post/spring%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/</url><categories><category>Java-Framework</category><category>Spring</category><category>设计模式</category></categories><tags><tag>Java</tag><tag>框架</tag><tag>Spring</tag><tag>设计模式</tag></tags><content type="html"> 一、控制反转(IoC) IoC(Inversion of Control,控制反转) 是Spring 中一个非常非常重要的概念，它不是什么技术，而是一种解耦的设计思想。它的主要目的是借助于“第三方”(Spring 中的 IOC 容器) 实现具有依赖关系的对象之间的解耦(IOC容器管理对象，你只管使用即可)，从而降低代码之间的耦合度。IOC 是一个原则，而不是一个模式，以下模式（但不限于）实现了IoC原则。
Spring IOC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。 IOC 容器负责创建对象，将对象连接在一起，配置这些对象，并从创建中处理这些对象的整个生命周期，直到它们被完全销毁。
在实际项目中一个 Service 类如果有几百甚至上千个类作为它的底层，我们需要实例化这个 Service，你可能要每次都要搞清这个 Service 所有底层类的构造函数，这可能会把人逼疯。如果利用 IOC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。关于Spring IOC 的理解，推荐看这一下知乎的一个回答：[Spring IoC有什么好处呢？ - 知乎 (zhihu.com)]
，非常不错。
控制反转怎么理解呢? 举个例子：&ldquo;对象a 依赖了对象 b，当对象 a 需要使用 对象 b的时候必须自己去创建。但是当系统引入了 IOC 容器后， 对象a 和对象 b 之前就失去了直接的联系。这个时候，当对象 a 需要使用 对象 b的时候， 我们可以指定 IOC 容器去创建一个对象b注入到对象 a 中&rdquo;。 对象 a 获得依赖对象 b 的过程,由主动行为变为了被动行为，控制权反转，这就是控制反转名字的由来。
1、什么是依赖倒置 **什么是依赖倒置原则？**假设我们设计一辆汽车：先设计轮子，然后根据轮子的大小设计底盘，接着根据底盘设计车身，最后根据车身设计好整个汽车。这里就出现了一个“依赖”关系：汽车依赖车身，车身依赖底盘，底盘依赖轮子。
这样的设计看起来没问题，但是可维护性却很低。假设设计完工之后，上司却突然说根据市场需求的变动
，要我们把车子的轮子设计都改大一码。这下我们就蛋疼了：因为我们是根据轮子的尺寸设计的底盘，轮子的尺寸一改，底盘的设计就得修改；同样因为我们是根据底盘设计的车身，那么车身也得改，同理汽车设计也得改——整个设计几乎都得改！
我们现在换一种思路。我们先设计汽车的大概样子，然后根据汽车的样子来设计车身，根据车身来设计底盘，最后根据底盘来设计轮子。这时候，依赖关系就倒置过来了：轮子依赖底盘， 底盘依赖车身， 车身依赖汽车。
这时候，上司再说要改动轮子的设计，我们就只需要改动轮子的设计，而不需要动底盘，车身，汽车的设计了。
这就是依赖倒置原则——把原本的高层建筑依赖底层建筑“倒置”过来，变成底层建筑依赖高层建筑。高层建筑决定需要什么，底层去实现这样的需求，但是高层并不用管底层是怎么实现的。这样就不会出现前面的“牵一发动全身”的情况。
二、依赖注入(DI) DI(Dependecy Inject,依赖注入)是实现控制反转的一种设计模式，依赖注入就是将实例变量传入到一个对象中去。
三、AOP 四、设计模式 1、工厂模式 工厂模式是一种在工程中广泛应用的设计模式，对代码的解耦合起到了很大的作用
工厂模式提供了一种绝佳的创建对象的方法。在工厂模式中，我们并不会直接使用new来创建一个对象，而是使用一个共同的接口类来指定其实现类，这就大大降低了系统的耦合性——我们无需改变每个调用此接口的类，而直接改变实现此接口的类即可完成软件的更新迭代
工厂模式的代码
import java.util.ResourceBundle; /** * 使用此工厂类创建bean实例 */ public class BeanFactory { //加载配置文件 private static ResourceBundle bundle; static { bundle = ResourceBundle.getBundle("instance"); } //根据指定的key,读取配置文件的全路径，创建对象 public static &lt;T>T getInstance(String key,Class&lt;T> clazz){ String className = bundle.getString(key); try { return (T)Class.forName(className).newInstance(); }catch (Exception e){ throw new RuntimeException(); } } } Class.forName(className).newInstance()方法就会返回className对应的类，这样就能够使用了。
工厂模式的思想正好契合SpringIOC的设计思想:某一接口的具体实现类的选择控制权从调用类中移除，转而交给第三方决定，即借由Spring的Bean配置来实现控制，这同样也是工厂模式的思想。 在Spring中有两个最基本的工厂，BeanFactory和ApplicationContext。BeanFactory是Spring框架的基础设施，面向的是Spring本身，也就是用于创建Spring扩展的其他内容，如Spring Security、Spring JDBC等，而ApplicationContext这个工厂是面向开发者的，也就是应用上下文——配置文件等，开发者能够使用这个工厂实现自己的功能。
工厂模式是把创建对象的任务交给工厂，从而来降低类与类之间的耦合。Spring最主要的两个特性就是AOP和IOC，其中IOC就是控制反转，将对象的控制权转移给Spring，并由Spring创建实例和管理各个实例之间的依赖关系，其中，对象的创建就是通过BeanFactory 和 ApplicationContext 完成的。
public interface BeanFactory { Object getBean(String name) throws BeansException; &lt;T> T getBean(String name, @Nullable Class&lt;T> requiredType) throws BeansException; Object getBean(String name, Object... args) throws BeansException; &lt;T> T getBean(Class&lt;T> requiredType) throws BeansException; &lt;T> T getBean(Class&lt;T> requiredType, Object... args) throws BeansException; //省略... } BeanFactory是Spring里面最底层的接口，是IoC的核心，定义了IoC的基本功能，包含了各种Bean的定义、加载、实例化，依赖注入和生命周期管理。BeanFactroy采用的是延迟加载形式来注入Bean的，只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化。这样，我们就不能提前发现一些存在的Spring的配置问题。 2、ApplicationContext接口作为BeanFactory的子类，除了提供BeanFactory所具有的功能外，还扩展了其他更完整功能，对于Bean创建，ApplicationContext在容器启动时，一次性创建了所有的Bean。
public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory,MessageSource, ApplicationEventPublisher, ResourcePatternResolver { @Nullable String getId(); String getApplicationName(); String getDisplayName(); long getStartupDate(); @Nullable ApplicationContext getParent(); AutowireCapableBeanFactory getAutowireCapableBeanFactory() throws IllegalStateException; } 2、单例模式 在Spring中的Bean默认的作用域就是singleton单例的。单例模式的好处在于对一些重量级的对象，省略了重复创建对象花费的时间，减少了系统的开销，第二点是使用单例可以减少new操作的次数，减少了GC线程回收内存的压力。
对于单例bean的创建方式，主要看DefaultSingletonBeanRegistry 的 getSingleton() 方法：
public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry { /** 保存单例Objects的缓存集合ConcurrentHashMap，key：beanName --> value：bean实例 */ private final Map&lt;String, Object> singletonObjects = new ConcurrentHashMap&lt;>(256); public Object getSingleton(String beanName, ObjectFactory&lt;?> singletonFactory) { Assert.notNull(beanName, "Bean name must not be null"); synchronized (this.singletonObjects) { //检查缓存中是否有实例，如果缓存中有实例，直接返回 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) { //省略... try { //通过singletonFactory获取单例 singletonObject = singletonFactory.getObject(); newSingleton = true; } //省略... if (newSingleton) { addSingleton(beanName, singletonObject); } } //返回实例 return singletonObject; } } protected void addSingleton(String beanName, Object singletonObject) { synchronized (this.singletonObjects) { this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); } } } 从源码中可以看出，是通过ConcurrentHashMap的方式，如果在Map中存在则直接返回，如果不存在则创建，并且put进Map集合中，并且整段逻辑是使用同步代码块包住的，所以是线程安全的。
3、策略模式 策略模式，简单来说就是封装好一组策略算法，外部客户端根据不同的条件选择不同的策略算法解决问题。比如在Spring的Resource类，针对不同的资源，Spring定义了不同的Resource类的实现类，以此实现不同的访问方式。我们看一张类图：
简单介绍一下Resource的实现类：
UrlResource：访问网络资源的实现类。 ServletContextResource：访问相对于 ServletContext 路径里的资源的实现类。 ByteArrayResource：访问字节数组资源的实现类。 PathResource：访问文件路径资源的实现类。 ClassPathResource：访问类加载路径里资源的实现类。
@RequestMapping(value = "/resource", method = RequestMethod.GET) public String resource(@RequestParam(name = "type") String type, @RequestParam(name = "arg") String arg) throws Exception { Resource resource; //这里可以优化为通过工厂模式，根据type创建Resource的实现类 if ("classpath".equals(type)) { //classpath下的资源 resource = new ClassPathResource(arg); } else if ("file".equals(type)) { //本地文件系统的资源 resource = new PathResource(arg); } else if ("url".equals(type)) { //网络资源 resource = new UrlResource(arg); } else { return "fail"; } InputStream is = resource.getInputStream(); ByteArrayOutputStream os = new ByteArrayOutputStream(); int i; while ((i = is.read()) != -1) { os.write(i); } String result = new String(os.toByteArray(), StandardCharsets.UTF_8); is.close(); os.close(); return "type:" + type + ",arg:" + arg + "\r\n" + result; } 这就是策略模式的思想，通过外部条件使用不同的算法解决问题。其实很简单，因为每个实现类的getInputStream()方法都不一样，我们看ClassPathResource的源码，是通过类加载器加载资源：
public class ClassPathResource extends AbstractFileResolvingResource { private final String path; @Nullable private ClassLoader classLoader; @Nullable private Class&lt;?> clazz; @Override public InputStream getInputStream() throws IOException { InputStream is; //通过类加载器加载类路径下的资源 if (this.clazz != null) { is = this.clazz.getResourceAsStream(this.path); } else if (this.classLoader != null) { is = this.classLoader.getResourceAsStream(this.path); } else { is = ClassLoader.getSystemResourceAsStream(this.path); } //如果输入流is为null，则报错 if (is == null) { throw new FileNotFoundException(getDescription() + " cannot be opened because it does not exist"); } //返回InputStream return is; } } 再看UrlResource的源码，获取InputStream的实现又是另一种策略。
public class UrlResource extends AbstractFileResolvingResource { @Nullable private final URI uri; private final URL url; private final URL cleanedUrl; @Override public InputStream getInputStream() throws IOException { //获取连接 URLConnection con = this.url.openConnection(); ResourceUtils.useCachesIfNecessary(con); try { //获取输入流，并返回 return con.getInputStream(); } catch (IOException ex) { // Close the HTTP connection (if applicable). if (con instanceof HttpURLConnection) { ((HttpURLConnection) con).disconnect(); } throw ex; } } } 4、代理模式 对于代理模式不了解地读者可以阅读另外一篇文章：Java设计模式之结构型模式：代理模式
AOP是Spring的一个核心特性(面向切面编程)，作为面向对象的一种补充，用于将那些与业务无关，但却对多个对象产生影响的公共行为和逻辑，抽取并封装为一个可重用的模块，减少系统中的重复代码，降低了模块间的耦合度，提高系统的可维护性。可用于权限认证、日志、事务处理。 Spring AOP实现的关键在于动态代理，主要有两种方式，JDK动态代理和CGLIB动态代理：
（1）JDK动态代理只提供接口的代理，不支持类的代理，要求被代理类实现接口。JDK动态代理的核心是InvocationHandler接口和Proxy类，在获取代理对象时，使用Proxy类来动态创建目标类的代理类（即最终真正的代理类，这个类继承自Proxy并实现了我们定义的接口），当代理对象调用真实对象的方法时， InvocationHandler 通过invoke()方法反射来调用目标类中的代码，动态地将横切逻辑和业务编织在一起；
（2）如果被代理类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成指定类的一个子类对象，并覆盖其中特定方法并添加增强代码，从而实现AOP。CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。
我们看DefaultAopProxyFactory的createAopProxy()方法，Spring通过此方法创建动态代理类：
public class DefaultAopProxyFactory implements AopProxyFactory, Serializable { @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException { if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) { Class targetClass = config.getTargetClass(); if (targetClass == null) { throw new AopConfigException(&ldquo;TargetSource cannot determine target class: " + &ldquo;Either an interface or a target is required for proxy creation.&rdquo;); } if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) { return new JdkDynamicAopProxy(config); } return new ObjenesisCglibAopProxy(config); } else { return new JdkDynamicAopProxy(config); } } } 从源码中可以看出，Spring会先判断是否实现了接口，如果实现了接口就使用JDK动态代理，如果没有实现接口则使用Cglib动态代理，也可以通过配置，强制使用Cglib动态代理，配置如下：
&lt;aop:aspectj-autoproxy proxy-target-class=&ldquo;true&rdquo;/> JDK动态代理和Cglib动态代理的区别：
JDK动态代理只能对实现了接口的类生成代理，没有实现接口的类不能使用。 Cglib动态代理即使被代理的类没有实现接口，也可以使用，因为Cglib动态代理是使用继承被代理类的方式进行扩展。 Cglib动态代理是通过继承的方式，覆盖被代理类的方法来进行代理，所以如果方法是被final修饰的话，就不能进行代理。
5、模板方法 对于模板模式不了解地读者可以阅读另外一篇文章：Java设计模式之行为型模式：模板方法模式
所谓模板就是一个方法，这个方法定义了算法的骨架，即将算法的实现定义成了一组步骤，并将一些步骤延迟到子类中实现，子类重写抽象类中的模板方法实现算法骨架中特定的步骤。模板模式可以不改变一个算法的结构即可重新定义该算法的某些特定步骤。在模板方法模式中，我们可以将相同部分的代码放在父类中，而将不同的代码放入不同的子类中，从而解决代码重复的问题。
Spring中的事务管理器就运用模板模式的设计，首先看PlatformTransactionManager类。这是最底层的接口，定义提交和回滚的方法。
public interface PlatformTransactionManager { TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException; void commit(TransactionStatus status) throws TransactionException; void rollback(TransactionStatus status) throws TransactionException; } 毫无意外，使用了抽象类作为骨架，接着看AbstractPlatformTransactionManager类。
@Override public final void commit(TransactionStatus status) throws TransactionException { //省略... DefaultTransactionStatus defStatus = (DefaultTransactionStatus) status; if (defStatus.isLocalRollbackOnly()) { //省略... //调用processRollback() processRollback(defStatus, false); return; } if (!shouldCommitOnGlobalRollbackOnly() &amp;&amp; defStatus.isGlobalRollbackOnly()) { //省略... //调用processRollback() processRollback(defStatus, true); return; } //调用processCommit() processCommit(defStatus); } //这个方法定义了骨架，里面会调用一个doRollback()的模板方法 private void processRollback(DefaultTransactionStatus status, boolean unexpected) { if (status.hasSavepoint()) { //省略... } else if (status.isNewTransaction()) { //调用doRollback()模板方法 doRollback(status); } else { //省略... } //省略了很多代码... } private void processCommit(DefaultTransactionStatus status) throws TransactionException { //省略... if (status.hasSavepoint()) { //省略... } else if (status.isNewTransaction()) { //省略... //调用doCommit()模板方法 doCommit(status); } else if (isFailEarlyOnGlobalRollbackOnly()) { unexpectedRollback = status.isGlobalRollbackOnly(); } //省略了很多代码... } //模板方法doRollback()，把重要的步骤延迟到子类去实现 protected abstract void doRollback(DefaultTransactionStatus status) throws TransactionException; //模板方法doCommit()，把重要的步骤延迟到子类去实现 protected abstract void doCommit(DefaultTransactionStatus status) throws TransactionException; 模板方法则由各种事务管理器的实现类去实现，也就是把骨架中重要的doRollback()延迟到子类。一般来说，Spring默认是使用的事务管理器的实现类是DataSourceTransactionManager。
//通过继承AbstractPlatformTransactionManager抽象类 public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean { //重写doCommit()方法，实现具体commit的逻辑 @Override protected void doCommit(DefaultTransactionStatus status) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); if (status.isDebug()) { logger.debug("Committing JDBC transaction on Connection [" + con + "]"); } try { con.commit(); } catch (SQLException ex) { throw new TransactionSystemException("Could not commit JDBC transaction", ex); } } //重写doRollback()方法，实现具体的rollback的逻辑 @Override protected void doRollback(DefaultTransactionStatus status) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); if (status.isDebug()) { logger.debug("Rolling back JDBC transaction on Connection [" + con + "]"); } try { con.rollback(); } catch (SQLException ex) { throw new TransactionSystemException("Could not roll back JDBC transaction", ex); } } } 如果你是用Hibernate框架，Hibernate也有自身的实现，这就体现了设计模式的开闭原则，通过继承或者组合的方式进行扩展，而不是直接修改类的代码。Hibernate的事务管理器则是HibernateTransactionManager。
public class HibernateTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, BeanFactoryAware, InitializingBean { //重写doCommit()方法，实现Hibernate的具体commit的逻辑 @Override protected void doCommit(DefaultTransactionStatus status) {HibernateTransactionObject txObject = (HibernateTransactionObject) status.getTransaction(); Transaction hibTx = txObject.getSessionHolder().getTransaction(); Assert.state(hibTx != null, "No Hibernate transaction"); if (status.isDebug()) { logger.debug("Committing Hibernate transaction on Session [" + txObject.getSessionHolder().getSession() + "]"); } try { hibTx.commit(); } catch (org.hibernate.TransactionException ex) { throw new TransactionSystemException("Could not commit Hibernate transaction", ex); } //省略... } //重写doRollback()方法，实现Hibernate的具体rollback的逻辑 @Override protected void doRollback(DefaultTransactionStatus status) { HibernateTransactionObject txObject = (HibernateTransactionObject) status.getTransaction(); Transaction hibTx = txObject.getSessionHolder().getTransaction(); Assert.state(hibTx != null, "No Hibernate transaction"); //省略... try { hibTx.rollback(); } catch (org.hibernate.TransactionException ex) { throw new TransactionSystemException("Could not roll back Hibernate transaction", ex); } //省略... finally { if (!txObject.isNewSession() &amp;&amp; !this.hibernateManagedSession) { txObject.getSessionHolder().getSession().clear(); } } } } 其实模板模式在日常开发中也经常用，比如一个方法中，前后代码都一样，只有中间有一部分操作不同，就可以使用模板模式进行优化代码，这可以大大地减少冗余的代码，非常实用。
6、适配器模式与责任链模式： 对于适配器模式不了解地读者可以阅读另外一篇文章：Java设计模式之结构型模式：适配器模式
对于责任链模式不了解地读者可以阅读另外一篇文章：Java设计模式之行为型模式：责任链模式
适配器模式能使接口不兼容的对象能够相互合作，将一个类的接口，转换成客户期望的另外一个接口。
在SpringAOP中有一个很重要的功能就是使用的 Advice（通知） 来增强被代理类的功能，Advice主要有MethodBeforeAdvice、AfterReturningAdvice、ThrowsAdvice这几种。每个Advice都有对应的拦截器，如下所示：
Spring需要将每个 Advice 都封装成对应的拦截器类型返回给容器，所以需要使用适配器模式对 Advice 进行转换。对应的就有三个适配器，我们看个类图：
适配器在Spring中是怎么把通知类和拦截类进行转换的呢，我们先看适配器的接口。定义了两个方法，分别是supportsAdvice()和getInterceptor()。
public interface AdvisorAdapter { //判断通知类是否匹配 boolean supportsAdvice(Advice advice); //传入通知类，返回对应的拦截类 MethodInterceptor getInterceptor(Advisor advisor); } 其实很简单，可以看出转换的方法就是getInterceptor()，通过supportsAdvice()进行判断。我们看前置通知的适配器的实现类MethodBeforeAdviceAdapter。
class MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable { //判断是否匹配MethodBeforeAdvice通知类 @Override public boolean supportsAdvice(Advice advice) { return (advice instanceof MethodBeforeAdvice); } //传入MethodBeforeAdvice，转换为MethodBeforeAdviceInterceptor拦截类 @Override public MethodInterceptor getInterceptor(Advisor advisor) { MethodBeforeAdvice advice = (MethodBeforeAdvice) advisor.getAdvice(); return new MethodBeforeAdviceInterceptor(advice); } } getInterceptor()方法中，调用了对应的拦截类的构造器创建对应的拦截器返回，传入通知类advice作为参数。接着我们看拦截器MethodBeforeAdviceInterceptor。
public class MethodBeforeAdviceInterceptor implements MethodInterceptor, Serializable { //成员变量，通知类 private MethodBeforeAdvice advice; //定义了有参构造器，外部通过有参构造器创建MethodBeforeAdviceInterceptor public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) { Assert.notNull(advice, "Advice must not be null"); this.advice = advice; } //当调用拦截器的invoke方法时，就调用通知类的before()方法，实现前置通知 @Override public Object invoke(MethodInvocation mi) throws Throwable { //调用通知类的before()方法，实现前置通知 this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis() ); return mi.proceed(); } } 那么在哪里初始化这些适配器呢，我们看DefaultAdvisorAdapterRegistry()
public class DefaultAdvisorAdapterRegistry implements AdvisorAdapterRegistry, Serializable { private final List&lt;AdvisorAdapter> adapters = new ArrayList&lt;>(3); public DefaultAdvisorAdapterRegistry() { //初始化适配器，添加到adapters集合，也就是注册 registerAdvisorAdapter(new MethodBeforeAdviceAdapter()); registerAdvisorAdapter(new AfterReturningAdviceAdapter()); registerAdvisorAdapter(new ThrowsAdviceAdapter()); } @Override public void registerAdvisorAdapter(AdvisorAdapter adapter) { this.adapters.add(adapter); } //获取所有的拦截器 @Override public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException { List&lt;MethodInterceptor> interceptors = new ArrayList&lt;>(3); Advice advice = advisor.getAdvice(); if (advice instanceof MethodInterceptor) { interceptors.add((MethodInterceptor) advice); } //遍历adapters集合 for (AdvisorAdapter adapter : this.adapters) { //调用supportsAdvice()方法，判断入参的advisor是否有匹配的适配器 if (adapter.supportsAdvice(advice)) { //如果匹配，则调用getInterceptor()转换成对应的拦截器，添加到interceptors集合中 interceptors.add(adapter.getInterceptor(advisor)); } } if (interceptors.isEmpty()) { throw new UnknownAdviceTypeException(advisor.getAdvice()); } //返回拦截器集合 return interceptors.toArray(new MethodInterceptor[0]); } } 适配器模式在这里就是把通知类转为拦截类，转为拦截类之后，就添加到拦截器集合中。添加到拦截器集合之后，就用到了责任链模式，在ReflectiveMethodInvocation类被调用，我们看JDK动态代理JdkDynamicAopProxy的invoke()方法。
@Override @Nullable public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { MethodInvocation invocation; //这里就是获取拦截器集合，最后就会调用到上文说的getInterceptors() List&lt;Object> chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty()) { //省略... }else { //创建一个MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); //调用proceed()方法，底层会通过指针遍历拦截器集合，然后实现前置通知等功能 retVal = invocation.proceed(); } //省略... } 最后就在ReflectiveMethodInvocation里调用proceed()方法，proceed()方法是一个递归的方法，通过指针控制递归的结束。这是很典型的责任链模式。
public class ReflectiveMethodInvocation implements ProxyMethodInvocation, Cloneable { protected final List&lt;?> interceptorsAndDynamicMethodMatchers; //指针 private int currentInterceptorIndex = -1; protected ReflectiveMethodInvocation(Object proxy, @Nullable Object target, Method method, @Nullable Object[] arguments, @Nullable Class&lt;?> targetClass, List&lt;Object> interceptorsAndDynamicMethodMatchers) { //省略... //拦截器的集合 this.interceptorsAndDynamicMethodMatchers = interceptorsAndDynamicMethodMatchers; } @Override @Nullable public Object proceed() throws Throwable { // We start with an index of -1 and increment early. if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) { //递归结束 return invokeJoinpoint(); } //获取拦截器，并且当前的指针+1 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) { InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) { return dm.interceptor.invoke(this); } else { //匹配失败，跳过，递归下一个 return proceed(); } } else { //匹配拦截器，强转为拦截器，然后执行invoke()方法，然后就会调用拦截器里的成员变量的before()，afterReturning()等等，实现前置通知，后置通知，异常通知 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); } } } 这里可能没学过责任链模式的同学会看得有点晕，但是学过责任链模式应该很容易看懂，这其实跟SpringMVC的拦截器的逻辑实现几乎一样的。
7、观察者模式 对于观察者模式不了解地读者可以阅读另外一篇文章：Java设计模式之行为型模式：观察者模式
观察者模式是一种对象行为型模式，当一个对象发生变化时，这个对象所依赖的对象也会做出反应。
Spring 事件驱动模型就是观察者模式很经典的一个应用。
1、事件角色：
在Spring事件驱动模型中，首先有事件角色ApplicationEvent，这是一个抽象类，抽象类下有四个实现类代表四种事件。
ContextStartedEvent：ApplicationContext启动后触发的事件。 ContextStoppedEvent：ApplicationContext停止后触发的事件。 ContextRefreshedEvent：ApplicationContext初始化或刷新完成后触发的事件。 ContextClosedEvent：ApplicationContext关闭后触发的事件。
2、事件发布者：
有了事件之后，需要有个发布者发布事件，发布者对应的类是ApplicationEventPublisher。
@FunctionalInterface public interface ApplicationEventPublisher { default void publishEvent(ApplicationEvent event) { publishEvent((Object) event); } void publishEvent(Object event); } @FunctionalInterface表示这是一个函数式接口，函数式接口只有一个抽象方法。ApplicationContext类又继承了ApplicationEventPublisher类，所以我们可以使用ApplicationContext发布事件。
3、事件监听者：
发布事件后需要有事件的监听者，事件监听者通过实现接口ApplicationListener来定义，这是一个函数式接口，并且带有泛型，要求E参数是ApplicationEvent的子类。
@FunctionalInterface public interface ApplicationListener&lt;E extends ApplicationEvent> extends EventListener { void onApplicationEvent(E event); } 4、下面我们演示一下怎么使用，首先继承抽象类ApplicationEvent定义一个事件角色PayApplicationEvent。
public class PayApplicationEvent extends ApplicationEvent { private String message; public PayApplicationEvent(Object source, String message) { super(source); this.message = message; } public String getMessage() { return message; } } 接着定义一个PayApplicationEvent事件的监听者PayListener。
@Component public class PayListener implements ApplicationListener&lt;PayApplicationEvent> { @Override public void onApplicationEvent(PayApplicationEvent event) { String message = event.getMessage(); System.out.println("监听到PayApplicationEvent事件，消息为：" + message); } } 最后我们使用ApplicationContext发布事件。
@SpringBootApplication public class SpringmvcApplication { public static void main(String[] args) throws Exception { ApplicationContext applicationContext = SpringApplication.run(SpringmvcApplication.class, args); applicationContext.publishEvent(new PayApplicationEvent(applicationContext,"成功支付100元！")); } } 启动之后我们可以看到控制台打印： 8、桥接模式 可以根据客户的需求能够动态切换不同的数据源。比如我们的项目需要连接多个数据库，客户在每次访问中根据需要会去访问不同的数据库
五、常用的设计模式 https://blog.csdn.net/a745233700/article/details/112598471?ops_request_misc=&request_id=&biz_id=102&utm_term=spring
1、装饰模式 设计模式
系列文章：
Java设计模式之创建型：工厂模式详解（简单工厂+工厂方法+抽象工厂）
Java设计模式之创建型：建造者模式
Java设计模式之创建型：单例模式
Java设计模式之创建型：原型模式
Java设计模式之结构型：适配器模式
Java设计模式之结构型：装饰器模式
Java设计模式之结构型：代理模式
Java设计模式之结构型：桥接模式
Java设计模式之结构型：外观模式
Java设计模式之结构型：组合模式
Java设计模式之结构型：享元模式
Java设计模式之行为型：策略模式
Java设计模式之行为型：模板方法模式
Java设计模式之行为型：责任链模式
Java设计模式之行为型：观察者模式
Java设计模式之行为型：访问者模式
Java设计模式之行为型：中介者模式
Java设计模式之行为型：命令模式
Java设计模式之行为型：状态模式
Java设计模式之行为型：备忘录模式
Java设计模式之行为型：迭代器模式
Java设计模式之行为型：解释器模式</content></entry><entry><title>Java框架-Spring源码（二）</title><url>https://zhang4014439175.github.io/post/spring%E6%BA%90%E7%A0%81%E4%BA%8C/</url><categories><category>Java-Framework</category><category>Spring</category></categories><tags><tag>Java</tag><tag>框架</tag><tag>Spring</tag></tags><content type="html"> 一、refresh 1、prepareRefresh /** * 前戏，做容器刷新前的准备工作 * 1、设置容器的启动时间 * 2、设置活跃状态为true * 3、设置关闭状态为false * 4、获取Enviroment对象，并加载当前系统的属性值到Enviroment对象中（可扩展） * 5、准备监听器和事件的集合对象，默认为空的集合。 */ 1.1、initPropertySources 重写initPropertySources()方法，添加系统属性
public class MyClassPathXmlApplicationContext extends ClassPathXmlApplicationContext { public MyClassPathXmlApplicationContext(String... configLocations){ super(configLocations); } @Override protected void initPropertySources() { System.out.println("扩展initPropertySource"); //这里添加了一个name属性到Environment里面，以方便我们在后面用到 getEnvironment().getSystemProperties().put("name","bobo"); //这里要求Environment中必须包含username属性，如果不包含，则抛出异常 getEnvironment().setRequiredProperties("username"); } } public class Test { public static void main(String[] args) { MyClassPathXmlApplicationContext ac = new MyClassPathXmlApplicationContext("applicationContext.xml"); String name = (String) context.getEnvironment().getSystemProperties().get("name"); System.out.println(name); // ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("spring-${username}.xml"); } } 1.2、validateRequiredProperties() @Override protected void initPropertySources() { System.out.println("扩展initPropertySource"); //这里添加了一个name属性到Environment里面，以方便我们在后面用到 getEnvironment().getSystemProperties().put("name","bobo"); //这里要求Environment中必须包含username属性，如果不包含，则抛出异常 getEnvironment().setRequiredProperties("username"); } //获取 2、obtainFreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); 2.1、refreshBeanFactory 2.1.1、customizeBeanFactory 1）介绍
**allowBeanDefinitionOverriding:**设置是否允许具有相同名称的Bean来覆盖之前的Bean
　在同一个配置文件中定义两个相同的Bean,编译器就会直接报错,但是我们可以在不同的配置文件中定义两个相同的Bean,这种情况下编译器是允许的,例如 ioc01.xml中定义了一个 id=person的Bean,ioc02中也定义了一个相同的id=person的Bean,Spring通过 allowBeanDefinitionOverriding这个属性来控制,是否允许定义两个相同的Bean,默认值是true,(也就是允许定义两个相同的Bean),只不过后加载的配置文件中的Bean会覆盖掉前面加载的配置文件中的Bean.如果allowBeanDefinitionOverriding的值为false,那么就不允许出现两个相同名称的Bean加载到Spring容器中.这样就会报错
**allowCircularReferences:**设置是否允许循环引用
　A依赖B,同时B又依赖A
　A依赖B,B依赖C,C依赖A
　这种情况就称为循环引用,Spring默认情况下使允许循环引用的.
2）源码分析
allowBeanDefinitionOverriding、allowCircularReferences这两个属性值的设置是在AbstractRefreshableApplicationContext这个类中的,具体的源码如下
　我们可以看到这里有两个判断条件 this.allowBeanDefinitionOverriding、this.allowCircularReferences,这两个判断条件的值是什么呢?
　我们在这个类中往上翻,会发现,在该类中这两个属性值都是包装类类型Boolean,而且没有给定初始值,但是包装类类型的默认初始值就是 null啊.
　所以呢,这两个判断条件都不成立,那么自然而然的DefaultListableBeanFactory类型的beanFactory就不能设置值,那么既然不能设置值,它们的初始值又是什么呢?
　翻开DefaultListableBeanFactory这个类,我们可以看到这两个属性的默认值都是true,这样的话,我们就可以知道Spring中这两个属性都是默认为true的了.
3）扩展
方式一：
ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("bean1.xml"); context.setAllowBeanDefinitionOverriding(false); context.setAllowCircularReferences(false); 方式二：
public class MyClassPathXmlApplicationContext extends ClassPathXmlApplicationContext { @Override protected void customizeBeanFactory(DefaultListableBeanFactory beanFactory) { //是否允许覆盖同名称的不同定义的对象 //spring默认为true super.setAllowBeanDefinitionOverriding(false); super.setAllowCircularReferences(false); super.customizeBeanFactory(beanFactory); } } ClassPathXmlApplicationContext context = new MyClassPathXmlApplicationContext("bean1.xml"); 问题：到底allowBeanDefinitionOverriding应该设置true还是false？
spring中默认是true，也就是默认支持名称相同的bean的覆盖。 而springboot中的默认值是false，也就是不支持名称相同的bean被覆盖。 那么我们自己应该如何选择呢？ 这里笔者认为默认不覆盖比较好。因为还是推荐一个系统中不要存在名称相同的bean，否则后者覆盖前者，多人分工合作的时候，难以避免某些bean被覆盖，会出现很多诡异的问题 ，甚至会带来线上真实的业务损失。 bean的名称不相同，依据具体的业务给bean起名字。这样不但可以解决bean名称重复的问题，还可以大大提高程序的可读性与可维护性。 只有当集成了第三方的库，不同库直接由于是多个团队开发的，甚至这些团队属于不同的国家，有可能会出现bean名称相同的情况。这种情况就需要根据实际需求来设置allowBeanDefinitionOverriding的值了。 那我问他又来了，如果能拿到spring上下文对象了，如何此时再设置这个属性，那么这个属性肯定是没有生效的，如何让这个属性生效呢？？？ applicationContext.refresh(); 就是这么简单，调用上下文对象的refresh()方法就 可以了 2.1.2、customizeBeanFactory</content></entry><entry><title>Java框架-Spring源码（一）</title><url>https://zhang4014439175.github.io/post/spring%E6%BA%90%E7%A0%81%E4%B8%80/</url><categories><category>Java-Framework</category><category>Spring</category></categories><tags><tag>Java</tag><tag>框架</tag><tag>Spring</tag></tags><content type="html"> https://www.bilibili.com/video/BV16q4y1n7Fd/?p=3&spm_id_from=pageDriver&vd_source=81d9ec453e0a2eb8337b93642bef5ce0
一、流程 1、流程 加载xml&mdash;-解析xml&mdash;-封装BeanDefinition&mdash;-实例化&mdash;-放到容器中&mdash;-从容器中获取
容器 &mdash;- Map &mdash;- 三级缓存
map k String v object
​ k class v object
​ String objectFactory
​ String BeanDefinition
BeanFactoryPostProcessor &mdash;- 实例化 &mdash;- 填充属性 &mdash;- 设置Aware接口的属性 &mdash;- BeanPostProcessor : before &mdash;&mdash; 填充属性 &mdash;&mdash; 初始化bean执行init-method方法 &mdash;- BeanPostProcessor : after &mdash;- 完整对象
填充属性后面属于对象初始化
2、对象流程 new classpathxmlApplicationContext(“applicationcontext.xml”) | 创建BeanFactory | applicationcontext.xml | xml、yaml、json定义读取配置文件的规范 | bean定义信息BeanDefinition | 反射（BeanFactory） | 实例化bean | 填充属性（prepareBeanFactory(beanFactory)） | BeanPostProcessor : before | 初始化bean执行init-method方法 | BeanPostProcessor : after | 完整bean对象 2.1、实例化bean 1）BeanFactory 反射进行创建
三种获取方式 Constructor ctor = Class.getDeclareConstructor(); Object obj = ctor,newInstance(); 2.2、实例化和初始化 实例化：堆中开辟一块空间属性都是默认值
初始化：1）填充属性、赋值
​ 2）调用具体的初始化方法
二、PostProcessor后置处理器增强器 1、BeanFactoryPostProcessor 上一步，beanDefinition &mdash;- BeanFactory中间的过程，增强beanDefinition信息
例子：
&lt;bean id=datasource class=com.alibaba.druid.pool.DruidDatasource> &lt;property name=username value=${jdbc.username}/> &lt;/bean> 自定义实现类，实现BeanFactoryPostProcessor方法，以对beandefinition进行增强
自定义 BeanFactoryPostProcessor 实现 BeanFactoryPostProcessor，重写方法，以至于可以更好的对对象进行操作
1.1、PlaceholderConfigurerSupport 对配置文件中的${}进行替换
2、BeanPostProcessor AbstractAutowireCapableBeanFactory里面
2.1、增强bean信息 2.2、AOP AbstractAutoProxyCreator 实现 BeanPostProcessor，createProxy
在after 和 before 方法里执行AOP
1）动态代理
cglib
jdk
三、Aware 在不同的阶段要处理不同的工作，应该怎么办？
观察者模式： 监听器，监听事件，多播器。
四、SpringBean 分为普通对象和容器对象
普通对象： 我们自定义需要的对象
容器对象：内置对象，spring需要的对象
五、FactoryBean FactoryBean：只需要调用getObject就可以返回具体的对象，整个对象的创建过程由用户自己来控制，用来创建一些更加复杂的、个性化的bean。一种Bean创建的一种方式，对Bean的一种扩展。对于复杂的Bean对象初始化创建使用其可封装对象的创建细节。它是一个可以返回bean的实例的工厂bean，实现这个接口可以对bean进行一些额外的操作，例如根据不同的配置类型返回不同类型的bean，简化xml配置等。
​ getObject：
​ isSingleton
​ getObjectType
BeanFactory：它是IoC容器的顶级接口，是IoC容器的底层基础实现，也是访问Spring容器的根接口，负责对bean的创建，访问等工作。需要完整的创建过程、这个过程是spring来控制的 。
它在使用上也有些特殊，BeanFactory接口中有一个字符常量String FACTORY_BEAN_PREFIX = &ldquo;&amp;&rdquo;; 当我们去获取BeanFactory类型的bean时，如果beanName不加&amp;则获取到对应bean的实例;如果beanName加上&amp;，则获取到BeanFactory本身的实例。
区别：BeanFactory是个Factory，也就是IOC容器或对象工厂，而FactoryBean就是个Bean。在Spring中，所有的Bean都是由BeanFactory(也就是IOC容器)来进行管理的。但对FactoryBean而言，这个Bean不是简单的Bean，而是一个能生产或者修饰对象生成的工厂Bean,它的实现与设计模式中的工厂模式和修饰器模式类似。
ListableBeanFactory
ConfigurationBeanFactory
CustomizeBeanFactory
​ allowBeanDefinitionOverriding
​ allowCircularReferences
loadBeanDefinitions ( beanFactory )
六、BeanDefinition beanDefinitionMap
RootBeanDefinition
GerericBeanDefinition
BeanDefinition合并
七、BeanDefinitionReader 八、调用方法 1、refresh方法 位置：AbstractApplicationContext 517行
prepareRefresh方法：
ObtainFreshBeanFactory
AbstractApplicationContext refresh开始
invokeBeanFactoryPostProcessors方法：
Tomcat入口，ServletWebServerApplicationContext的150行，onRefresh方法
九、常见问题 1、详细了解每一个步骤 如果需要在bean对象创建过程中，详细了解每一个步骤完成的进度应该怎么做？在不同的阶段要做不同的处理工作，应该怎么办？
观察者模式：监听器、监听事件</content></entry><entry><title>Elasticsearch</title><url>https://zhang4014439175.github.io/post/elasticsearch/</url><categories><category>Elasticsearch</category></categories><tags><tag>Elasticsearch</tag><tag>缓存</tag><tag>搜索</tag></tags><content type="html"> 一、es入门 1、docker安装es 、kibana docker run &ndash;name elasticsearch -p 9200:9200 -p 9300:9300 -e &ldquo;discovery.type=single-node&rdquo; -e ES_JAVA_OPTS="-Xms64m -Xmx512m" -v /mydata/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /mydata/elasticsearch/data:/usr/share/elasticsearch/data -v /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins -d elasticsearch:7.4.2
docker run &ndash;name kibana -e ELASTICSEARCH_HOSTS=http://192.168.56.102:9200 -p 5601:5601 -d kibana:7.4.2
2、查看节点信息
http://192.168.56.10:9200/_cat/nodes
3、官方文档
官方文档:https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html
官方中文:https://www.elastic.co/guide/cn/elasticsearch/guide/current/foreword_id.html
社区中文:https://es.xiaoleilu.com/index.html http://doc.codingdict.com/elasticsearch/0/
2、nginx Nginx.org/en/docs
 随便启动一个nginx实例，只是为了复制出配置  docker run -p 80:80 &ndash;name nginx -d nginx:1.10
 将容器内的配置文件拷贝到当前目录:docker container cp nginx:/etc/nginx .  别忘了后面的点
 修改文件名称:mv nginx conf 把这个 conf 移动到/mydata/nginx 下
 终止原容器:docker stop nginx
 执行命令删除原容器:docker rm $ContainerId
 创建新的nginx;执行以下命令
docker run -p 80:80 &ndash;name nginx -v /mydata/nginx/html:/usr/share/nginx/html -v /mydata/nginx/logs:/var/log/nginx -v /mydata/nginx/conf:/etc/nginx -d nginx:1.10
 给nginx的html下面放的所有资源可以直接访问;
2.1、动静分离 静：图片、js、css等静态资源（以实际文件存在的方式）
动：服务器需要处理的请求
静态资源都放在static文件夹下就可以按照路径直接访问
2.2、nginx配置文件 1）全局块
2）events块
3）http块
​ http全局块
​ 配置upstream 块
​ server块
​ location
​ proxy_pass http://直接路由到上游的upstream块
​ location
2.3、动静分离 location /static/ { root /usr/share/nginx/html; } location / { proxy_set_header Host $host; proxy_pass http://gulimall; } 2.3、问题 1）nginx代理给网关的时候，会丢失请求的host信息
Proxy_set_header Host $host
2）去gateway过滤域名
二、初步检索 1、_cat GET /_cat/nodes:查看所有节点 _
GET /_cat/health:查看 es 健康状况
GET /_cat/master:查看主节点
GET /_cat/indices:查看所有索引
show databases;
2、索引一个文档(保存) 保存一个数据，保存在哪个索引的哪个类型下，指定用哪个唯一标识
PUT customer/external/1;在 customer 索引下的 external 类型下保存 1 号数据为
PUT 和 POST 都可以， POST 新增。如果不指定 id，会自动生成 id。指定 id 就会修改这个数据，并新增版本号
PUT 可以新增可以修改。PUT 必须指定 id;由于 PUT 需要指定 id，我们一般都用来做修改 操作，不指定 id 会报错。
3、查询文档 GET customer/external/1
{ "_index": "customer", //在哪个索引 "_type": "external", //在哪个类型 "_id": "1", //记录 id "_version": 2, //版本号 "_seq_no": 1, //并发控制字段，每次更新就会+1，用来做乐观锁 "_primary_term": 1, //同上，主分片重新分配，如重启，就会变化 "found": true, "_source": { //真正的内容 "name": "John Doe" } } 更新携带 ?if_seq_no=0&amp;if_primary_term=1
4、更新文档 POST customer/external/1/_update { "doc":{ "name": "John Doew" } } POST customer/external/1 { "name": "John Doe2" } PUT customer/external/1 { "name": "John Doe" } 5、删除文档&amp;索引 POST /_bulk { "delete": { "_index": "website", "_type": "blog", "_id": "123" }} { "create": { "_index": "website", "_type": "blog", "_id": "123" }} { "title": "My first blog post"} { "index": {"_index": "website", "_type": "blog"}} { "title": "My second blog post"} { "update": { "_index": "website", "_type": "blog", "_id": "123", "_retry_on_conflict" : 3}} { "doc" : {"title" : "My updated blog post"} } P109：https://raw.githubusercontent.com/elastic/elasticsearch/7.4/docs/src/test/resources/accounts.json
P133的json： PUTproduct{&ldquo;mappings&rdquo;:{&ldquo;properties&rdquo;:{&ldquo;skuId&rdquo;:{&ldquo;type&rdquo;:&ldquo;long&rdquo;},&ldquo;spuId&rdquo;:{&ldquo;type&rdquo;:&ldquo;keyword&rdquo;},&ldquo;skuTitle&rdquo;:{&ldquo;type&rdquo;:&ldquo;text&rdquo;,&ldquo;analyzer&rdquo;:&ldquo;ik_smart&rdquo;},&ldquo;skuPrice&rdquo;:{&ldquo;type&rdquo;:&ldquo;keyword&rdquo;},&ldquo;skuImg&rdquo;:{&ldquo;type&rdquo;:&ldquo;keyword&rdquo;,&ldquo;index&rdquo;:false,&ldquo;doc_values&rdquo;:false},&ldquo;saleCount&rdquo;:{&ldquo;type&rdquo;:&ldquo;long&rdquo;},&ldquo;hasStock&rdquo;:{&ldquo;type&rdquo;:&ldquo;boolean&rdquo;},&ldquo;hotScore&rdquo;:{&ldquo;type&rdquo;:&ldquo;long&rdquo;},&ldquo;brandId&rdquo;:{&ldquo;type&rdquo;:&ldquo;long&rdquo;},&ldquo;catalogId&rdquo;:{&ldquo;type&rdquo;:&ldquo;long&rdquo;},&ldquo;brandName&rdquo;:{&ldquo;type&rdquo;:&ldquo;keyword&rdquo;,&ldquo;index&rdquo;:false,&ldquo;doc_values&rdquo;:false},&ldquo;brandImg&rdquo;:{&ldquo;type&rdquo;:&ldquo;keyword&rdquo;,&ldquo;index&rdquo;:false,&ldquo;doc_values&rdquo;:false},&ldquo;catalogName&rdquo;:{&ldquo;type&rdquo;:&ldquo;keyword&rdquo;,&ldquo;index&rdquo;:false,&ldquo;doc_values&rdquo;:false},&ldquo;attrs&rdquo;:{&ldquo;type&rdquo;:&ldquo;nested&rdquo;,&ldquo;properties&rdquo;:{&ldquo;attrId&rdquo;:{&ldquo;type&rdquo;:&ldquo;long&rdquo;},&ldquo;attrName&rdquo;:{&ldquo;type&rdquo;:&ldquo;keyword&rdquo;,&ldquo;index&rdquo;:false,&ldquo;doc_values&rdquo;:false},&ldquo;attrValue&rdquo;:{&ldquo;type&rdquo;:&ldquo;keyword&rdquo;}}}}}}
P136如果静态资源中的JS、CSS效果没有达到。可以在项目中添加一个配置类，再重启项目即可。 @Configuration public class WebMVCConfig extends WebMvcConfigurerAdapter {
​ @Override ​ public void addResourceHandlers(ResourceHandlerRegistry registry) { ​ registry.addResourceHandler("/static/**").addResourceLocations(&ldquo;classpath:/static/&rdquo;); ​ } }
二、进阶检索 1、SearchAPI ES 支持两种基本方式检索 :
1.1、一个是通过使用 REST request URI 发送搜索参数(uri+检索参数)
GET bank/_search 检索 bank 下所有信息，包括 type 和 docs GET bank/_search?q=*&amp;sort=account_number:asc 请求参数方式检索 响应结果解释: took - Elasticsearch 执行搜索的时间(毫秒) time_out - 告诉我们搜索是否超时 _shards - 告诉我们多少个分片被搜索了，以及统计了成功/失败的搜索分片 hits - 搜索结果 hits.total - 搜索结果 hits.hits - 实际的搜索结果数组(默认为前 10 的文档) sort - 结果的排序 key(键)(没有则按 score 排序
1.2、另一个是通过使用 REST request body 来发送它们(uri+请求体)
GET bank/_search { "query": { "match_all": {} }, "sort": [ { "account_number": { "order": "desc" } } ] } HTTP 客户端工具(POSTMAN)，get 请求不能携带请求体，我们变为 post 也是一样的 我们 POST 一个 JSON 风格的查询请求体到 _search API。 需要了解，一旦搜索的结果被返回，Elasticsearch 就完成了这次请求，并且不会维护任何 服务端的资源或者结果的 cursor(游标) 2、Query DSL Elasticsearch 提供了一个可以执行查询的 Json 风格的 DSL(domain-specific language 领域特 定语言)。这个被称为 Query DSL。该查询语言非常全面，并且刚开始的时候感觉有点复杂， 真正学好它的方法是从一些基础的示例开始的。
1、基本语法 { QUERY_NAME: { ARGUMENT: VALUE, ARGUMENT: VALUE,... }, "from": 0, //分页，开始 "size": 5 //大小 } { QUERY_NAME: { FIELD_NAME: { ARGUMENT: VALUE, ARGUMENT: VALUE,... } } } 案例：
GET bank/_search { "query": { "match_all": {} }, "from": 0, //分页，开始 "size": 5, //大小 "sort": [ { "account_number": { "order": "desc" } } ] } query 定义如何查询，  match_all 查询类型【代表查询所有的所有】，es 中可以在 query 中组合非常多的查 询类型完成复杂查询  除了 query 参数之外，我们也可以传递其它的参数以改变查询结果。如 sort，size  from+size限定，完成分页功能  sort排序，多字段排序，会在前序字段相等时后续字段内部排序，否则以前序为准 2、match match all
GET bank/_search { "query":{ "match":{ "account_number":"20" } } } { "query":{ "match":{ "address":"Mill" //包含Mill就行 } } } 3、match_phrase GET bank/_search { "query":{ "match_phrase":{ "address":"mill lane" } } } 4、multi_match 多字段匹配
GET bank/_search { "query":{ "multi_match":{ "query": "mill movico", "address":["mill lane"] } } } 5、bool复合查询 must：必须满足
must_not：必须不满足
should：应该
range：区间
Filter：过滤
match
GET bank/_search { "query":{ "bool":{ "must":[ //必须满足 {"match": {"gender":"M"}}, //F 女人 M 男人 //必须满足 北京 和 男人 这两个条件 {"match": {"address":"mill"}} ], "must_not":[ {"match": {"age": "38"}} ], "should":[{ "match": { "lastname": "Wallace" } }] } } } { "query":{ "bool":{ "must":[ //必须满足 { "range": { "age":{ "gte": 18, "lte": 30 } } }, { "match": { "address": "mill" } } ] } } } 6、filter过滤 不会贡献score得分
GET bank/_search { "query":{ "bool":{ "filter":{ "range": { "age":{ "gte": 18, "lte": 30 } } } } } } 7、term查询 GET bank/_search { "query":{ "term":{ "balance":32131 } } } GET bank/_search { "query":{ "match":{ "address.keyword":{ } } } } 1）keyword 和 match_phrase 的区别
keyword是精确匹配，phrase是短语匹配包含
全文检索用match、非text字段匹配用term
8、aggregations(执行聚合) 聚合提供了从数据中分组和提取数据的能力。最简单的聚合方法大致等于 SQL GROUP BY 和 SQL 聚合函数。在 Elasticsearch 中，您有执行搜索返回 hits(命中结果)，并且同时返 回聚合结果，把一个响应中的所有 hits(命中结果)分隔开的能力。这是非常强大且有效的， 您可以执行查询和多个聚合，并且在一次使用中得到各自的(任何一个的)返回结果，使用 一次简洁和简化的 API 来避免网络往返。
1）
GET bank/_search { "query":{ "match":{ "address": "mill" } }, "aggs": { "ageAgg":{ //年龄分组 "terms":{ "field": "age", "size": 10 } }, "ageAvg":{ //年龄分组 "avg":{ "field": "age" } }, "balanceAvg":{ //年龄分组 "avg":{ "field": "balance" } } } } 加size只看聚合结果
2）按照年龄聚合，并且请求这些年龄段的这些人的平均薪资
GET bank/_search { "query":{ "match_all":{} }, "aggs": { "ageAgg":{ //年龄分组 "terms":{ "field": "age", "size": 10 }, "aggs":{ "ageAvg":{ "avg":{ "field": "balance" } } } } } } 3）查出所有年龄分布，并且这些年龄段中性别M的平均薪资和性别F的平均薪资以及这个年龄段的总体平均薪资
GET bank/_search { "query":{ "match_all":{} }, "aggs": { "ageAgg":{ //年龄分组 "terms":{ "field": "age", "size": 100 }, "aggs":{ "genderAgg":{ "terms":{ "field":"gender.keyword", "size": 10 }, "aggs":{ "balanceAvg":{ "avg":{ "field": "balance" } } } }, "ageBalanceAvg":{ "avg":{ "field":"balance" } } } } } } 9、type Nested嵌入式，处理扁平化问题
GET my_index/_mapping PUT my_index/_doc/1 { "group": "fans", "user":[ { "first":"John", "last": "Smith" }, { "first":"Alice", "last": "White" } ] } 3、mapping映射 Mapping(映射) Mapping 是用来定义一个文档(document)，以及它所包含的属性(field)是如何存储和 索引的。比如，使用 mapping 来定义:
 哪些字符串属性应该被看做全文本属性(full text fields)。  哪些属性包含数字，日期或者地理位置。  文档中的所有属性是否都能被索引(_all 配置)。  日期的格式。
 自定义映射规则来执行动态添加属性。
1、创建映射 PUT /my-index { "mappings": { "properties": { "age":{ "type": "integer" }, "email":{ "type": "keyword" }, "name":{ "type": "text" }, //"employee_id":{ "type": "text" } } } } 2、添加新的字段映射 PUT /my-index/_mapping { "properties": { "employee-id": { "type": "keyword", "index": false } } } 3、迁移数据 POST _reindex { "source": { "index":"bank", "type":"account" }, "dest": { "index": "newbank" } } 4、ik分词器 POST _analyze { "analyzer": "standard", "text":"尚硅谷电商项目" } POST _analyze { "analyzer": "ik_max_word", "text":"我是中国人" } POST _analyze { "analyzer": "ik_smart", "text":"我是中国人" } 1）自定义词库
修改/usr/share/elasticsearch/plugins/ik/config/中的 IKAnalyzer.cfg.xml /usr/share/elasticsearch/plugins/ik/config
&lt;?xml version="1.0" encoding="UTF-8"?> &lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"> &lt;properties> &lt;comment>IK Analyzer 扩展配置&lt;/comment> &lt;!--用户可以在这里配置自己的扩展字典 --> &lt;entry key="ext_dict">&lt;/entry> &lt;!--用户可以在这里配置自己的扩展停止词字典--> &lt;entry key="ext_stopwords">&lt;/entry> &lt;!--用户可以在这里配置远程扩展字典 --> &lt;entry key="remote_ext_dict">http://192.168.128.130/fenci/myword.txt&lt;/entry> &lt;!--用户可以在这里配置远程扩展停止词字典--> &lt;!-- &lt;entry key="remote_ext_stopwords">words_location&lt;/entry> --> &lt;/properties> 三、实战 https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high.html
Es，kibana，jar包的版本必须一致
&lt;dependency> &lt;groupId>org.elasticsearch.client&lt;/groupId> &lt;artifactId>elasticsearch-rest-high-level-client&lt;/artifactId> &lt;version>7.4.2&lt;/version> &lt;/dependency></content></entry><entry><title>RabbitMQ（二）</title><url>https://zhang4014439175.github.io/post/rabbitmq%E4%BA%8C/</url><categories><category>微服务</category><category>中间件</category></categories><tags><tag>RabbitMQ</tag><tag>削峰</tag><tag>解耦</tag><tag>异步</tag><tag>中间件</tag></tags><content type="html"> 一、延迟队列（SpringBoot） 配置文件
1、基于死信完成延迟队列 死信队列参数：
x-dead-letter-exchange：死信交换机
x-dead-letter-routing-key：死信路由key
x-message-ttl：消息过期时间
@Configuration public class TtlQueueConfig { //普通交换机名称 public static final String X_EXCHANGE = "X"; //死信交换机名称 public static final String Y_DEAD_LETTER_EXCHANGE = "Y"; //普通队列名称 public static final String QUEUE_A = "QA"; public static final String QUEUE_B = "QB"; //死信队列名称 public static final String DEAD_LETTER_QUEUE = "QD"; @Bean("xExchange") public DirectExchange xExchange() { return new DirectExchange(X_EXCHANGE); } @Bean("yExchange") public DirectExchange yExchange() { return new DirectExchange(Y_DEAD_LETTER_EXCHANGE); } @Bean("queueA") public Queue queueA() { Map&lt;String, Object> arguments = new HashMap&lt;>(); arguments.put("x-dead-letter-exchange", Y_DEAD_LETTER_EXCHANGE); arguments.put("x-dead-letter-routing-key", "YD"); arguments.put("x-message-ttl", 10000); return QueueBuilder.durable(QUEUE_A).withArguments(arguments).build(); } @Bean("queueB") public Queue queueB() { Map&lt;String, Object> arguments = new HashMap&lt;>(); arguments.put("x-dead-letter-exchange", Y_DEAD_LETTER_EXCHANGE); arguments.put("x-dead-letter-routing-key", "YD"); arguments.put("x-message-ttl", 40000); return QueueBuilder.durable(QUEUE_B).withArguments(arguments).build(); } @Bean("queueD") public Queue queueD() { return QueueBuilder.durable(DEAD_LETTER_QUEUE).build(); } @Bean public Binding queueABindingX(@Qualifier("queueA") Queue queueA, @Qualifier("xExchange") DirectExchange xExchange) { return BindingBuilder.bind(queueA).to(xExchange).with("XA"); } @Bean public Binding queueBBindingX(@Qualifier("queueB") Queue queueB, @Qualifier("xExchange") DirectExchange xExchange) { return BindingBuilder.bind(queueB).to(xExchange).with("XB"); } @Bean public Binding queueDBindingY(@Qualifier("queueD") Queue queueD, @Qualifier("yExchange") DirectExchange yExchange) { return BindingBuilder.bind(queueD).to(yExchange).with("YD"); } } 生产者： @GetMapping("/sendMsg/{message}") public void sendMsg(@PathVariable String message) { log.info("当前时间：{},发送一条信息给两个TTL队列：{}", new Date(), message); rabbitTemplate.convertAndSend("X", "XA", "消息来自ttl为10s的队列：" + message); rabbitTemplate.convertAndSend("X", "XB", "消息来自ttl为40s的队列：" + message); } 消费者： @Slf4j @Component public class DeadLetterQueueConsumer { //接收消息 @RabbitListener(queues = "QD") public void receiveD(Message message, Channel channel) throws Exception { String msg = new String(message.getBody()); log.info("当前时间：{},收到死信队列的消息:{}", new Date().toString(), msg); } } 第一条消息在 10S 后变成了死信消息，然后被消费者消费掉，第二条消息在 40S 之后变成了死信消息， 然后被消费掉，这样一个延时队列就打造完成了。
不过，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有 10S 和 40S 两个时间选项，如果需要一个小时后处理，那么就需要增加 TTL 为一个小时的队列，如果是预定会议室然 后提前通知这样的场景，岂不是要增加无数个队列才能满足需求?
2、延迟队列优化 看起来似乎没什么问题，但是在最开始的时候，就介绍过如果使用在消息属性上设置 TTL 的方式，消息可能并不会按时“死亡“，因为 RabbitMQ 只会检查第一个消息是否过期，如果过期则丢到死信队列， 如果第一个消息的延时时长很长，而第二个消息的延时时长很短，第二个消息并不会优先得到执行。
@GetMapping("/sendMsg/{message}") public void sendMsg(@PathVariable String message) { log.info("当前时间：{},发送一条信息给两个TTL队列：{}", new Date(), message); rabbitTemplate.convertAndSend("X", "XA", "消息来自ttl为10s的队列：" + message); rabbitTemplate.convertAndSend("X", "XB", "消息来自ttl为40s的队列：" + message); } @GetMapping("/sendExpirationMsg/{message}/{ttlTime}") public void sendMsgs(@PathVariable String message, @PathVariable String ttlTime) { log.info("当前时间：{},发送一条信息给两个TTL队列：{}", new Date(), ttlTime, message); rabbitTemplate.convertAndSend("X", "XC", message, msg -> { msg.getMessageProperties().setExpiration(ttlTime); return msg; }); } 3、rabbitmq使用插件实现延迟队列 @GetMapping("/sendDelayMsg/{message}/{delayTime}") public void sendMsg(@PathVariable String message, @PathVariable Integer delayTime) { log.info("当前时间：{},发送一条时长{}毫秒TTL信息给队列QC:{}", new Date().toString(), delayTime, message); rabbitTemplate.convertAndSend(DelayedQueueConfig.DELAYED_EXCHANGE_NAME, DelayedQueueConfig.DELAYED_ROUTING_KEY, message, msg -> { msg.getMessageProperties().setDelay(delayTime); return msg; }); } 延时队列还有很多其他的选择，比如Java的DelayQueue，利用Redis的zset，利用Quartz或者kafka的时间轮，这些方式各有特点，看需要使用的场景。
二、发布确认高级 1、集成springboot 1.1、配置 1）配置回调类型
​ Spring.rabbitmq.publisher-confirm-type=correlated
None ​ 禁用发布模式，是默认
CORRELATED
发布消息成功到交换器后会触发回调方法
如果交换机写错会报错
如果路由key写错，回调收到消息，队列收不到消息
SIMPLE
经测试有两种效果，其一效果和 CORRELATED 值一样会触发回调方法，
其二在发布消息成功后使用 rabbitTemplate 调用 waitForConfirms 或 waitForConfirmsOrDie 方法 等待 broker 节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是 waitForConfirmsOrDie 方法如果返回 false 则会关闭 channel，则接下来无法发送消息到 broker
@Configuration public class ConfirmConfig { public static final String CONFIRM_EXCHANGE_NAME = "confirm.exchange"; public static final String CONFIRM_QUEUE_NAME = "confirm.queue"; public static final String CONFIRM_ROUTING_KEY = "key1"; //声明业务 Exchange @Bean("confirmExchange") public DirectExchange confirmExchange(){ return new DirectExchange(CONFIRM_EXCHANGE_NAME); } // 声明确认队列 @Bean("confirmQueue") public Queue confirmQueue(){ return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build(); } // 声明确认队列绑定关系 @Bean public Binding queueBinding(@Qualifier("confirmQueue") Queue queue, @Qualifier("confirmExchange") DirectExchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(CONFIRM_ROUTING_KEY); } } 1.2、回调 消息被接收后，回调确认已接收消息
实现回退的话，会回退没有收到的消息
@Slf4j @Component //第一步执行 public class MyCallBack implements RabbitTemplate.ConfirmCallback { @Autowired //第二步执行 private RabbitTemplate rabbitTemplate; @PostConstruct //第三步执行 注入 public void init() { rabbitTemplate.setConfirmCallback(this); } /** * 交换机确认回调方法 * 1.发消息 交换机接收到了 回调 * 1.1 correlationData保存回调消息的ID及相关信息 * 1.2 交换机收到消息 ack = true * 1.3 cause null * 2.发消息 交换机接受失败了 回调 * 2.1 correlationData 保存回调消息的ID及相关信息 * 2.2 交换机接收到消息 ack = false * 2.3 cause 失败的原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) { String id = correlationData != null ? correlationData.getId() : ""; if (ack) { log.info("交换机已经收到Id为 {} 的消息", id); }else { log.info("交换机还没有收到Id为 {} 的消息，由于原因 {}", id, cause); } } } 1.3、生产者 @GetMapping("/sendMessage/{message}") public void sendMessage(@PathVariable String message) { CorrelationData correlationData = new CorrelationData("1"); rabbitTemplate.convertAndSend(ConfirmConfig.CONFIRM_EXCHANGE_NAME, "key2", message, correlationData); log.info("发送消息内容:{}", message); } 1.4、消费者 @Slf4j @Component public class Consumer { @RabbitListener(queues = ConfirmConfig.CONFIRM_QUEUE_NAME) public void receiveConfirmMessage(Message message) { System.out.println(new String(message.getBody())); log.info("接收到队列confirm.queue消息：{}", message); } } 如果修改key之后，消息无法被路由
2、回退消息（无法被路由时处理） Spring.rabbitmq.publisher-returns=true
在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如 果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道消息被丢弃这个事件的。那么如何 让无法被路由的消息帮我想办法处理一下?最起码通知我一声，我好自己处理啊。通过设置 mandatory 参 数可以在当消息传递过程中不可达目的地时将消息返回给生产者。
2.1升级回调 ​ Spring.rabbitmq.publisher-returns=true
​ 实现回退方法，重写回退方法，配置初始化方法
@Slf4j @Component //第一步执行 public class MyCallBack implements RabbitTemplate.ConfirmCallback, RabbitTemplate.ReturnCallback { @Autowired //第二步执行 private RabbitTemplate rabbitTemplate; @PostConstruct //第三步执行 注入 public void init() { rabbitTemplate.setConfirmCallback(this); rabbitTemplate.setReturnCallback(this); } /** * 交换机确认回调方法 * 1.发消息 交换机接收到了 回调 * 1.1 correlationData保存回调消息的ID及相关信息 * 1.2 交换机收到消息 ack = true * 1.3 cause null * 2.发消息 交换机接受失败了 回调 * 2.1 correlationData 保存回调消息的ID及相关信息 * 2.2 交换机接收到消息 ack = false * 2.3 cause 失败的原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) { String id = correlationData != null ? correlationData.getId() : ""; if (ack) { log.info("交换机已经收到Id为 {} 的消息", id); }else { log.info("交换机还没有收到Id为 {} 的消息，由于原因 {}", id, cause); } } /** * 通过设置 mandatory 参数可以在当消息传递过程中不可达目的地时将消息返回给生产者 * 只有不可达目的地时，才进行回退 */ @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) { log.error("消息{},被交换机{}退回，退回原因:{},路由 key:{}",new String(message.getBody()),exchange,replyText, routingKey); } } 3、备份交换机 3.1 确认交换机要转发消息到备份交换机，需要修改交换机类型
//普通确认交换机 @Bean("confirmExchange") public DirectExchange confirmExchange(){ return new DirectExchange(CONFIRM_EXCHANGE_NAME); } //转发备份交换机的确认交换机 @Bean("confirmExchange") public DirectExchange confirmExchange(){ return ExchangeBuilder.directExchange(CONFIRM_EXCHANGE_NAME).durable(true) .withArgument("alternate-exchange", BACKUP_EXCHANGE_NAME).build(); } //声明备份 Exchange @Bean("backupExchange") public FanoutExchange backupExchange(){ return new FanoutExchange(BACKUP_EXCHANGE_NAME); } //声明备份队列绑定备份交换机 @Bean public Binding backupBinding(@Qualifier("backupQueue") Queue backupQueue, @Qualifier("backupExchange") FanoutExchange backupExchange){ return BindingBuilder.bind(backupQueue).to(backupExchange); } // 声明报警队列绑定备份交换机 @Bean public Binding warningBinding(@Qualifier("warningQueue") Queue warningQueue, @Qualifier("backupExchange") FanoutExchange backupExchange){ return BindingBuilder.bind(warningQueue).to(backupExchange); } @Slf4j public class WarningConsumer { //接收报警信息 @RabbitListener(queues = ConfirmConfig.WARNING_QUEUE_NAME) public void receiveWarningMsg(Message message) { String msg = new String(message.getBody()); log.error("报警发现不可路由消息:{}", msg); } } 3.2 mandatory 参数与备份交换机可以一起使用的时候，如果两者同时开启，消息究竟何去何从?谁优先 级高，经过上面结果显示答案是备份交换机优先级高。
4、幂等性 4.1 概念 用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。 举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常， 此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱 了，流水记录也变成了两条。在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等等
4.2 消息重复消费 消费者在消费 MQ 中的消息时，MQ 已把消息发送给消费者，消费者在给 MQ 返回 ack 时网络中断， 故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但 实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息。
4.3 解决思路 MQ 消费者的幂等性的解决一般使用全局 ID 或者写个唯一标识比如时间戳 或者 UUID 或者订单消费 者消费 MQ 中的消息也可利用 MQ 的该 id 来判断，或者可按自己的规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已消费过。
4.4 消费端的幂等性保障 在海量订单生成的业务高峰期，生产端有可能就会重复发生了消息，这时候消费端就要实现幂等性， 这就意味着我们的消息永远不会被消费多次，即使我们收到了一样的消息。业界主流的幂等性有两种操作:a. 唯一 ID+指纹码机制,利用数据库主键去重, b.利用 redis 的原子性去实现
4.4.1唯一 ID+指纹码机制
指纹码:我们的一些规则或者时间戳加别的服务给到的唯一信息码,它并不一定是我们系统生成的，基 本都是由我们的业务规则拼接而来，但是一定要保证唯一性，然后就利用查询语句进行判断这个 id 是否存 在数据库中,优势就是实现简单就一个拼接，然后查询判断是否重复;劣势就是在高并发时，如果是单个数 据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但也不是我们最推荐的方式。
4.4.2Redis 原子性
利用 redis 执行 setnx 命令，天然具有幂等性。从而实现不重复消费
5、优先级队列 在我们系统中有一个订单催付的场景，我们的客户在天猫下的订单,淘宝会及时将订单推送给我们，如 果在用户设定的时间内未付款那么就会给用户推送一条短信提醒，很简单的一个功能对吧，但是，tmall 商家对我们来说，肯定是要分大客户和小客户的对吧，比如像苹果，小米这样大商家一年起码能给我们创 造很大的利润，所以理应当然，他们的订单必须得到优先处理，而曾经我们的后端系统是使用 redis 来存 放的定时轮询，大家都知道 redis 只能用 List 做一个简简单单的消息队列，并不能实现一个优先级的场景，所以订单量大了后采用 RabbitMQ 进行改造和优化,如果发现是大客户的订单给一个相对比较高的优先级， 否则就是默认优先级。
6、惰性队列（学习） RabbitMQ 从 3.6.0 版本开始引入了惰性队列的概念。惰性队列会尽可能的将消息存入磁盘中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持 更多的消息存储。当消费者由于各种各样的原因(比如消费者下线、宕机亦或者是由于维护而关闭等)而致 使长时间内不能消费消息造成堆积时，惰性队列就很有必要了。
默认情况下，当生产者将消息发送到 RabbitMQ 的时候，队列中的消息会尽可能的存储在内存之中， 这样可以更加快速的将消息发送给消费者。即使是持久化的消息，在被写入磁盘的同时也会在内存中驻留 一份备份。当 RabbitMQ 需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的 时间，也会阻塞队列的操作，进而无法接收新的消息。虽然 RabbitMQ 的开发者们一直在升级相关的算法， 但是效果始终不太理想，尤其是在消息量特别大的时候。
6.1、两种模式 队列具备两种模式:default 和 lazy。默认的为 default 模式，在 3.6.0 之前的版本无需做任何变更。lazy 模式即为惰性队列的模式，可以通过调用 channel.queueDeclare 方法的时候在参数中设置，也可以通过 Policy 的方式设置，如果一个队列同时使用这两种方式设置的话，那么 Policy 的方式具备更高的优先级。 如果要通过声明的方式改变已有队列的模式的话，那么只能先删除队列，然后再重新声明一个新的。
在队列声明的时候可以通过“x-queue-mode”参数来设置队列的模式，取值为“default”和“lazy”。下面示 例中演示了一个惰性队列的声明细节:
Map&lt;String, Object> args = new HashMap&lt;String, Object>(); args.put("x-queue-mode", "lazy"); channel.queueDeclare("myqueue", false, false, false, args); 6.2、内存开销 在发送 1 百万条消息，每条消息大概占 1KB 的情况下，普通队列占用内存是 1.2GB，而惰性队列仅仅 占用 1.5MB
三、rabbitmq集群 1、集群clustering 1.1、使用集群的原因 最开始我们介绍了如何安装及运行 RabbitMQ 服务，不过这些是单机版的，无法满足目前真实应用的 要求。如果 RabbitMQ 服务器遇到内存崩溃、机器掉电或者主板故障等情况，该怎么办?单台 RabbitMQ 服务器可以满足每秒 1000 条消息的吞吐量，那么如果应用需要 RabbitMQ 服务满足每秒 10 万条消息的吞吐量呢?购买昂贵的服务器来增强单机 RabbitMQ 务的性能显得捉襟见肘，搭建一个 RabbitMQ 集群才是 解决实际问题的关键.
1.2、搭建步骤 1.2.1.修改 3 台机器的主机名称
​ vim /etc/hostname
1.2.2.配置各个节点的 hosts 文件，让各个节点都能互相识别对方
​ vim /etc/hosts 10.211.55.74 node1 10.211.55.75 node2 10.211.55.76 node3
1.2.3.以确保各个节点的 cookie 文件使用的是同一个值 在 node1 上执行远程操作命令
​ scp /var/lib/rabbitmq/.erlang.cookie root@node2:/var/lib/rabbitmq/.erlang.cookie
​ scp /var/lib/rabbitmq/.erlang.cookie root@node3:/var/lib/rabbitmq/.erlang.cookie
1.2.4.启动 RabbitMQ 服务,顺带启动 Erlang 虚拟机和 RbbitMQ 应用服务(在三台节点上分别执行以 下命令)
​ rabbitmq-server -detached
1.2.5.在节点 2 执行
rabbitmqctl stop_app (rabbitmqctl stop 会将 Erlang 虚拟机关闭，rabbitmqctl stop_app 只关闭 RabbitMQ 服务) rabbitmqctl reset rabbitmqctl join_cluster rabbit@node1 rabbitmqctl start_app(只启动应用服务) 1.2.6.在节点 3 执行
rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl join_cluster rabbit@node2 rabbitmqctl start_app 1.2.7.集群状态
rabbitmqctl cluster_status 1.2.8.需要重新设置用户
#创建账号 rabbitmqctl add_user admin 123 #设置用户角色 rabbitmqctl set_user_tags admin administrator #设置用户权限 rabbitmqctl set_permissions -p "/" admin ".*" ".*" ".*" 1.2.9.解除集群节点(node2 和 node3 机器分别执行)
rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl start_app rabbitmqctl cluster_status rabbitmqctl forget_cluster_node rabbit@node2(node1 机器上执行） 2、镜像队列 如果 RabbitMQ 集群中只有一个 Broker 节点，那么该节点的失效将导致整体服务的临时性不可用，并且也可能会导致消息的丢失。可以将所有消息都设置为持久化，并且对应队列的 durable 属性也设置为 true， 但是这样仍然无法避免由于缓存导致的问题:因为消息在发送之后和被写入磁盘井执行刷盘动作之间存在 一个短暂却会产生问题的时间窗。通过 publisherconfirm 机制能够确保客户端知道哪些消息己经存入磁盘， 尽管如此，一般不希望遇到因单点故障导致的服务不可用。
引入镜像队列(Mirror Queue)的机制，可以将队列镜像到集群中的其他 Broker 节点之上，如果集群中 的一个节点失效了，队列能自动地切换到镜像中的另一个节点上以保证服务的可用性。
2.1步骤
1、启动三台集群节点 2、随便找一个节点添加 policy ， admin右边 name：随便 pattern：正则式 ^mirrior，mirrior为前缀的队列 ha-mode exactly ha-params 2 ha-sync-mode automatic 3、在 node1 上创建一个队列发送一条消息，队列存在镜像队列 4、停掉 node1 之后发现 node2 成为镜像队列 5、就算整个集群只剩下一台机器了，依然能消费队列里面的消息。说明队列里面的消息被镜像队列传递到相应机器里面了 3、Haproxy + Keepalive实现负载均衡 HAProxy 提供高可用性、负载均衡及基于 TCPHTTP 应用的代理，支持虚拟主机，它是免费、快速并 且可靠的一种解决方案，包括 Twitter,Reddit,StackOverflow,GitHub 在内的多家知名互联网公司在使用。 HAProxy 实现了一种事件驱动、单一进程模型，此模型支持非常大的井发连接数。
扩展 nginx,lvs,haproxy 之间的区别: http://www.ha97.com/5646.html
3.1补助
1、下载 haproxy(在 node1 和 node2) yum -y install haproxy 2、修改 node1 和 node2 的 haproxy.cfg vim /etc/haproxy/haproxy.cfg 需要修改红色 IP 为当前机器 IP 3、在两台节点启动 haproxy haproxy -f /etc/haproxy/haproxy.cfg ps -ef | grep haproxy 4、访问地址 http://10.211.55.71:8888/stats 3.2Keepalived 实现双机(主备)热备
试想如果前面配置的 HAProxy 主机突然宕机或者网卡失效，那么虽然 RbbitMQ 集群没有任何故障但是 对于外界的客户端来说所有的连接都会被断开结果将是灾难性的为了确保负载均衡服务的可靠性同样显得 十分重要，这里就要引入 Keepalived 它能够通过自身健康检查、资源接管功能做高可用(双机热备)，实现 故障转移.
1.下载 keepalived yum -y install keepalived 2.节点 node1 配置文件 vim /etc/keepalived/keepalived.conf 把资料里面的 keepalived.conf 修改之后替换 3.节点 node2 配置文件 需要修改 global_defs 的 router_id,如:nodeB 其次要修改 vrrp_instance_VI 中 state 为"BACKUP"; 最后要将 priority 设置为小于 100 的值 4.添加 haproxy_chk.sh (为了防止 HAProxy 服务挂掉之后 Keepalived 还在正常工作而没有切换到 Backup 上，所以这里需要编写一个脚本来检测 HAProxy 务的状态,当 HAProxy 服务挂掉之后该脚本会自动重启 HAProxy 的服务，如果不成功则关闭 Keepalived 服务，这样便可以切换到 Backup 继续工作) vim /etc/keepalived/haproxy_chk.sh(可以直接上传文件) 修改权限 chmod 777 /etc/keepalived/haproxy_chk.sh 5.启动 keepalive 命令(node1 和 node2 启动) systemctl start keepalived 6.观察 Keepalived 的日志 tail -f /var/log/messages -n 200 7.观察最新添加的 vip ip add show 8.node1 模拟 keepalived 关闭状态 systemctl stop keepalived 9.使用 vip 地址来访问 rabbitmq 集群 4、Federation Exchange 联邦交换机
5、Federation Queue 联邦队列
6、Shovel Federation 具备的数据转发功能类似，Shovel 够可靠、持续地从一个 Broker 中的队列(作为源端，即 source)拉取数据并转发至另一个 Broker 中的交换器(作为目的端，即 destination)。作为源端的队列和作 为目的端的交换器可以同时位于同一个 Broker，也可以位于不同的 Broker 上。Shovel 可以翻译为"铲子"， 是一种比较形象的比喻，这个"铲子"可以将消息从一方"铲子"另一方。Shovel 行为就像优秀的客户端应用 程序能够负责连接源和目的地、负责消息的读写及负责连接失败问题的处理</content></entry><entry><title>RabbitMQ（一）</title><url>https://zhang4014439175.github.io/post/rabbitmq%E4%B8%80/</url><categories><category>微服务</category><category>中间件</category></categories><tags><tag>RabbitMQ</tag><tag>削峰</tag><tag>解耦</tag><tag>异步</tag><tag>中间件</tag></tags><content type="html"> 一、简介功能 1、简介 什么是 MQ
消息队列 尚硅谷
MQ(message queue)，从字面意思上看，本质是个队列，FIFO 先入先出，只不过队列中存放的内容是 message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ 是一种非常常 见的上下游“逻辑解耦+物理解耦”的消息通信服务。使用了 MQ 之后，消息发送上游只需要依赖 MQ，不 用依赖其他服务。
建议使用更优秀的方案；MQ对业务系统侵入性高，使用cdc工具+kafka+flink，延迟低，业务系统0侵入，现在实时数仓都爱用这套，非常好用
2、功能 1）流量消峰 举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正 常时段我们下单一秒后就能返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的。
只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分 散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好。
好处：订单系统不宕机
坏处：访问比较慢
2）应用解耦 以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合 调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于 消息队列的方式后，系统间调用的问题会减少很多，比如物流系统因为发生故障，需要几分钟来修复。在 这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流 系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。
3）异步处理 有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可 以执行完，以前一般有两种方式，A 过一段时间去调用 B 的查询 api 查询。或者 A 提供一个 callback api， B 执行完之后调用 api 通知 A 服务。这两种方式都不是很优雅，使用消息总线，可以很方便解决这个问题， A 调用 B 服务后，只需要监听 B 处理完成的消息，当 B 处理完成后，会发送一条消息给 MQ，MQ 会将此 消息转发给 A 服务。这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样 B 服务也不 用做这些操作。A 服务还能及时的得到异步处理成功的消息。
3、分类 1.ActiveMQ
优点:单机吞吐量万级，时效性 ms 级，可用性高，基于主从架构实现高可用性，消息可靠性较低的概率丢失数据
缺点:官方社区现在对 ActiveMQ 5.x 维护越来越少，高吞吐量场景较少使用。 尚硅谷官网视频: http://www.gulixueyuan.com/course/322
2.Kafka
大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开 Kafka，这款为大数据而生的消息中间件， 以其百万级 TPS 的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥 着举足轻重的作用。目前已经被 LinkedIn，Uber, Twitter, Netflix 等大公司所采纳。
优点： 性能卓越，单机写入 TPS 约在百万条/秒，最大的优点，就是吞吐量高。时效性 ms 级可用性非 常高，kafka 是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用,消费者采 用 Pull 方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次;有优秀的第三方 Kafka Web 管理界面 Kafka-Manager;在日志领域比较成熟，被多家公司和多个开源项目使用;功能支持: 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用
缺点：Kafka 单机超过 64 个队列/分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消 息响应时间变长，使用短轮询方式，实时性取决于轮询间隔时间，消费失败不支持重试；支持消息顺序， 但是一台代理宕机后，就会产生消息乱序，社区更新较慢；
3.RocketMQ
RocketMQ 出自阿里巴巴的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一 些改进。被阿里巴巴广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发等场 景。
优点：单机吞吐量十万级，可用性非常高，分布式架构,消息可以做到 0 丢失**,MQ 功能较为完善，还是分布式的，扩展性好,支持10亿级别的消息堆积，不会因为堆积导致性能下降,源码是 java 我们可以自己阅 读源码，定制自己公司的 MQ
缺点:支持的客户端语言不多，目前是 java 及 c++，其中 c++不成熟;社区活跃度一般,没有在 MQ 核心中去实现 JMS 等接口,有些系统要迁移需要修改大量代码
4.RabbitMQ
2007 年发布，是一个在 AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。
优点：由于 erlang 语言的高并发特性，性能较好；吞吐量到万级，MQ 功能比较完备,健壮、稳定、易 用、跨平台、支持多种语言 如:Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等，支持 AJAX 文档齐全；开源提供的管理界面非常棒，用起来很好用,社区活跃度高;更新频率相当高
https://www.rabbitmq.com/news.html
缺点：商业版需要收费,学习成本较高
4、MQ 的选择 1.Kafka
Kafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集 和传输，适合产生大量数据的互联网服务的数据收集业务。大型公司建议可以选用，如果有日志采集功能， 肯定是首选 kafka 了。尚硅谷官网 kafka 视频连接 http://www.gulixueyuan.com/course/330/tasks
2.RocketMQ
天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削 峰，在大量交易涌入时，后端可能无法及时处理的情况。RoketMQ 在稳定性上可能更值得信赖，这些业务 场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。
3.RabbitMQ
结合 erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度也比较高，管理界面用起来十分方便，如果你的数据量没有那么大，中小型公司优先选择功能比较完备的 RabbitMQ。
二、RabbitMQ 1、RabbitMQ的概念 RabbitMQ 是一个消息中间件:它接受并转发消息。你可以把它当做一个快递站点，当你要发送一个包 裹时，你把你的包裹放到快递站，快递员最终会把你的快递送到收件人那里，按照这种逻辑 RabbitMQ 是 一个快递站，一个快递员帮你传递快件。RabbitMQ 与快递站的主要区别在于，它不处理快件而是接收， 存储和转发消息数据。
2、四大核心概念 1）生产者：
产生数据发送消息的程序是生产者
2）交换机：
交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息 推送到队列中。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃，这个得有交换机类型决定
3）队列：
队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存 储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可 以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。这就是我们使用队列的方式
4）消费者：
消费与接收具有相似的含义。消费者大多时候是一个等待接收消息的程序。请注意生产者，消费 者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。
3、六大核心模式 1）hello world简单模式
2）work queues工作队列
3）publish/subscribe发布订阅模式
4）routing路由模式
5）topics主体模式
6）publisher confirms发布确认模式
4、工作原理 Broker：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker
Virtual host：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似 于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出 多个 vhost，每个用户在自己的 vhost 创建 exchange/queue 等
Connection：publisher/consumer 和 broker 之间的 TCP 连接
Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程 序支持多线程，通常每个 thread 创建单独的 channel 进行通讯，AMQP method 包含了 channel id 帮助客 户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。Channel 作为轻量级的 Channel 极大减少了操作系统建立 TCP connection 的开销
Exchange：message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发 消息到 queue 中去。常用的类型有:direct (point-to-point), topic (publish-subscribe) and fanout(multicast)
Queue：消息最终被送到这里等待 consumer 取走
Binding：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保 存到 exchange 中的查询表中，用于 message 的分发依据
三、生产者消费者one 1、生产者
//创建一个连接工厂 ConnectionFactory factory = new ConnectionFactory(); factory.setHost("59.110.161.137"); factory.setUsername("lizi"); factory.setPassword("lizi"); //channel 实现了自动 close 接口 自动关闭 不需要显示关闭 Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); /** * 生成一个队列 * 1.队列名称 * 2.队列里面的消息是否持久化 默认消息存储在内存中 * 3.该队列是否只供一个消费者进行消费 是否进行共享 true 可以多个消费者消费 * 4.是否自动删除 最后一个消费者端开连接以后 该队列是否自动删除 true 自动删除 * 5.其他参数 */ channel.queueDeclare(QUEUE_NAME, false, false, false, null); String message = "hello world"; /** * 发送一个消息 * 1.发送到那个交换机 * 2.路由的 key 是哪个 * 3.其他的参数信息 * 4.发送消息的消息体 */ channel.basicPublish("", QUEUE_NAME, null, message.getBytes()); System.out.println("消息发送完毕"); 2、消费者
ConnectionFactory factory = new ConnectionFactory(); factory.setHost("59.110.161.137"); factory.setUsername("lizi"); factory.setPassword("lizi"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); System.out.println("等待接收消息...."); //推送的消息如何进行消费的接口回调 DeliverCallback deliverCallback=(consumerTag, delivery)->{ String message= new String(delivery.getBody()); System.out.println(message); }; //取消消费的一个回调接口 如在消费的时候队列被删除掉了 CancelCallback cancelCallback=(consumerTag)->{ System.out.println("消息消费被中断"); }; /** * 消费者消费消息 * 1.消费哪个队列 * 2.消费成功之后是否要自动应答 true 代表自动应答 false 手动应答 * * 3.消费者未成功消费的回调 * 4.消费者取消消费的回调 */ channel.basicConsume(QUEUE_NAME,true,deliverCallback,cancelCallback); 四、工作队列原理（简单模式、工作模式） 工作队列(又称任务队列)的主要思想是避免立即执行资源密集型任务，而不得不等待它完成。
相反我们安排任务在之后执行。我们把任务封装为消息并将其发送到队列。
在后台运行的工作进程将弹出任务并最终执行作业。
当有多个工作线程时，这些工作线程将一起处理这些任务。
生产者&mdash;&mdash;&mdash;队列&mdash;&mdash;&ndash;工作线程
​ 工作线程
​ 工作线程
注意事项：一个消息只能被处理一次，不可以处理多次
1）工具类 public class RabbitMqUtils { //得到一个连接的 channel public static Channel getChannel() throws Exception{ //创建一个连接工厂 ConnectionFactory factory = new ConnectionFactory(); factory.setHost("59.110.161.137"); factory.setUsername("lizi"); factory.setPassword("lizi"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); return channel; } } 1、工作队列案例 1）生产者 two Channel channel = RabbitMqUtils.getChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); //从控制台接收信息 Scanner scanner = new Scanner(System.in); while (scanner.hasNext()) { String next = scanner.next(); //1.发送到那个交换机 //2.路由的 key 是哪个，队列 //3.其他的参数信息 //4.发送消息的消息体，二进制 channel.basicPublish("", QUEUE_NAME,null, next.getBytes()); System.out.println("发送消息完成"); } 2）消费者 Channel channel = RabbitMqUtils.getChannel(); DeliverCallback deliverCallback = (consumerTag, message) -> { System.out.println("接收到的消息" + new String(message.getBody())); }; CancelCallback cancelCallback = (consumerTag) -> { System.out.println(consumerTag + "消息者取消消费接口回调逻辑"); }; System.out.println("C2等待接收消息。。。。。。。"); channel.basicConsume(QUEUE_NAME,true,deliverCallback,cancelCallback); 2、消息应答 消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长的任务并仅只完成 了部分突然它挂掉了，会发生什么情况。RabbitMQ 一旦向消费者传递了一条消息，便立即将该消 息标记为删除。在这种情况下，突然有个消费者挂掉了，我们将丢失正在处理的消息。以及后续 发送给该消费这的消息，因为它无法接收到。
为了保证消息在发送过程中不丢失，rabbitmq 引入消息应答机制，消息应答就是:消费者在接 收到消息并且处理该消息之后，告诉 rabbitmq 它已经处理了，rabbitmq 可以把该消息删除了。
1）自动应答（已接收到消息为准） 消息发送后立即被认为已经传送成功，这种模式需要在高吞吐量和数据传输安全性方面做权 衡,因为这种模式如果消息在接收到之前，消费者那边出现连接或者 channel 关闭，那么消息就丢 失了,当然另一方面这种模式消费者那边可以传递过载的消息，没有对传递的消息数量进行限制， 当然这样有可能使得消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，最终 使得内存耗尽，最终这些消费者线程被操作系统杀死，所以这种模式仅适用在消费者可以高效并 以某种速率能够处理这些消息的情况下使用。
2）手动应答 three Channel.basicAck ( 用于肯定确认 )
Channel.basicNack ( 用于否定确认 )
Channel.basicReject ( 用于否定确认 )
两个否定确认的区别是Channel.basicReject少一个参数 Multiple批处理
Channel channel = RabbitMqUtils.getChannel(); System.out.println("C2等待接收消息处理时间较长"); DeliverCallback deliverCallback = (consumerTag, message) -> { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println("接收到的消息 : " + new String(message.getBody(), "UTF-8")); //手动应答 channel.basicAck(message.getEnvelope().getDeliveryTag(), false); }; boolean autoAck = false; channel.basicConsume(ACK_QUEUE_NAME, autoAck, deliverCallback, (consumerTag -> { System.out.println(consumerTag + "消费者取消消费接口回调逻辑"); })); 3）批量应答 公司里面不使用批量应答，防止多个数据丢失
Channel.basicAck ( deliveryTag, false )
4）消息自动重新入队 如果消费者由于某些原因失去连接(其通道已关闭，连接已关闭或 TCP 连接丢失)，导致消息 未发送 ACK 确认，RabbitMQ 将了解到消息未完全处理，并将对其重新排队。如果此时其他消费者 可以处理，它将很快将其重新分发给另一个消费者。这样，即使某个消费者偶尔死亡，也可以确 保不会丢失任何消息。
五、持久化 刚刚我们已经看到了如何处理任务不丢失的情况，但是如何保障当 RabbitMQ 服务停掉以后消 息生产者发送过来的消息不丢失。默认情况下 RabbitMQ 退出或由于某种原因崩溃时，它忽视队列 和消息，除非告知它不要这样做。确保消息不会丢失需要做两件事:我们需要将队列和消息都标记为持久化。
1、队列如何实现持久化 之前我们创建的队列都是非持久化的，rabbitmq 如果重启的化，该队列就会被删除掉，如果 要队列实现持久化 需要在声明队列的时候把 durable 参数设置为持久化
但是需要注意的就是如果之前声明的队列不是持久化的，需要把原先队列先删除，或者重新 创建一个持久化的队列，不然就会出现错误
发消息的时候，生产者就需要通知这个消息需要持久化
2、消息实现持久化 要想让消息实现持久化需要在消息生产者修改代码，MessageProperties.PERSISTENT_TEXT_PLAIN 添加这个属性。
将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是 这里依然存在当消息刚准备存储在磁盘的时候 但是还没有存储完，消息还在缓存的一个间隔点。此时并没 有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。如果需要 更强有力的持久化策略，参考后边课件发布确认章节。
Channel channel = RabbitMqUtils.getChannel(); //这是声明队列的一系列参数，其具体的含义为： //queueDeclare（名字，是否持久化，独占的queue， 不使用时是否自动删除，其他参数）； boolean durable = true; channel.queueDeclare(ACK_QUEUE_NAME, durable, false, false, null); //channel.queueDeclare(ACK_QUEUE_NAME, null, false, false, null); //从控制台接收信息 Scanner scanner = new Scanner(System.in); while (scanner.hasNext()) { String message = scanner.next(); //设置生产者发送消息为持久化消息 channel.basicPublish("", ACK_QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes("UTF-8")); //channel.basicPublish("", ACK_QUEUE_NAME,null, message.getBytes("UTF-8")); System.out.println("发送消息完成" + message); } 3、不公平分发 ( 能者多劳 ) 在最开始的时候我们学习到 RabbitMQ 分发消息采用的轮训分发，但是在某种场景下这种策略并不是 很好，比方说有两个消费者在处理任务，其中有个消费者 1 处理任务的速度非常快，而另外一个消费者 2 处理速度却很慢，这个时候我们还是采用轮训分发的化就会到这处理速度快的这个消费者很大一部分时间 处于空闲状态，而处理慢的那个消费者一直在干活，这种分配方式在这种情况下其实就不太好，但是 RabbitMQ 并不知道这种情况它依然很公平的进行分发。
为了避免这种情况，我们可以设置参数 channel.basicQos(1)；
channel.basicQos(1); boolean autoAck = false; channel.basicConsume(ACK_QUEUE_NAME, autoAck, deliverCallback, (consumerTag -> { System.out.println(consumerTag + "消费者取消消费接口回调逻辑"); })); 意思就是如果这个任务我还没有处理完或者我还没有应答你，你先别分配给我，我目前只能处理一个 任务，然后 rabbitmq 就会把该任务分配给没有那么忙的那个空闲消费者，当然如果所有的消费者都没有完 成手上任务，队列还在不停的添加新任务，队列有可能就会遇到队列被撑满的情况，这个时候就只能添加 新的 worker 或者改变其他存储任务的策略。
4、预取值 ( 指定分配 ) 本身消息的发送就是异步发送的，所以在任何时候，channel 上肯定不止只有一个消息另外来自消费 者的手动确认本质上也是异步的。因此这里就存在一个未确认的消息缓冲区，因此希望开发人员能限制此 缓冲区的大小，以避免缓冲区里面无限制的未确认消息问题。这个时候就可以通过使用 basic.qos 方法设 置“预取计数”值来完成的。该值定义通道上允许的未确认消息的最大数量。一旦数量达到配置的数量， RabbitMQ 将停止在通道上传递更多消息，除非至少有一个未处理的消息被确认，例如，假设在通道上有未确认的消息 5、6、7，8，并且通道的预取计数设置为4，此时 RabbitMQ将不会在该通道上再传递任何消息，除非至少有一个未应答的消息被 ack。比方说 tag=6这个消息刚刚被确认ACK，RabbitMQ将会感知这个情况到并再发送一条消息。消息应答和QoS预取值对用户吞吐量有重大影响。通常，增加预取将提高向消费者传递消息的速度。虽然自动应答传输消息速率是最佳的，但是，在这种情况下已传递但尚未处理的消息的数量也会增加，从而增加了消费者的RAM消耗(随机存取存储器)应该小心使用具有无限预处理 的自动确认模式或手动确认模式，消费者消费了大量的消息如果没有确认的话，会导致消费者连接节点的 内存消耗变大，所以找到合适的预取值是一个反复试验的过程，不同的负载该值取值也不同 100 到 300 范 围内的值通常可提供最佳的吞吐量，并且不会给消费者带来太大的风险。预取值为1是最保守的。当然这将使吞吐量变得很低，特别是消费者连接延迟很严重的情况下，特别是在消费者连接等待时间较长的环境 中。对于大多数应用来说，稍微高一点的值将是最佳的。
//消费者里面设置 channel.basicQos(2); channel.basicQos(5); 六、发布确认（发布确认模式） ​ 发消息 rabbitmq
​ 生产者&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;- 队列hello 磁盘上达到持久化目标
要求队列持久化
设置要求队列中的消息也必须持久化
发布确认
生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式，所有在该信道上面发布的 消息都将会被指派一个唯一的 ID(从 1 开始)，一旦消息被投递到所有匹配的队列之后，broker 就会发送一个确认给生产者(包含消息的唯一 ID)，这就使得生产者知道消息已经正确到达目的队 列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker 回传 给生产者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外 broker 也可以设置 basic.ack 的 multiple 域，表示到这个序列号之前的所有消息都已经得到了处理。
confirm 模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信 道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调 方法来处理该确认消息，如果 RabbitMQ 因为自身内部错误导致消息丢失，就会发送一条 nack 消 息，生产者应用程序同样可以在回调方法中处理该 nack 消息。
boolean durable = true; channel.queueDeclare(ACK_QUEUE_NAME, durable, false, false, null); //channel.queueDeclare(ACK_QUEUE_NAME, null, false, false, null); //从控制台接收信息 Scanner scanner = new Scanner(System.in); while (scanner.hasNext()) { String message = scanner.next(); channel.basicPublish("", ACK_QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes("UTF-8")); //channel.basicPublish("", ACK_QUEUE_NAME,null, message.getBytes("UTF-8")); System.out.println("发送消息完成" + message); } 1、发布确认的策略 1）开启发布确认的方法 发布确认默认是没有开启的，如果要开启需要调用方法 confirmSelect，每当你要想使用发布 确认，都需要在 channel 上调用该方法
//开启发布确认 channel.confirmSelect(); 2）单个确认方法 这是一种简单的确认方式，它是一种同步确认发布的方式，也就是发布一个消息之后只有它 被确认发布，后续的消息才能继续发布,waitForConfirmsOrDie(long)这个方法只有在消息被确认 的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。
这种确认方式有一个最大的缺点就是:发布速度特别的慢，因为如果没有确认发布的消息就会 阻塞所有后续消息的发布，这种方式最多提供每秒不超过数百条发布消息的吞吐量。当然对于某 些应用程序来说这可能已经足够了。
3）批量确认方法 上面那种方式非常慢，与单个等待确认消息相比，先发布一批消息然后一起确认可以极大地 提高吞吐量，当然这种方式的缺点就是:当发生故障导致发布出现问题时，不知道是哪个消息出现 问题了，我们必须将整个批处理保存在内存中，以记录重要的信息而后重新发布消息。当然这种 方案仍然是同步的，也一样阻塞消息的发布。
4）异步确认发布 异步确认虽然编程逻辑比上两个要复杂，但是性价比最高，无论是可靠性还是效率都没得说， 他是利用回调函数来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否投递成功， 下面就让我们来详细讲解异步确认是怎么实现的。
5）如何处理异步未确认消息 最好的解决的解决方案就是把未确认的消息放到一个基于内存的能被发布线程访问的队列， 比如说用 ConcurrentLinkedQueue 这个队列在 confirm callbacks 与发布线程之间进行消息的传递。
6）以上三种方式速度对比 ①、单独发布消息 同步等待确认，简单，但吞吐量非常有限。
②、批量发布消息 批量同步等待确认，简单，合理的吞吐量，一旦出现问题但很难推断出是那条 消息出现了问题。
③、异步处理: 最佳性能和资源使用，在出现错误的情况下可以很好地控制，但是实现起来稍微难些
七、交换机（发布、订阅模式） 生产者 &mdash;&mdash;交换机&mdash;&mdash;&ndash;队列&mdash;&mdash;-消费者
​ |_________队列&mdash;&mdash;&mdash;消费者 一个消息由交换机分发给两个队列，可以被消费两次
在上一节中，我们创建了一个工作队列。我们假设的是工作队列背后，每个任务都恰好交付给一个消 费者(工作进程)。在这一部分中，我们将做一些完全不同的事情-我们将消息传达给多个消费者。这种模式 称为 ”发布/订阅”.
five
为了说明这种模式，我们将构建一个简单的日志系统。它将由两个程序组成:第一个程序将发出日志消 息，第二个程序是消费者。其中我们会启动两个消费者，其中一个消费者接收到消息后把日志存储在磁盘，另外一个消费者接收到消息后把消息打印在屏幕上，事实上第一个程序发出的日志消息将广播给所有消费者
1、概念 RabbitMQ 消息传递模型的核心思想是: 生产者生产的消息从不会直接发送到队列。实际上，通常生产者甚至都不知道这些消息传递传递到了哪些队列中。
相反，生产者只能将消息发送到交换机(exchange)，交换机工作的内容非常简单，一方面它接收来自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的消息。是应该把这些消息放到特定队列还是说把他们到许多队列中还是说应该丢弃它们。这就的由交换机的类型来决定。
1）交换机的类型 接（direct）路由、主题（topic）、标题（headers）、扇出（fanout）
2）无名exchange 在本教程的前面部分我们对 exchange 一无所知，但仍然能够将消息发送到队列。之前能实现的 原因是因为我们使用的是默认交换，我们通过空字符串(“”)进行标识。
channel.basicPublish("", "hello", null, message.getBytes()); 第一个参数是交换机的名称。空字符串表示默认或无名称交换机:消息能路由发送到队列中其实 是由 routingKey(bindingkey)绑定 key 指定的，如果它存在的话
2、临时队列 String queueName = channel.queueDeclare().getQueue()
3、绑定(bindings) 4、Fanout（扇出交换机）广播模式 1）简介
Fanout 这种类型非常简单。正如从名称中猜到的那样，它是将接收到的所有消息广播到它知道的 所有队列中。系统中默认有些 exchange 类型
与routingKey没有关系，会把消息发送到exchange所绑定的所有队列里面 2）实战
Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(EXCHANGE_NAME,"fanout"); String queueName = channel.queueDeclare().getQueue(); channel.queueBind(queueName, EXCHANGE_NAME, ""); System.out.println("等待接收消息，把接收到的消息打在屏幕"); DeliverCallback deliverCallback = (consumerTag, message) -> { System.out.println("1111111111111111控制台打印接收到的消息： " + new String(message.getBody(), "UTF-8")); }; channel.basicConsume(queueName, true, deliverCallback, consumerTag -> {}); 5、Direct exchange（路由模式） 1）回顾
在上一节中，我们构建了一个简单的日志记录系统。我们能够向许多接收者广播日志消息。在本 节我们将向其中添加一些特别的功能-比方说我们只让某个消费者订阅发布的部分消息。例如我们只把 严重错误消息定向存储到日志文件(以节省磁盘空间)，同时仍然能够在控制台上打印所有日志消息。
我们再次来回顾一下什么是 bindings，绑定是交换机和队列之间的桥梁关系。也可以这么理解: 队列只对它绑定的交换机的消息感兴趣。绑定用参数:routingKey 来表示也可称该参数为 binding key， 创建绑定我们用代码:
channel.queueBind(queueName, EXCHANGE_NAME, &ldquo;routingKey&rdquo;);
绑定之后的 意义由其交换类型决定。
2）介绍
上一节中的我们的日志系统将所有消息广播给所有消费者，对此我们想做一些改变，例如我们希 望将日志消息写入磁盘的程序仅接收严重错误(errros)，而不存储哪些警告(warning)或信息(info)日志 消息避免浪费磁盘空间。Fanout 这种交换类型并不能给我们带来很大的灵活性-它只能进行无意识的 广播，在这里我们将使用 direct 这种类型来进行替换，这种类型的工作方式是，消息只去到它绑定的 routingKey 队列中去。
3）多重绑定 six
4）实战
6、Topics（主题模式） 1）类型
在上一个小节中，我们改进了日志记录系统。我们没有使用只能进行随意广播的 fanout 交换机，而是 使用了 direct 交换机，从而有能实现有选择性地接收日志。
尽管使用 direct 交换机改进了我们的系统，但是它仍然存在局限性-比方说我们想接收的日志类型有 info.base 和 info.advantage，某个队列只想 info.base 的消息，那这个时候 direct 就办不到了。这个时候 就只能使用 topic 类型
2）要求
发送到类型是 topic 交换机的消息的 routing_key 不能随意写，必须满足一定的要求，它必须是一个单 词列表，以点号分隔开。这些单词可以是任意单词，比如说:&ldquo;stock.usd.nyse&rdquo;, &ldquo;nyse.vmw&rdquo;, &ldquo;quick.orange.rabbit&rdquo;.这种类型的。当然这个单词列表最多不能超过 255 个字节。
在这个规则列表中，其中有两个替换符是大家需要注意的 *(星号)可以代替一个单词 #(井号)可以替代零个或多个单词 *.orange.* *.*.rabbit lazy.# quick.orange.rabbit lazy.orange.elephant quick.orange.fox lazy.brown.fox lazy.pink.rabbit quick.brown.fox quick.orange.male.rabbit lazy.orange.male.rabbit 3）实战 seven
Q1&ndash;>绑定的是
中间带 orange 带 3 个单词的字符串(.orange.)
Q2&ndash;>绑定的是
最后一个单词是 rabbit 的 3 个单词(..rabbit) 第一个单词是 lazy 的多个单词(lazy.#)
4）注意
当队列绑定关系是下列这种情况时需要引起注意： 当一个队列绑定键是#,那么这个队列将接收所有数据，就有点像 fanout 了 如果队列绑定键当中没有#和*出现，那么该队列绑定类型就是 direct 了 八、死信队列 1、死信的概念 先从概念解释上搞清楚这个定义，死信，顾名思义就是无法被消费的消息，字面意思可以这样理 解，一般来说，producer 将消息投递到 broker 或者直接到 queue 里了，consumer 从 queue 取出消息 进行消费，但某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有 后续的处理，就变成了死信，有死信自然就有了死信队列。
应用场景:为了保证订单业务的消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息 消费发生异常时，将消息投入死信队列中.还有比如说: 用户在商城下单成功并点击去支付后在指定时 间未支付时自动失效
2、死信的来源 消息 TTL 过期 存活时间过期
队列达到最大长度(队列满了，无法再添加数据到 mq 中)
消息被拒绝(basic.reject 或 basic.nack)并且 requeue=false.
3、死信实战 1）代码架构图
![image-20220806220702974](/Users/mac/Library/Application Support/typora-user-images/image-20220806220702974.png)
2）实战
设置消息TTL过期
public class Consumer01 { //普通交换机名称 private static final String NORMAL_EXCHANGE = "normal_exchange"; //死信交换机名称 private static final String DEAD_EXCHANGE = "dead_exchange"; //普通队列 private static final String NORMAL_QUEUE = "normal_queue"; private static final String DEAD_QUEUE = "dead_queue"; public static void main(String[] args) throws Exception{ Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT); channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT); Map&lt;String, Object> arguments = new HashMap&lt;>(); arguments.put("x-dead-letter-exchange", DEAD_EXCHANGE); arguments.put("x-dead-letter-routing-key", "lisi"); arguments.put("x-message-ttl", 10000); channel.queueDeclare(NORMAL_QUEUE, false, false, false, arguments); channel.queueDeclare(DEAD_QUEUE, false, false, false, null); channel.queueBind(NORMAL_QUEUE, NORMAL_EXCHANGE, "zhangsan"); channel.queueBind(DEAD_QUEUE, DEAD_EXCHANGE, "lisi"); System.out.println("等待接收消息。。。"); DeliverCallback deliverCallback = (consummerTag, message) -> { System.out.println("Consumer01接收的消息：" + new String(message.getBody(), "UTF-8")); }; channel.basicConsume(NORMAL_QUEUE, true, deliverCallback, consumerTag -> {}); } } 队列达到最大长度
Map&lt;String, Object> arguments = new HashMap&lt;>(); arguments.put("x-dead-letter-exchange", DEAD_EXCHANGE); arguments.put("x-dead-letter-routing-key", "lisi"); //arguments.put("x-message-ttl", 10000); arguments.put("x-max-length", 6); channel.queueDeclare(NORMAL_QUEUE, false, false, false, arguments); channel.queueDeclare(DEAD_QUEUE, false, false, false, null);</content></entry><entry><title>docker（四）docker-compose</title><url>https://zhang4014439175.github.io/post/docker%E5%9B%9B/</url><categories><category>运维部署</category></categories><tags><tag>docker</tag><tag>容器化技术</tag><tag>网络</tag><tag>微服务</tag></tags><content type="html"> 一、dockerfile Dockerfile是用来构建Docker镜像的文本文件，是由一条条构建镜像所需的指令和参数构成的脚本。
1、介绍 编写dockerfile文件、docker build命令构建镜像、docker run依镜像运行容器实例
1）基础知识 ​ 每条保留字指令都必须为大写字母且后面要跟随至少一个参数
​ 指令按照从上到下，顺序执行
​ #表示注释
​ 每条指令都会创建一个新的镜像层并对镜像进行提交
2）Docker执行Dockerfile的大致流程 （1）docker从基础镜像运行一个容器
（2）执行一条指令并对容器作出修改
（3）执行类似docker commit的操作提交一个新的镜像层
（4）docker再基于刚提交的镜像运行一个新容器
（5）执行dockerfile中的下一条指令直到所有指令都执行完成
3）总结 从应用软件的角度来看，Dockerfile、Docker镜像与Docker容器分别代表软件的三个不同阶段，
Dockerfile是软件的原材料
Docker镜像是软件的交付品
Docker容器则可以认为是软件镜像的运行态，也即依照镜像运行的容器实例
Dockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石。
1 Dockerfile，需要定义一个Dockerfile，Dockerfile定义了进程需要的一切东西。Dockerfile涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程(当应用进程需要和系统服务和内核进程打交道，这时需要考虑如何设计namespace的权限控制)等等;
2 Docker镜像，在用Dockerfile定义一个文件之后，docker build时会产生一个Docker镜像，当运行 Docker镜像时会真正开始提供服务;
3 Docker容器，容器是直接提供服务的。
2、常用保留字 1总 0.7 0.7 0.7 0.2 0.2 0.2 0.3 0.7 0.5 0.4 0.3 1 1 1 0.5 9.4 8.4
​ 0.3 1 0.3 0.3 0.8 0.8 0.8 0.7 0.3 0.5 0.6 0.7 1 0.5 8.6
1）FROM 基础镜像，当前新镜像是基于哪个镜像的，指定一个已经存在的镜像作为模板，第一条必须是from 2）MAINTAINER 镜像维护者的姓名和邮箱地址 3）RUN shell
RUN &lt;命令行命令> RUN yum -y install vim exec
RUN ["可执行文件","参数1","参数2"] RUN ["./test.php","dev","offline"] 等价于 RUN RUN是在 docker build时运行
4）EXPOSE 对外暴露接口
5）WORKDIR 指定在创建容器后，终端默认登录的进来工作目录，一个落脚点
6）USER 指定该镜像以什么样的用户去执行，如果都不指定，默认是root
7）ENV 用来在构建镜像过程中设置环境变量
ENV MY_PATH /usr/mytest
这个环境变量可以在后续的任何RUN指令中使用，这就如同在命令前面指定了环境变量前缀一样；
也可以在其它指令中直接使用这些环境变量，
比如：WORKDIR $MY_PATH
8）ADD 将宿主机目录下的文件拷贝进镜像且会自动处理URL和解压tar压缩包
9）COPY 类似ADD，拷贝文件和目录到镜像中。
将从构建上下文目录中 &lt;源路径> 的文件/目录复制到新的一层的镜像内的 &lt;目标路径> 位置
COPY src dest
COPY [&ldquo;src&rdquo;, &ldquo;dest&rdquo;]
&lt;src源路径>：源文件或者源目录
&lt;dest目标路径>：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。
10）VOLUME - /var/lib/mysql # 映射容器内的 /var/lib/mysql 到宿主机的一个随机目录中 - /opt/data:/var/lib/mysql # 映射容器内的 /var/lib/mysql 到宿主机的 /opt/data - ./cache:/tmp/cache # 映射容器内的 /var/lib/mysql 到宿主机 compose 文件所在的位置 - ~/configs:/etc/configs/:ro # 映射容器宿主机的目录到容器中去, 权限只读 - datavolume:/var/lib/mysql # datavolume 为 volumes 顶级键定义的目录, 在此处直接调用 ———————————————— 版权声明：本文为CSDN博主「常名先生」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/jiangbenchu/article/details/102495531
容器数据卷，用于数据保存和持久化工作
11）CMD 指定容器启动后的要干的事情
Dockerfile 中可以有多个 CMD 指令，但只有最后一个生效，CMD 会被 docker run 之后的参数替换
shell格式
CMD &lt;命令> exec格式
exec ["可执行文件","参数1","参数2"...] 12）ENTRYPOINT 也是用来指定一个容器启动时要运行的命令
类似于 CMD 指令，但是ENTRYPOINT不会被docker run后面的命令覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序
命令：
​ ENTRYPOINT ["","","",&hellip;.]
ENTRYPOINT可以和CMD一起用，一般是 变参 才会使用 CMD ，这里的 CMD 等于是在给 ENTRYPOINT 传参。
当指定了ENTRYPOINT后，CMD的含义就发生了变化，不再是直接运行其命令而是将CMD的内容作为参数传递给ENTRYPOINT指令，他两个组合会变成
案例如下： 假设已通过 Dockerfile 构建了 nginx:test 镜像 ：
FROM nginx ENTRYPOINT ["nginx", "-c"] #定参 CMD ["/etc/nginx/nginx.conf"] #变参 是否传参 按照dockerfile编写执行 传参运行 Docker命令 docker run nginx:test docker run nginx:test -c /etc/nginx/ new.conf 衍生出的实际命令 nginx -c /etc/nginx/nginx.conf nginx -c /etc/nginx/ new.conf 3、Dockerfile编写Centos7 1）配置dockerfile
FROM centos MAINTAINER zzyy&lt;zzyybs@126.com>  ENV MYPATH /usr/local WORKDIR $MYPATH  #安装vim编辑器 RUN yum -y install vim #安装ifconfig命令查看网络IP RUN yum -y install net-tools #安装java8及lib库 RUN yum -y install glibc.i686 RUN mkdir /usr/local/java #ADD 是相对路径jar,把jdk-8u171-linux-x64.tar.gz添加到容器中,安装包必须要和Dockerfile文件在同一位置 ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/ #配置java环境变量 ENV JAVA_HOME /usr/local/java/jdk1.8.0_171 ENV JRE_HOME $JAVA_HOME/jre ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH ENV PATH $JAVA_HOME/bin:$PATH  EXPOSE 80  CMD echo $MYPATH CMD echo "success--------------ok" CMD /bin/bash 2）构建镜像文件
docker build -t centosjava8:1.5 .
最后一个.是当前目录的意思
3）运行
docker run -it centosjava8:1.5 /bin/bash
4、虚悬镜像 仓库名、标签都是的镜像，俗称dangling image
1 vim Dockerfile
from ubuntu CMD echo &lsquo;action is success&rsquo;
2 docker build .
5、作业Ubuntu 二、docker微服务实战 1、准备好module，打好jar包 2、dockerfile文件 # 基础镜像使用java FROM java:8 # 作者 MAINTAINER zzyy # VOLUME 指定临时文件目录为/tmp，在主机/var/lib/docker目录下创建了一个临时文件并链接到容器的/tmp VOLUME /tmp # 将jar包添加到容器中并更名为zzyy_docker.jar ADD docker_boot-0.0.1-SNAPSHOT.jar zzyy_docker.jar # 运行jar包 RUN bash -c 'touch /zzyy_docker.jar' ENTRYPOINT ["java","-jar","/zzyy_docker.jar"] #暴露6001端口作为微服务 EXPOSE 6001 3、上传到部署好docker的服务器上 4、构建镜像 docker build -t zzyy_docker:1.6 .
5、运行容器 docker run -d -p 6001:6001 zzyy_docker:1.6
6、访问测试 三、Docker网络 1、简介 1）docker不启动时，网络情况
​ ens33
​ lo
​ virbr0
在CentOS7的安装过程中如果有 选择相关虚拟化的的服务安装系统后 ，启动网卡时会发现有一个以网桥连接的私网地址的virbr0网卡(virbr0网卡：它还有一个固定的默认IP地址192.168.122.1)，是做虚拟机网桥的使用的，其作用是为连接其上的虚机网卡提供 NAT访问外网的功能。  我们之前学习Linux安装，勾选安装系统的时候附带了libvirt服务才会生成的一个东西，如果不需要可以直接将libvirtd服务卸载， yum remove libvirt-libs.x86_64 2）docker启动时，网络情况
​ docker0
2、常用命令 ​ docker network connect
​ docker network create
​ docker network disconnect
​ docker network inspect
​ docker network ls
​ docker network prune
​ docker network rm
3、作用 1）容器间的互联和通信以及端口映射
2）容器IP变动时候可以通过服务名直接网络通信而不受到影响
​ 通过网络服务名调用，不需要写死ip
4、网络模式 1）bridge
bridge模式：使用&ndash;network bridge指定，默认使用docker0
为每一个容器分配、设置IP等，并将容器连接到docker0
虚拟网桥默认为该模式
1 Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥(docker0)，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。  2 docker run 的时候，没有指定network的话默认使用的网桥模式就是bridge，使用的就是docker0 。 在宿主机ifconfig,就可以看到docker0和自己create的network(后面讲)eth0，eth1，eth2……代表网卡一，网卡二，网卡三…… ， lo代表127.0.0.1，即localhost ， inet addr用来表示网卡的IP地址  3 网桥docker0创建一对对等虚拟设备接口一个叫veth，另一个叫eth0，成对匹配。  3.1 整个宿主机的网桥模式都是docker0，类似一个交换机有一堆接口，每个接口叫veth，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通（这样一对接口叫veth pair）；  3.2 每个容器实例内部也有一块网卡，每个接口叫eth0；  3.3 docker0上面的每个veth匹配某个容器实例内部的eth0，两两配对，一一匹配。  通过上述，将宿主机上的所有容器都连接到这个内部网络上，两个容器在同一个网络下,会从这个网关下各自拿到分配的ip，此时两个容器的网络是互通的。  run镜像后exec进入容器，使用ip addr查看 2）host
host模式：使用&ndash;network host指定
虚拟机将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口
直接使用宿主机的 IP 地址与外界进行通信，不再需要额外进行NAT 转换。 容器将 不会获得 一个独立的Network Namespace， 而是和宿主机共用一个Network Namespace。 容器将不会虚拟出自己的网卡而是使用宿主机的IP和端口。 docker run -d -p 8083:8080 --network host --name tomcat83 billygoo/tomcat8-jdk8 docker run -d --network host --name tomcat83 billygoo/tomcat8-jdk8 问题：  docke启动时总是遇见标题中的警告 原因：  docker启动时指定--network=host或-net=host，如果还指定了-p映射端口，那这个时候就会有此警告， 并且通过-p设置的参数将不会起到任何作用，端口号会以主机端口号为主，重复时则递增。 解决:  解决的办法就是使用docker的其他网络模式，例如--network=bridge，这样就可以解决问题，或者直接无视。。。。O(∩_∩)O哈哈~ 3）none
none模式：使用&ndash;network none指定
容器有独立的network namespace，但并没有对其进行任何网络设置，如分配veth pair和网桥连接，IP等
docker run -d -p 8084:8080 --network none --name tomcat84 billygoo/tomcat8-jdk8 4）container
container模式：使用&ndash;network container:NAME或者容器ID指定
新创建的容器不会创建自己的网卡和配置自己的IP，而是和一个指定的容器共享IP，端口范围
container⽹络模式 新建的容器和已经存在的一个容器共享一个网络ip配置而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。 docker run -it --name alpine1 alpine /bin/sh docker run -it --network container:alpine1 --name alpine2 alpine /bin/sh 如果alpine1关闭，alpine2没有网络 5、新建自定义网络 docker network ls
docker network create
三、docker-compose容器编排 1、简介 Compose 是 Docker 公司推出的一个工具软件，可以管理多个 Docker 容器组成一个应用。你需要定义一个 YAML 格式的配置文件docker-compose.yml， 写好多个容器之间的调用关系 。然后，只要一个命令，就能同时启动/关闭这些容器
spring是对new对象进行管理，applicationContext.xml，对bean对象统一集中管理起来
&lt;bean id="" class=""> &lt;bean id="" class=""> &lt;bean id="" class=""> &lt;bean id="" class=""> docker-compose是对容器进行管理
docker run redis docker run mysql docker run nginx docker run orderms ok，前提条件mysql+redis要县启动 2、能干什么 docker建议我们每一个容器中只运行一个服务,因为docker容器本身占用资源极少,所以最好是将每个服务单独的分割开来但是这样我们又面临了一个问题？
如果我需要同时部署好多个服务,难道要每个服务单独写Dockerfile然后在构建镜像,构建容器,这样累都累死了,所以docker官方给我们提供了docker-compose多服务部署的工具
例如要实现一个Web微服务项目，除了Web服务容器本身，往往还需要再加上后端的数据库mysql服务容器，redis服务器，注册中心eureka，甚至还包括负载均衡容器等等。。。。。。
Compose允许用户通过一个单独的 docker-compose.yml模板文件 （YAML 格式）来定义 一组相关联的应用容器为一个项目（project）。
可以很容易地用一个配置文件定义一个多容器的应用，然后使用一条指令安装这个应用的所有依赖，完成构建。Docker-Compose 解决了容器与容器之间如何管理编排的问题。
3、compose常用命令 docker-compose -h # 查看帮助 docker-compose up # 启动所有 docker-compose服务 docker-compose up -d # 启动所有 docker-compose服务 并后台运行 docker-compose down # 停止并删除容器、网络、卷、镜像。 docker-compose exec yml里面的服务id # 进入容器实例内部 docker-compose exec docker-compose.yml文件中写的服务id /bin/bash docker-compose ps # 展示当前docker-compose编排过的运行的所有容器 docker-compose top # 展示当前docker-compose编排过的容器进程 docker-compose logs yml里面的服务id # 查看容器输出日志 docker-compose config # 检查配置 docker-compose config -q # 检查配置，有问题才有输出 docker-compose restart # 重启服务 docker-compose start # 启动服务 docker-compose stop # 停止服务 4、compose使用步骤 编写Dockerfile定义各个微服务应用并构建出对应的镜像文件
使用 docker-compose.yml 定义一个完整业务单元，安排好整体应用中的各个容器服务。
最后，执行docker-compose up命令 来启动并运行整个应用程序，完成一键部署上线
5、微服务工程 前后端jar包
mysql数据
docker run -p 3306:3306 --name mysql57 --privileged=true -v /zzyyuse/mysql/conf:/etc/mysql/conf.d -v /zzyyuse/mysql/logs:/logs -v /zzyyuse/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 docker build -t zzyy_docker:1.6 .
version: "3" serices: microService: image: lizi-security container_name: ms01 ports: - "8001:8001" volumes: - /app/microService:/data networks: - lizi_net depends_on: - redis - mysql redis:  image: redis:6.0.8  ports:  - "6379:6379"  volumes:  - /app/redis/redis.conf:/etc/redis/redis.conf  - /app/redis/data:/data  networks:  - lizi_net  command: redis-server /etc/redis/redis.conf   mysql:  image: mysql:5.7  environment:  MYSQL_ROOT_PASSWORD: '123456'  MYSQL_ALLOW_EMPTY_PASSWORD: 'no'  MYSQL_DATABASE: 'db2021'  MYSQL_USER: 'zzyy'  MYSQL_PASSWORD: 'zzyy123'  ports:  - "3306:3306"  volumes:  - /app/mysql/db:/var/lib/mysql  - /app/mysql/conf/my.cnf:/etc/my.cnf  - /app/mysql/init:/docker-entrypoint-initdb.d  networks:  - lizi_net  command: --default-authentication-plugin=mysql_native_password #解决外部无法访问  networks:  lizi_net: #新建网段 四、监控和统计 1、Portainer Portainer 是一款轻量级的应用，它提供了图形化界面，用于方便地管理Docker环境，包括单机环境和集群环境。
docker volume create portainer_date docker run -d -p 8000:8000 -p 9000:9000 --name portainer \ --restart=always \ #跟着docker重启 -v /var/run/docker.sock:/var/run/docker.sock \ -v portainer_data:/data \ portainer/portainer-ce:2.9.3 2、CAdvisor监控收集+InfluxDB存储数据+Granfana展示图表 version:'3.1'volumes:grafana_data:{}services:influxdb:image:tutum/influxdb:0.9 restart:always environment:- PRE_CREATE_DB=cadvisor ports:- "8083:8083"- "8086:8086"volumes:- ./data/influxdb:/data cadvisor:image:google/cadvisor links:- influxdb:influxsrv command:-storage_driver=influxdb -storage_driver_db=cadvisor -storage_driver_host=influxsrv:8086 restart:always ports:- "8080:8080"volumes:- /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro grafana:user:"104"image:grafana/grafana user:"104"restart:always links:- influxdb:influxsrv ports:- "3000:3000"volumes:- grafana_data:/var/lib/grafana environment:- HTTP_USER=admin - HTTP_PASS=admin - INFLUXDB_HOST=influxsrv - INFLUXDB_PORT=8086 - INFLUXDB_NAME=cadvisor - INFLUXDB_USER=root - INFLUXDB_PASS=root</content></entry><entry><title>docker（三）集群</title><url>https://zhang4014439175.github.io/post/docker%E4%B8%89%E5%AE%89%E8%A3%85mysql%E5%92%8Credis%E9%9B%86%E7%BE%A4/</url><categories><category>运维部署</category></categories><tags><tag>docker</tag><tag>容器化技术</tag><tag>集群</tag></tags><content type="html"> 一、mysql主从复制 新建主服务器容器实例3307
进入/mydata/mysql-master/conf目录下新建my.cnf
[mysqld] ## 设置server_id，同一局域网中需要唯一 server_id=101 ## 指定不需要同步的数据库名称 binlog-ignore-db=mysql ## 开启二进制日志功能 log-bin=mall-mysql-bin ## 设置二进制日志使用内存大小（事务） binlog_cache_size=1M ## 设置使用的二进制日志格式（mixed,statement,row） binlog_format=mixed ## 二进制日志过期清理时间。默认值为0，表示不自动清理。 expire_logs_days=7 ## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。 ## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致 slave_skip_errors=1062 修改完配置后重启master实例
进入mysql-master容器
master容器实例内创建数据同步用户
CREATE USER 'slave'@'%' IDENTIFIED BY '123456'; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%'; 新建从服务器容器实例3308
进入/mydata/mysql-slave/conf目录下新建my.cnf
[mysqld] ## 设置server_id，同一局域网中需要唯一 server_id=102 ## 指定不需要同步的数据库名称 binlog-ignore-db=mysql ## 开启二进制日志功能，以备Slave作为其它数据库实例的Master时使用 log-bin=mall-mysql-slave1-bin ## 设置二进制日志使用内存大小（事务） binlog_cache_size=1M ## 设置使用的二进制日志格式（mixed,statement,row） binlog_format=mixed ## 二进制日志过期清理时间。默认值为0，表示不自动清理。 expire_logs_days=7 ## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。 ## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致 slave_skip_errors=1062 ## relay_log配置中继日志 relay_log=mall-mysql-relay-bin ## log_slave_updates表示slave将复制事件写进自己的二进制日志 log_slave_updates=1 ## slave设置为只读（具有super权限的用户除外） read_only=1 修改完配置后重启slave实例
docker restart mysql-slave 在主数据库中查看主从同步状态
show master status; 进入mysql-slave容器
docker exec -it mysql-slave /bin/bash 在从数据库中配置主从复制
change master to master_host='宿主机ip', master_user='slave', master_password='123456', master_port=3307, master_log_file='mall-mysql-bin.000001', master_log_pos=617, master_connect_retry=30; 在从数据库中查看主从同步状态
show slave status \G; 在从数据库中开启主从同步
mysql中 start slave 查看从数据库状态发现已经同步
主从复制测试
docker run -p 3307:3306 --name mysql-master \ -v /mydata/mysql-master/log:/var/log/mysql \ -v /mydata/mysql-master/data:/var/lib/mysql \ -v /mydata/mysql-master/conf:/etc/mysql \ -e MYSQL_ROOT_PASSWORD=root \ -d mysql:5.7 二、redis集群 1、hash取余分区 2亿条记录就是2亿个k,v，我们单机不行必须要分布式多机，假设有3台机器构成一个集群，用户每次读写操作都是根据公式：
​ hash(key) % N个机器台数，计算出哈希值，用来决定数据映射到哪一个节点上。
1）优点 简单粗暴，直接有效，只需要预估好数据规划好节点，例如3台、8台、10台，就能保证一段时间的数据支撑。使用Hash算法让固定的一部分请求落到同一台服务器上，这样每台服务器固定处理一部分请求（并维护这些请求的信息），起到负载均衡+分而治之的作用。
2）缺点 原来规划好的节点，进行扩容或者缩容就比较麻烦了额，不管扩缩，每次数据变动导致节点有变动，映射关系需要重新进行计算，在服务器个数固定不变时没有问题，如果需要弹性扩容或故障停机的情况下，原来的取模公式就会发生变化：Hash(key)/3会变成Hash(key) /?。此时地址经过取余运算的结果将发生很大变化，根据公式获取的服务器也会变得不可控。
某个redis机器宕机了，由于台数数量变化，会导致hash取余全部数据重新洗牌。
2、一致性hash算法分区 一致性哈希算法在1997年由麻省理工学院中提出的，设计目标是为了解决
分布式缓存数据 变动和映射问题 ，某个机器宕机了，分母数量改变了，自然取余数不OK了。
提出一致性Hash解决方案。目的是当服务器个数发生变动时，尽量减少影响客户端到服务器的映射关系
1）一致性哈希环 一致性哈希算法必然有个hash函数并按照算法产生hash值，这个算法的所有可能哈希值会构成一个全量集，这个集合可以成为一个hash空间[0,2^32-1]，这个是一个线性空间，但是在算法中，我们通过适当的逻辑控制将它首尾相连(0 = 2^32),这样让它逻辑上形成了一个环形空间。
它也是按照使用取模的方法，前面笔记介绍的节点取模法是对节点（服务器）的数量进行取模。而一致性Hash算法是对2^32取模，简单来说， 一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环 ，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希环如下图：整个空间 按顺时针方向组织 ，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1， 0和2^32-1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环。
2）节点映射 将集群中各个IP节点映射到环上的某一个位置。
将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。假如4个节点NodeA、B、C、D，经过IP地址的 哈希函数 计算(hash(ip))，使用IP地址哈希后在环空间的位置如下：
3）key落到服务器的落键规则 当我们需要存储一个kv键值对时，首先计算key的hash值，hash(key)，将这个key使用相同的函数Hash计算出哈希值并确定此数据在环上的位置， 从此位置沿环顺时针“行走” ，第一台遇到的服务器就是其应该定位到的服务器，并将该键值对存储在该节点上。
如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。
①优点
一致性哈希算法的容错性
​ 假设Node C宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性Hash算法中，如果一台服务器不可用，则 受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据 ，其它不会受到影响。简单说，就是C挂了，受到影响的只是B、C之间的数据，并且这些数据会转移到D进行存储。
一致性哈希算法的扩展性
​ 数据量增加了，需要增加一台节点NodeX，X的位置在A和B之间，那收到影响的也就是A到X之间的数据，重新把A到X的数据录入到X上即可， 不会导致hash取余全部数据重新洗牌。
②缺点
Hash环的数据倾斜问题
一致性Hash算法在服务 节点太少时 ，容易因为节点分布不均匀而造成 数据倾斜 （被缓存的对象大部分集中缓存在某一台服务器上）问题，
3、hash槽分区 1） 为什么出现 哈希槽实质就是一个数组，数组[0,2^14 -1]形成hash slot空间。 16384
2） 能干什么 解决均匀分配的问题， 在数据和节点之间又加入了一层，把这层称为哈希槽（slot），用于管理数据和节点之间的关系 ，现在就相当于节点上放的是槽，槽里放的是数据。
槽解决的是粒度问题，相当于把粒度变大了，这样便于数据移动。
哈希解决的是映射问题，使用key的哈希值来计算所在的槽，便于数据分配。
3） 多少个hash槽 一个集群只能有16384个槽，编号0-16383（0-2^14-1）。这些槽会分配给集群中的所有主节点，分配策略没有要求。可以指定哪些编号的槽分配给哪个主节点。集群会记录节点和槽的对应关系。解决了节点和槽的关系后，接下来就需要对key求哈希值，然后对16384取余，余数是几key就落入对应的槽里。slot = CRC16(key) % 16384。以槽为单位移动数据，因为槽的数目是固定的，处理起来比较容易，这样数据移动问题就解决了。
为什么redis最大槽数是16384个？
4） hash槽计算 Redis 集群中内置了 16384 个哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。当需要在 Redis 集群中放置一个 key-value时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，也就是映射到某个节点上。如下代码，key之A 、B在Node2， key之C落在Node3上
SlotHash.getSlot("A") //6373 SlotHash.getSlot("B") //10374 SlotHash.getSlot("C") //14503 SlotHash.getSlot("HELLO")//866 4、redis集群 docker run -d --name redis-node-1 --net host --privileged=true -v /data/redis/share/redis-node-1:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6381  docker run -d --name redis-node-2 --net host --privileged=true -v /data/redis/share/redis-node-2:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6382  docker run -d --name redis-node-3 --net host --privileged=true -v /data/redis/share/redis-node-3:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6383  docker run -d --name redis-node-4 --net host --privileged=true -v /data/redis/share/redis-node-4:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6384  docker run -d --name redis-node-5 --net host --privileged=true -v /data/redis/share/redis-node-5:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6385  docker run -d --name redis-node-6 --net host --privileged=true -v /data/redis/share/redis-node-6:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6386 --net host 使用宿主机的IP和端口，默认 --privileged=true 获取宿主机root用户权限 -v /data/redis/share/redis-node-6:/data 容器卷，宿主机地址:docker内部地址 redis:6.0.8 redis镜像和版本号 --cluster-enabled yes 开启redis集群 --appendonly yes 开启持久化 --port 6386 redis端口号 redis-cli --cluster create 192.168.111.147:6381 192.168.111.147:6382 192.168.111.147:6383 192.168.111.147:6384 192.168.111.147:6385 192.168.111.147:6386 --cluster-replicas 1 5、数据读写存储 1）查看集群状态 redis-cli -p 6381 cluster info cluster nodes set k1 v1 分配槽时，分配到别的节点就会报错error redis-cli -p 6381 -c 另一种方法
redis -cli --cluster check 192.168.111.167:6381 2）使用集群命令 6、容错切换迁移 1号主节点宕机，4号从节点成为主节点。
1号主节点恢复，成为从节点。需要手动切换
7、主从扩容 1）步骤
​ 新建两个节点，一主一从
​ 进入容器内部
​ 将新增的6387节点作为master节点加入原集群
​ 检查集群情况第1次
​ 重新分派槽号
​ 检查集群情况第2次
​ 为主节点6387分配从节点6388
命令：redis-cli --cluster add-node ip:新slave端口 ip:新master端口 --cluster-slave --cluster-master-id 新主机节点ID  redis-cli --cluster add-node 192.168.111.147:6388 192.168.111.147:6387 --cluster-slave --cluster-master-id e4781f644d4a4e4d4b4d107157b9ba8144631451-------这个是6387的编号，按照自己实际情况 ​ 检查集群情况第3次
2）重新分配槽位
redis cli -- cluster reshard 192.168.111.117:6381 how many slots do you want to move (from 1 to 16384)? 4096 what is the receiving node ID? 新加节点的id redis -cli --cluster check 192.168.111.167:6381 每个节点平均给新节点分配了一点槽位
8、主从缩容 目的：6387和6388下线
检查集群情况1获得6388的节点ID
redis-cli --cluster check 192.168.111.147:6382 将6388删除，从集群中将4号从节点6388删除
命令：redis-cli --cluster del-node ip:从机端口 从机6388节点ID redis-cli --cluster del-node 192.168.111.147:6388 5d149074b7e57b802287d1797a874ed7a1a284a8 将6387的槽号清空，重新分配，本例将清出来的槽号都给6381
how many slots do you want to move (from 1 to 16384)? 4096 what is the receiving node ID? 新加节点的id 6381 source node #1: 要删除的master source node #2: done 检查集群情况第二次
将6387删除
redis-cli --cluster del-node 192.168.111.147:6388 5d149074b7e57b802287d1797a874ed7a1a284a8 检查集群情况第三次</content></entry><entry><title>docker（二）镜像</title><url>https://zhang4014439175.github.io/post/docker%E4%BA%8C/</url><categories><category>运维部署</category></categories><tags><tag>docker</tag><tag>容器化技术</tag><tag>镜像</tag></tags><content type="html"> 一、镜像分层 1、UnionFS（联合文件系统）： Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持 对文件系统的修改作为一次提交来一层层的叠加， 同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union 文件系统是 Docker 镜像的基础。 镜像可以通过分层来进行继承 ，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。
特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录
2、镜像加载原理 1）Docker镜像加载原理：
docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。
bootfs(boot file system)主要包含bootloader和kernel, bootloader主要是引导加载kernel, Linux刚启动时会加载bootfs文件系统， 在Docker镜像的最底层是引导文件系统bootfs。 这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。
2）rootfs (root file system) ，在bootfs之上 。包含的就是典型 Linux 系统中的 /dev, /proc, /bin, /etc 等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。
3）平时我们安装进虚拟机的CentOS都是好几个G，为什么docker这里才200M？？
对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供 rootfs 就行了。由此可见对于不同的linux发行版, bootfs基本是一致的, rootfs会有差别, 因此不同的发行版可以公用bootfs。
4）为什么docker要采用这种镜像分层？
镜像分层最大的一个好处就是共享资源，方便复制迁移，就是为了复用。
比如说有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像；
同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。
5）重点理解
Docker镜像层都是只读的，容器层是可写的
当容器启动时，一个新的可写层被加载到镜像的顶部。
这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。
当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。
所有对容器的改动 - 无论添加、删除、还是修改文件都只会发生在容器层中。只有容器层是可写的，容器层下面的所有镜像层都是只读的。
二、docker镜像commit docker run -it ubuntu /bin/bash
Apt-get update
Apt-get -y install vim
1、commit打包成新镜像 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]
docker commit -m=&ldquo;vim cmd add ok&rdquo; -a=&ldquo;zzm&rdquo; ed0196152932 lizi/ubuntu:0.1
Docker tag redis:6.8.0 192.168.0.1:5000/redis:6.8.0
2、docker公有库、私有库 私有库：阿里云容器镜像服务、实例列表、命名空间
创建私人仓库，然后根据步骤进行提交
3、本地镜像推阿里云，从阿里云拉镜像到本地 4、docker registry -p 3306/80 本机端口/docker 端口
apt-get update
apt-get install net - tools ifconfig
三、本地镜像推送到私有库 1、下载私有库 docker pull registry
2、运行私有库Registry，相当于本地有个私有Docker hub docker run -d -p 5000:5000 -v /zzyyuse/myregistry/:/tmp/registry &ndash;privileged=true registry
默认情况，仓库被创建在容器的/var/lib/registry目录下，建议自行用容器卷映射，方便于宿主机联调
3、curl验证私服库上有什么镜像 curl -XGET http://192.168.111.162:5000/v2/_catalog
4、将新镜像zzyyubuntu:1.2修改符合私服规范的Tag 按照公式： docker tag 镜像:Tag Host:Port/Repository:Tag
自己host主机IP地址，填写同学你们自己的，不要粘贴错误，O(∩_∩)O
使用命令 docker tag 将zzyyubuntu:1.2 这个镜像修改为192.168.111.162:5000/zzyyubuntu:1.2
docker tag zzyyubuntu:1.2 192.168.111.162:5000/zzyyubuntu:1.2
5、修改配置文件使之支持http docker默认允许http方式推送镜像，通过配置选项来取消这个限制，修改完成如果不生效，建议重启docker
别无脑照着复制，registry-mirrors 配置的是国内阿里提供的镜像加速地址，不用加速的话访问官网的会很慢。 2个配置中间有个逗号** ***&rsquo;,&rsquo;***别漏了 ，这个配置是json格式的。
//vim命令新增如下红色内容：vim /etc/docker/daemon.json {  "registry-mirrors": ["https://aa25jngu.mirror.aliyuncs.com"],  "insecure-registries": ["192.168.111.162:5000"] } 6、push推送到私服库 docker push 192.168.111.162:5000/zzyyubuntu:1.2
7、pull到本地并运行 docker pull 192.168.111.162:5000/zzyyubuntu:1.2
四、docker容器数据卷 &ndash;privileged=true 可以解决无权限问题，容器内才会有真正的权限
1、是什么 有点类似redis中的rdb和aof文件
将docker容器内的数据保存进宿主机的磁盘中
运行一个带有容器卷存储功能的容器实例
卷就是目录或文件，存在于一个或多个容器中，由docker挂载到容器，但不属于联合文件系统，因此能够绕过Union File System提供一些用于持续存储或共享数据的特性：
卷的设计目的就是 数据的持久化， 完全独立于容器的生存周期，因此Docker不会在容器删除时删除其挂载的数据卷
2、能干嘛 docker run -it &ndash;privileged=true -v /宿主机绝对路径目录:/容器内目录 镜像名
* 将运用与运行的环境打包镜像，run后形成容器实例运行 ，但是我们对数据的要求希望是 持久化的
Docker容器产生的数据，如果不备份，那么当容器实例删除后，容器内的数据自然也就没有了。
为了能保存数据在docker中我们使用卷。
特点：
1：数据卷可在容器之间共享或重用数据
2：卷中的更改可以直接实时生效，爽
3：数据卷中的更改不会包含在镜像的更新中
4：数据卷的生命周期一直持续到没有容器使用它为止
3、容器卷案例 1）宿主机vs容器之间映射添加容器卷
​ docker run -it &ndash;privileged=true -v /宿主机绝对路径目录:/容器内目录 镜像名
​ 获取容器/镜像的元数据
​ docker inspect [OPTIONS] NAME|ID [NAME|ID&hellip;]
2）读写规则映射添加说明
​ docker run -it &ndash;privileged=true -v /宿主机绝对路径目录:/容器内目录:rw 镜像名 //读写
​ rw读写
​ ro只读，限制容器，不限制宿主机
3）卷的继承和共享
​ docker run -it &ndash;privileged=true &ndash;volumes-from 父类 &ndash;name u2 ubuntu
docker run -it --privileged=true --volumes-from u1 --name u2 ubuntu 五、docker安装常用软件 1、总体步骤 1）搜索镜像
2）拉取镜像
3）查看镜像
4）启动镜像
5）停止容器
6）移除容器
2、Tomcat 1）删掉webapps
2）mv webapps.dist webapps
3）免修改版说明
​ docker pull billygoo/tomcat8-jdk8
​ docker run -d -p 8080:8080 &ndash;name mytomcat8 billygoo/tomcat8-jdk8
3、MySQL 1）how to use this image
本地3306停掉
docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 2）docker上默认编码集
SHOW VARIABLES LIKE &lsquo;character%&rsquo;
3）中文乱码、数据备份、敏感数据迁移
4）实战
docker run -d -p 3306:3306 --privileged=true -v /zzyyuse/mysql/log:/var/log/mysql -v /zzyyuse/mysql/data:/var/lib/mysql -v /zzyyuse/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 --name mysql mysql:5.7 新建my.cnf
[client] default_character_set=utf8 [mysqld] collation_server = utf8_general_ci character_set_server = utf8 4、Redis docker run -p 6379:6379 --name myr3 --privileged=true -v /app/redis/redis.conf:/etc/redis/redis.conf -v /app/redis/data:/data -d redis:6.0.8 redis-server /etc/redis/redis.conf</content></entry><entry><title>docker（一）基础</title><url>https://zhang4014439175.github.io/post/docker%E4%B8%80/</url><categories><category>运维部署</category></categories><tags><tag>docker</tag><tag>容器化技术</tag></tags><content type="html">  公司后端转为容器化部署。
一、docker为什么出现 希望平滑迁移
系统平滑移植，容器虚拟化技术
一次镜像，处处运行
解决了运行环境和配置问题的软件容器，方便做持续集成并有助于整体发布的容器虚拟化技术
1、Docker与传统虚拟机的不同之处
docker利用的是宿主机的内核，而不需要加载操作系统os内核
2、dockerHub安装docker镜像的仓库
3、容器是用镜像创建的运行实例，就像java中的类一样，镜像是静态的定义，容器是镜像运行时的实体。容器为镜像提供了一个标准的和隔离运行环境，他可以被启动、开始、停止、删除。每个容器都是互相隔离的、保证安全的平台。
二、docker 1、docker架构
镜像、容器、仓库
2、docker命令
build构建镜像
pull拉取远程仓库代码
run运行镜像文件
三、工作原理 docker守护进程运行在主机上，然后通过socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。
Docker 是一个 C/S 模式的架构，后端是一个松耦合架构，众多模块各司其职。
￼￼
1、用户是docker client与docker daemon建立连接docker
2、docker daemon作为docker架构中的主体部分，首先提供docker server的功能使其可以接受docker client的请求
3、docker engine执行docker内部的一系列工作，每一项工作都是以一个job的形式的存在。
4、job的运行过程中，当需要容器镜像时，则从docker registry中下载镜像，并通过镜像管理驱动Graph driber将下载镜像以Graph的形式存储
5、
6、
7、
四、docker安装 1、安装步骤 1）查看centos版本，cat/etc/redhat-release
2）安装gcc配置
3）安装gcc-c++配置
4）安装需要的软件包
yum isntall -y yum-utils sudo yum-config-manager \ --add-repo \ https://download.docker.com/inux/centos/docker-ce.repo 5）更新yum软件包索引
6）安装docker ce
7）启动docker
8）测试
9）卸载
2、阿里云镜像 是什么
注册阿里云账户
获得加速器地址连接
粘贴脚本直接执行
重启服务器
五、常用命令 1、帮助启动类命令 启动docker：systemctl start docker
停止docker：systemctl stop docker
重启docker：systemctl restart docker
开机启动：systemctl enale docker
查看docker状态：systemctl status docker
查看docker概要信息：docker info
查看docker总体帮助文档：docker &ndash;help
查看docker命令帮助文档：docker具体命令 &ndash;help
2、镜像类命令 1）docker images
repository：表示镜像的仓库源
image id：镜像id
created：镜像创建时间
size：镜像大小
tag：镜像的标签版本号
-a 所有镜像 -q只显示镜像id -aq
2）docker search 镜像名称
&ndash;limit：只列出N个镜像，默认25个
​ docker search &ndash;limit 5 redis
3）docker pull 镜像名称
​ docker pull redis
​ docker pull redis:latest
​ docker pull redis:6.0.8
4）docker system df 查看镜像/容器/数据卷/所占用的空间
5）docker rmi 镜像id
​ -f 强制
​ docker rmi -f ${docker images -qa}
6）gmall.镜像文件
3、谈谈docker虚悬镜像是什么？ 1）仓库名、标签名都是的镜像，俗称虚悬镜像 dockerfile中续讲
4、docker commit/push 六、容器命令 1、docker run &ndash;name=&ldquo;容器新名字&rdquo; 为容器指定一个名称
-d：后台运行容器并返回容器ID，也即启动守护式容器（后台运行）
-i：交互
-t：为容器重新分配一个伪输入终端，通常与-同时使用
-P：随机端口映射，大写P
-p：指定端口映射，小写p
/bin/bash：放在镜像后面的是命令，这里我们希望有个交互式Shell，因此用的是/bin/bash
exit：退出终端
2、查看容器 -a：所有在运行的容器
-l：最近创建的容器
-n：显示最近n个创建的容器
-q：静默模式，只显示容器编号
3、退出删除停止 exit：run进去，退出，容器停止
ctrl + p + q：run进去，退出，容器不停止
docker restart 重启容器id
docker stop 容器id或者容器名
docker rm 容器id
docker rm -f 容器id，强制删除
docker rm -f ${docker ps -a -q}
Docker ps -a -q | xargs docker rm
docker kill 容器id或容器名
4、运行 -it：前台交互式启动 ubutu
-d：后台守护启动 redis
5、日志 docker logs 容器id 编码开发微服务、上线部署容器化、时时刻刻要监控、devops
docker top 容器id
docker inspect 容器id 查看容器内部细节
6、进入正在运行的容器并以命令行进行交互 docker exec -it 容器id /bin/bash 在容器中打开新的终端，并且可以启动新的进程，用exit退出，不会导致容器的停止
docker attach 容器id 直接进入容器启动命令的终端，不会启动新的进程，用exit退出，会导致容器的停止
7、从容器内拷贝文件到主机上 docker cp 容器id：容器内路径 目的主机路径 从容器到主机
docker cp 目的主机路径 容器id：容器内路径 从主机到容器
8、导入导出容器 docker export 容器id > 文件名.tar
cat 文件名.tar | docker import - 镜像用户 / 镜像名：镜像版本号
​ cat a.tar | docker import - lizi/redis:6.8.0 导入为image镜像，需要docker run -it 镜像id /bin/bash</content></entry><entry><title>正则表达式</title><url>https://zhang4014439175.github.io/post/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url><categories><category>Java-Base</category><category>并发</category></categories><tags><tag>regex</tag><tag>正则表达式</tag></tags><content type="html">  飞梭平台专家知识模型的开发与调试需要用到正则，因此对正则进行学习。
一、正则表达式 System.out.println("-1234".matches("-?\\d+")); System.out.println("5678".matches("-?\\d+")); System.out.println("+911".matches("-?\\d+")); System.out.println("+911".matches("(-|\\+)?\\d+")); /* Output: true true false true */ (-|\+)?
这个正则表达式表示字符串的起始字符可能是一个 - 或 +，或者二者都没有（因为后面跟着 ? 修饰符）。因为字符 + 在正则表达式中有特殊的意义，所以必须使用 \ 将其转义，使之成为表达式中的一个普通字符。
String类还自带了一个非常有用的正则表达式工具——split() 方法，其功能是“将字符串从正则表达式匹配的地方切开。”
public class Splitting { public static String knights = "Then, when you have found the shrubbery, " + "you must cut down the mightiest tree in the " + "forest...with... a herring!"; public static void split(String regex) { System.out.println( Arrays.toString(knights.split(regex))); } public static void main(String[] args) { split(" "); // Doesn't have to contain regex chars split("\\W+"); // Non-word characters split("n\\W+"); // 'n' followed by non-words //按空格来划分字符串。 //一个非单词字符（如果 W 小写，\\w，则表示一个单词字符）。 //表示“字母n后面跟着一个或多个非单词字符。” } } /* Output: [Then,, when, you, have, found, the, shrubbery,, you, must, cut, down, the, mightiest, tree, in, the, forest...with..., a, herring!] [Then, when, you, have, found, the, shrubbery, you, must, cut, down, the, mightiest, tree, in, the, forest, with, a, herring] [The, whe, you have found the shrubbery, you must cut dow, the mightiest tree i, the forest...with... a herring!] */ 用正则表达式进行替换操作时，你可以只替换第一处匹配，也可以替换所有的匹配：
// strings/Replacing.java public class Replacing { static String s = Splitting.knights; public static void main(String[] args) { System.out.println(s.replaceFirst("f\\w+", "located")); //以字母 f 开头，后面跟一个或多个字母（注意这里的 w 是小写的）。并且只替换掉第一个匹配的部分，所以 “found” 被替换成 “located”。 System.out.println(s.replaceAll("shrubbery|tree|herring","banana")); //第二个表达式要匹配的是三个单词中的任意一个，因为它们以竖线分割表示“或”，并且替换所有匹配的部分。 } } /* Output: Then, when you have located the shrubbery, you must cut down the mightiest tree in the forest...with... a herring! Then, when you have found the banana, you must cut down the mightiest banana in the forest...with... a banana! */ 表达式 含义 B 指定字符B \xhh 十六进制值为0xhh的字符 \uhhhh 十六进制表现为0xhhhh的Unicode字符 \t 制表符Tab \n 换行符 \r 回车 \f 换页 \e 转义（Escape） 当你学会了使用字符类（character classes）之后，正则表达式的威力才能真正显现出来。以下是一些创建字符类的典型方式，以及一些预定义的类：
表达式 含义 . 任意字符 [abc] 包含a、b或c的任何字符（和`a [^abc] 除a、b和c之外的任何字符（否定） [a-zA-Z] 从a到z或从A到Z的任何字符（范围） [abc[hij]] a、b、c、h、i、j中的任意字符（与`a [a-z&amp;&amp;[hij]] 任意h、i或j（交） \s 空白符（空格、tab、换行、换页、回车） \S 非空白符（[^\s]） \d 数字（[0-9]） \D 非数字（[^0-9]） \w 词字符（[a-zA-Z_0-9]） \W 非词字符（[^\w]） for(String pattern : new String[]{ "Rudolph", "[rR]udolph", "[rR][aeiou][a-z]ol.*", "R.*" }) System.out.println("Rudolph".matches(pattern)); /* Output: true true true true */ 1、量词 贪婪型： 量词总是贪婪的，除非有其他的选项被设置。贪婪表达式会为所有可能的模式发现尽可能多的匹配。导致此问题的一个典型理由就是假定我们的模式仅能匹配第一个可能的字符组，如果它是贪婪的，那么它就会继续往下匹配。
勉强型： 用问号来指定，这个量词匹配满足模式所需的最少字符数。因此也被称作懒惰的、最少匹配的、非贪婪的或不贪婪的。
占有型： 目前，这种类型的量词只有在 Java 语言中才可用（在其他语言中不可用），并且也更高级，因此我们大概不会立刻用到它。当正则表达式被应用于 String 时，它会产生相当多的状态，以便在匹配失败时可以回溯。而“占有的”量词并不保存这些中间状态，因此它们可以防止回溯。它们常常用于防止正则表达式失控，因此可以使正则表达式执行起来更高效。
贪婪型 勉强型 占有型 如何匹配 X? X?? X?+ 一个或零个X X* X*? X*+ 零个或多个X X+ X+? X++ 一个或多个X X{n} X{n}? X{n}+ 恰好n次X X{n,} X{n,}? X{n,}+ 至少n次X X{n,m} X{n,m}? X{n,m}+ X至少n次，但不超过m次 A(B(C))D
中有三个组：组 0 是 ABCD，组 1 是 BC，组 2 是 C。
Matcher 对象提供了一系列方法，用以获取与组相关的信息：
public int groupCount() 返回该匹配器的模式中的分组数目，组 0 不包括在内。 public String group() 返回前一次匹配操作（例如 find()）的第 0 组（整个匹配）。 public String group(int i) 返回前一次匹配操作期间指定的组号，如果匹配成功，但是指定的组没有匹配输入字符串的任何部分，则将返回 null。 public int start(int group) 返回在前一次匹配操作中寻找到的组的起始索引。 public int end(int group) 返回在前一次匹配操作中寻找到的组的最后一个字符索引加一的值。 2、元字符 元字符：即为有特定含义的字符，常见的元字符如下
代码 说明 . 匹配除换行符以外的任意字符 \w 匹配字母或数字或下划线或汉字 \s 匹配任意的空白符 \d 匹配数字 \b 匹配单词的开始或结束 ^ 匹配字符串的开始（在集合字符里[^a]表示非（不匹配）的意思 $ 匹配字符串的结束 详解和示例：
（1）. 匹配任何任意字符 例如 . 可以匹配 1，n，*，+，- ,等
（2）\d\w\s 匹配第一个字符为数字，第二个字符为字母或数字、或下划线或汉字，第三字符为空格的字符串 例如：11 ，2a , 1_
（3）^\d\d\d$ 匹配三个全部都为数字的字符串 例如： 123,456,789
还可以用于验证输入的字符串是否符合qq（身份证号）的验证 ： 例如：^\d{8}$ 匹配8位数字的qq号，^\d{15}&amp;匹配15位均为数字的身份证号 （4）\bOlive\b 匹配单词Olive 例如： I Love Oliver and Olive .这个时候返回的是Olive 而不是Oliver,因为\b&hellip;.\b返回的匹配的单词
3、反义字符 反义字符：多用于查找除某个字符以外其他任意字符均可以的情况
常用的反义字符如下：
代码/语法 说明 \W 匹配任意不是字母，数字，下划线，汉字的字符 \S 匹配任意不是空白符的字符 \D 匹配任意非数字的字符 \B 匹配不是单词开头或结束的位置 [^x] 匹配除了x以外的任意字符 [^aeiou] 匹配除了aeiou这几个字母以外的任意字符 详解和示例：
（1）\W 匹配除字母、数字、下划线、汉字以为的字符形如 +，-，*
（2）\S 匹配除空格以外的任意字符形如：1，* ，）
（3）[^abcde]匹配除abcde以为的其他字符 如 e，f，g，h
4、限定字符 限定字符多用于重复匹配次数
常用的限定字符如下
代码/语法 说明 * 重复零次或更多次 + 重复一次或更多次 ? 重复零次或一次 {n} 重复n次 {n,} 重复n次或更多次 {n,m} 重复n到m次 详解和示例：
（1）\d* 匹配重复0次或多次数字 例如:可能为空 或 任意数字 （2,3。。。。）
（2）\d+ 匹配重复1次或多次数字 例如:可能为1个或多个数字 1,23,234,2345，&hellip;&hellip;..
（3）\d? 匹配重复次个或者一次数字 例如：可能为空或者任意的一个数字（1,2，。。。）
（4）\d{8}匹配重复8次数字 例如：123456768
（5）\d{4,}匹配重复至少4次数字 例如：1234,12345,124244,。。。。。
（6）^\d{8,11}$ 匹配重复8-11次数字 例如：12345678,123456789,1234567890,12345678901
5、转义字符 在实际的开发中，可能会遇到要比配元字符的情况，这个时候就需要进行字符转义，如元字符 . * \ 需要转换为. * \
例如： 需要匹配qq邮箱 \d{8,}+qq+.+com 在这里的. 就需要加斜杠
29,921,325 6、字符分枝 字符分枝多用于满足不同情况的选择，用“|”将不同的条件分割开来，比如有些固定电话区号有三位，有些有四位，这个时候可以采用字符分枝
例如：\d{3}-\d{8}|\d{4}-\d{8} 可以匹配两种不同长度区号的固定电话
下边的IP地址正则表达式也有用到字符分枝
7、字符分组 字符分组多用于将多个字符重复，主要通过使用小括号()来进行分组
形如：（\d\w){3} 重复匹配3次（\d\w)
常用于表示IP地址 形如： ((25[0-5]|2[0-4][0-9]|[0-1]\d\d).){3}(25[0-5]|2[0-4][0-9]|[0-1]\d\d)
解析：先把IP地址分为两部分一部分是123.123.123. 另一部分是123，又因Ip最大值为255，所以先使用分组，然后在组里边再进行选择，组里也有三部分，0-199,200-249,250-255，分别和上述的表达是对应，最后还要注意分组之后还要加上一个.，因为是元字符所以要转义故加上. 然后再把这部分整体看做是一个组，重复三次，再加上仅有数字的一组也就是不带.的那一组即可完成IP地址的校验
常用分组语法
分类 代码/语法 说明 (exp) 匹配exp,并捕获文本到自动命名的组里 捕 (?exp) 匹配exp,并捕获文本到名称为name的组里，也可以写成(?&rsquo;name&rsquo;exp) 获 (?:exp) 匹配exp,不捕获匹配的文本，也不给此分组分配组号 零 (?=exp) 匹配exp前面的位置 宽 (?&lt;=exp) 匹配exp后面的位置 断 (?!exp) 匹配后面跟的不是exp的位置 言 (?&lt;!exp) 匹配前面不是exp的位置 注释 (?#comment) 这种类型的分组不对正则表达式的处理产生任何影响，用于提供注释让人阅读 8、懒惰匹配和贪婪匹配 贪婪匹配：正则表达式中包含重复的限定符时，通常的行为是匹配尽可能多的字符。
懒惰匹配，有时候需要匹配尽可能少的字符。
例如： a.*b，它将会匹配最长的以a开始，以b结束的字符串。如果用它来搜索aabab的话，它会匹配整个字符串aabab。但是我们此时可能需要匹配的是ab这样的话就需要用到懒惰匹配了。懒惰匹配会匹配尽可能少的字符
常用的懒惰匹配限定符如下
代码/语法 说明 *? 重复任意次，但尽可能少重复 +? 重复1次或更多次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {n,m}? 重复n到m次，但尽可能少重复 {n,}? 重复n次以上，但尽可能少重复 9、后向引用 后向引用用于重复搜索前面某个分组匹配的文本。
使用小括号指定一个子表达式后，匹配这个子表达式的文本(也就是此分组捕获的内容)可以在表达式或其它程序中作进一步的处理。默认情况下，每个分组会自动拥有一个组号，规则是：从左向右，以分组的左括号为标志，第一个出现的分组的组号为1，第二个为2，以此类推
示例：\b(\w+)\b\s+\1\b可以用来匹配重复的单词，像go go, 或者kitty kitty。
这个表达式首先是一个单词，也就是单词开始处和结束处之间的多于一个的字母或数字(\b(\w+)\b)，这个单词会被捕获到编号为1的分组中，然后是1个或几个空白符(\s+)，最后是分组1中捕获的内容（也就是前面匹配的那个单词）(\1)。
你也可以自己指定子表达式的组名。要指定一个子表达式的组名，请使用这样的语法：(?\w+)(或者把尖括号换成&rsquo;也行：(?&lsquo;Word&rsquo;\w+)),这样就把\w+的组名指定为Word了。要反向引用这个分组捕获的内容，你可以使用\k,所以上一个例子也可以写成这样：\b(?\w+)\b\s+\k\b
10、零宽断言 有时候需要查找某些匹配之前或之后的东西，这个时候就需要用到们像\b,^,$那样用于指定一个位置，这个位置应该满足一定的条件(即断言)，因此它们也被称为零宽断言
(?=exp)也叫零宽度正预测先行断言，它断言自身出现的位置的后面能匹配表达式exp。比如 \b\w+(?=ing\b)，匹配以ing结尾的单词的前面部分(除了ing以外的部分)，如查找I&rsquo;m singing while you&rsquo;re dancing.时，它会匹配sing和danc。
(?&lt;=exp)也叫零宽度正回顾后发断言，它断言自身出现的位置的前面能匹配表达式exp。比如(?&lt;=\bre)\w+\b会匹配以re开头的单词的后半部分(除了re以外的部分)，例如在查找reading a book时，它匹配ading。
11、其他语法 12、常用的实用正则表达式整理 只能输入数字："^[0-9]*$"。
　只能输入n位的数字："^&ldquo;d{n}$"。
　只能输入至少n位的数字："^&ldquo;d{n,}$"。
　只能输入m~n位的数字：。"^&ldquo;d{m,n}$&rdquo;
　只能输入零和非零开头的数字："^(0|[1-9][0-9]*)$"。
　只能输入有两位小数的正实数："^[0-9]+(.[0-9]{2})?$"。
　只能输入有1~3位小数的正实数："^[0-9]+(.[0-9]{1,3})?$"。
　只能输入非零的正整数："^"+?[1-9][0-9]*$"。
　只能输入非零的负整数："^&rdquo;-[1-9][]0-9&rdquo;*$。
　只能输入长度为3的字符："^.{3}$"。
　只能输入由26个英文字母组成的字符串："^[A-Za-z]+$"。
　只能输入由26个大写英文字母组成的字符串："^[A-Z]+$"。
　只能输入由26个小写英文字母组成的字符串："^[a-z]+$"。
　只能输入由数字和26个英文字母组成的字符串："^[A-Za-z0-9]+$"。
　只能输入由数字、26个英文字母或者下划线组成的字符串："^&ldquo;w+$"。
　验证用户密码："^[a-zA-Z]&ldquo;w{5,17}$&ldquo;正确格式为：以字母开头，长度在6~18之间，只能包含字符、数字和下划线。
　验证是否含有^%&amp;’,;=?$&ldquo;&ldquo;等字符：&rdquo;[^%&amp;’,;=?$&ldquo;x22]+"。
　只能输入汉字："^[&ldquo;u4e00-&ldquo;u9fa5]{0,}$&rdquo;
　验证Email地址："^&ldquo;w+([-+.]&ldquo;w+)@&ldquo;w+([-.]&ldquo;w+)&rdquo;.&ldquo;w+([-.]&ldquo;w+)*$"。
　验证InternetURL："^http://([&ldquo;w-]+&rdquo;.)+[&ldquo;w-]+(/[&ldquo;w-./?%&amp;=]*)?$"。
　验证电话号码："^(&rdquo;(&ldquo;d{3,4}-)|&ldquo;d{3.4}-)?&ldquo;d{7,8}$&ldquo;正确格式为：&ldquo;XXX-XXXXXXX&rdquo;、&ldquo;XXXX- XXXXXXXX&rdquo;、&ldquo;XXX-XXXXXXX&rdquo;、&ldquo;XXX-XXXXXXXX&rdquo;、&ldquo;XXXXXXX"和"XXXXXXXX&rdquo;。
　验证身份证号(15位或18位数字)："^&ldquo;d{15}|&ldquo;d{18}$"。
　验证一年的12个月："^(0?[1-9]|1[0-2])$&ldquo;正确格式为：&ldquo;01"～"09"和"1"～"12&rdquo;。
　验证一个月的31天："^((0?[1-9])|((1|2)[0-9])|30|31)$&ldquo;正确格式为;&ldquo;01"～"09"和"1"～"31&rdquo;。</content></entry><entry><title>Java进阶-JVM（二）</title><url>https://zhang4014439175.github.io/post/jvm%E4%BA%8C/</url><categories><category>Java-Advanced</category></categories><tags><tag>Java</tag><tag>JVM</tag><tag>内存</tag><tag>垃圾回收</tag></tags><content type="html"> 一、GC Roots 是什么？ 哪些对象可以作为 GC Root？看完秒懂！
什么是是可达性分析算法？
现代虚拟机基本都是采用可达性分析算法来判断对象是否存活，可达性算法的原理是以一系列叫做 GC Root 的对象为起点出发，引出它们指向的下一个节点，再以下个节点为起点，引出此节点指向的下一个结点。这样通过 GC Root 串成的一条线就叫引用链），直到所有的结点都遍历完毕,如果相关对象不在任意一个以 GC Root 为起点的引用链中，则这些对象会被判断为垃圾对象,会被 GC 回收。
如图示，如果用可达性算法即可解决上述循环引用的问题，因为从GC Root 出发没有到达 a,b,所以 a，b 可回收。
a, b 对象可回收，就一定会被回收吗?
并不是，对象的 finalize 方法给了对象一次垂死挣扎的机会，当对象不可达（可回收）时，当发生GC时，会先判断对象是否执行了 finalize 方法，如果未执行，则会先执行 finalize 方法，我们可以在此方法里将当前对象与 GC Roots 关联，这样执行 finalize 方法之后，GC 会再次判断对象是否可达，如果不可达，则会被回收，如果可达，则不回收！
注意： finalize 方法只会被执行一次，如果第一次执行 finalize 方法此对象变成了可达确实不会回收，但如果对象再次被 GC，则会忽略 finalize 方法，对象会被回收！这一点切记!
GC Roots 到底是什么东西呢，哪些对象可以作为 GC Root 呢？
虚拟机栈（栈帧中的本地变量表）中引用的对象 本地方法栈中 JNI（即一般说的 Native 方法）引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 便于记忆，称他为两栈两方法！下面我们一一介绍一下：
1、虚拟机栈中引用的对象
如下代码所示，a 是栈帧中的本地变量，当 a = null 时，由于此时 a 充当了 GC Root 的作用，a 与原来指向的实例 new Test() 断开了连接，所以对象会被回收。
public static void main(String[] args) { 2、方法区中类静态属性引用的对象
如下代码所示，当栈帧中的本地变量 a = null 时，由于 a 原来指向的对象与 GC Root (变量 a) 断开了连接，所以 a 原来指向的对象会被回收，而由于我们给 s 赋值了变量的引用，s 在此时是类静态属性引用，充当了 GC Root 的作用，它指向的对象依然存活!
public static Test s; public static void main(String[] args) { 3、方法区中常量引用的对象
如下代码所示，常量 s 指向的对象并不会因为 a 指向的对象被回收而回收
public static final Test s = new Test(); public static void main(String[] args) { Test a = new Test(); 4、本地方法栈中 JNI 引用的对象
这是简单给不清楚本地方法为何物的童鞋简单解释一下：所谓本地方法就是一个 java 调用非 java 代码的接口，该方法并非 Java 实现的，可能由 C 或 Python等其他语言实现的， Java 通过 JNI 来调用本地方法， 而本地方法是以库文件的形式存放的（在 WINDOWS 平台上是 DLL 文件形式，在 UNIX 机器上是 SO 文件形式）。通过调用本地的库文件的内部方法，使 JAVA 可以实现和本地机器的紧密联系，调用系统级的各接口方法，还是不明白？见文末参考，对本地方法定义与使用有详细介绍。
当调用 Java 方法时，虚拟机会创建一个栈桢并压入 Java 栈，而当它调用的是本地方法时，虚拟机会保持 Java 栈不变，不会在 Java 栈祯中压入新的祯，虚拟机只是简单地动态连接并直接调用指定的本地方法。
JNIEXPORT void JNICALL Java_com_pecuyu_jnirefdemo_MainActivity_newStringNative(JNIEnv *env, jobject instance，jstring jmsg) { jclass jc = (*env)->FindClass(env, STRING_PATH); 如上代码所示，当 java 调用以上本地方法时，jc 会被本地方法栈压入栈中, jc 就是我们说的本地方法栈中 JNI 的对象引用，因此只会在此本地方法执行完成后才会被释放。
二、四种引用 1.强引用
我们平日里面的用到的new了一个对象就是强引用，例如 Object obj = new Object();当JVM的内存空间不足时，宁愿抛出OutOfMemoryError使得程序异常终止也不愿意回收具有强引用的存活着的对象！
记住是存活着，不可能是你new一个对象就永远不会被GC回收。当一个普通对象没有其他引用关系，只要超过了引用的作用域或者显示的将引用赋值为null时，你的对象就表明不是存活着，这样就会可以被GC回收了。当然回收的时间是不一定的具体得看GC回收策略。
2.软引用
软引用的生命周期比强引用短一些。软引用是通过SoftReference类实现的。
Objectobj=``new``Object();``SoftReferencesoftObj=``new``SoftReference(obj);``obj=``null``；``//去除强引用这样就是一个简单的软引用使用方法。通过get()方法获取对象。当JVM认为内存空间不足时，就回去试图回收软引用指向的对象，也就是说在JVM抛出OutOfMemoryError之前，会去清理软引用对象。软引用可以与引用队列(ReferenceQueue)联合使用。
Objectobj=``new``Object();``ReferenceQueuequeue=``new``ReferenceQueue();``SoftReferencesoftObj=``new``SoftReference(obj,queue);``obj=``null``；``//去除强引用当softObj软引用的obj被GC回收之后，softObj 对象就会被塞到queue中，之后我们可以通过这个队列的poll()来检查你关心的对象是否被回收了，如果队列为空，就返回一个null。反之就返回软引用对象也就是softObj。
软引用一般用来实现内存敏感的缓存，如果有空闲内存就可以保留缓存，当内存不足时就清理掉，这样就保证使用缓存的同时不会耗尽内存。例如图片缓存框架中缓存图片就是通过软引用的。
3.弱引用
弱引用是通过WeakReference类实现的，它的生命周期比软引用还要短,也是通过get()方法获取对象。
Objectobj=``new``Object();``WeakReferenceweakObj=``new``WeakReference(obj);``obj=``null``；``//去除强引用在GC的时候，不管内存空间足不足都会回收这个对象，同样也可以配合ReferenceQueue 使用，也同样适用于内存敏感的缓存。ThreadLocal中的key就用到了弱引用。
4.幻象引用
也称虚引用，是通过PhantomReference类实现的。任何时候可能被GC回收,就像没有引用一样。
Objectobj=``new``Object();``ReferenceQueuequeue=``new``ReferenceQueue();``PhantomReferencephantomObj=``new``PhantomReference(obj,queue);``obj=``null``；``//去除强引用无法通过虚引用访问对象的任何属性或者函数。那就要问了要它有什么用？虚引用仅仅只是提供了一种确保对象被finalize以后来做某些事情的机制。比如说这个对象被回收之后发一个系统通知啊啥的。虚引用是必须配合ReferenceQueue 使用的，具体使用方法和上面提到软引用的一样。主要用来跟踪对象被垃圾回收的活动。</content></entry><entry><title>Java进阶-JVM（一）</title><url>https://zhang4014439175.github.io/post/jvm%E4%B8%80/</url><categories><category>Java-Advanced</category></categories><tags><tag>Java</tag><tag>JVM</tag><tag>内存</tag><tag>垃圾回收</tag></tags><content type="html"> 一、内存结构 1、程序计数器 1.1、定义 程序计数器是一块较小的内存空间，是当前线程正在执行的那条字节码指令的地址。若当前线程正在执行的是一个本地方法，那么此时程序计数器为Undefined。
1.2、作用 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制。 在多线程情况下，程序计数器记录的是当前线程执行的位置，从而当线程切换回来时，就知道上次线程执行到哪了。 1.3、特点 是一块较小的内存空间。 线程私有，每条线程都有自己的程序计数器。 生命周期：随着线程的创建而创建，随着线程的结束而销毁。 是唯一一个不会出现 OutOfMemoryError 的内存区域。 2、java虚拟机栈 Java 虚拟机栈是描述 Java 方法运行过程的内存模型。
Java 虚拟机栈会为每一个即将运行的 Java 方法创建一块叫做“栈帧”的区域，用于存放该方法运行过程中的一些信息，如：
局部变量表 操作数栈 动态链接 方法出口信息 压栈出栈过程：
当方法运行过程中需要创建局部变量时，就将局部变量的值存入栈帧中的局部变量表中。
Java 虚拟机栈的栈顶的栈帧是当前正在执行的活动栈，也就是当前正在执行的方法，PC 寄存器也会指向这个地址。只有这个活动的栈帧的本地变量可以被操作数栈使用，当在这个栈帧中调用另一个方法，与之对应的栈帧又会被创建，新创建的栈帧压入栈顶，变为当前的活动栈帧。
方法结束后，当前栈帧被移出，栈帧的返回值变成新的活动栈帧中操作数栈的一个操作数。如果没有返回值，那么新的活动栈帧中操作数栈的操作数没有变化。
2.1、局部变量表 1）局部变量表也被称为局部变量数组或者本地变量表
2）关于slot的理解
局部变量表中最基础的存储单元为slot（变量槽）
在局部变量表中，32位以内的类型只占用一个slot（包括returnAddress类型），64位的类型（long和double）占用两个slot。
byte、short、char在存储前被转换为int，boolean也被转换为int，0表示false，非0表示true。
long和double则占据两个slot。
当前帧的构造方法或者实例方法创建时，那么该对象引用this将会存放在index为0的slot处（下面的jclasslib会有体现），其余的参数按照参数表顺序继续排序。
3）局部变量表
因为局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据的安全问题。 局部变量表所需的容量大小是在编译期确定下来的。保存在Code属性的maximum local variables数据项中，在这个方法运行期间不会改变局部变量的大小。 方法嵌套的次数由栈的大小决定。 局部变量表中的变量只能在当前方法调用中有效。当方法调用结束时，随着方法栈帧的销毁，局部变量表也会随之销毁。 局部变量表中的变量是重要的垃圾回收节点，只要被局部变量表中直接或者间接引用的对象都不会被回收（垃圾回收中的根搜索算法，在JAVA中都是使用这种算法进行垃圾回收），局部变量表中的变量若不存在，则指向堆空间的指针消失，顾堆空间中的垃圾被回收。 2.2、操作数栈 栈顶缓存技术：由于操作数是存储在内存中，频繁的进行内存读写操作影响执行速度，将栈顶元素全部缓存到物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率。 每一个操作数栈会拥有一个明确的栈深度，用于存储数值，最大深度在编译期就定义好。32bit 类型占用一个栈单位深度，64bit 类型占用两个栈单位深度操作数栈。 并非采用访问索引方式进行数据访问，而是只能通过标准的入栈、出栈操作完成一次数据访问。 2.3、方法的调用 静态链接：当一个字节码文件被装载进 JVM 内部时，如果被调用的目标方法在编译期可知，且运行时期间保持不变，这种情况下降调用方的符号引用转为直接引用的过程称为静态链接。 动态链接：如果被调用的方法无法在编译期被确定下来，只能在运行期将调用的方法的符号引用转为直接引用，这种引用转换过程具备动态性，因此被称为动态链接。 方法绑定 早期绑定：被调用的目标方法如果在编译期可知，且运行期保持不变。 晚期绑定：被调用的方法在编译期无法被确定，只能够在程序运行期根据实际的类型绑定相关的方法。 非虚方法：如果方法在编译期就确定了具体的调用版本，则这个版本在运行时是不可变的，这样的方法称为非虚方法静态方法。私有方法，final 方法，实例构造器，父类方法都是非虚方法，除了这些以外都是虚方法。 虚方法表：面向对象的编程中，会很频繁的使用动态分配，如果每次动态分配的过程都要重新在类的方法元数据中搜索合适的目标的话，就可能影响到执行效率，因此为了提高性能，JVM 采用在类的方法区建立一个虚方法表，使用索引表来代替查找。 每个类都有一个虚方法表，表中存放着各个方法的实际入口。 虚方法表会在类加载的链接阶段被创建，并开始初始化，类的变量初始值准备完成之后，JVM 会把该类的方法也初始化完毕。 方法重写的本质 找到操作数栈顶的第一个元素所执行的对象的实际类型，记做 C。如果在类型 C 中找到与常量池中描述符和简单名称都相符的方法，则进行访问权限校验。 如果通过则返回这个方法的直接引用，查找过程结束；如果不通过，则返回 java.lang.IllegalAccessError 异常。 否则，按照继承关系从下往上依次对 C 的各个父类进行上一步的搜索和验证过程。 如果始终没有找到合适的方法，则抛出 java.lang.AbstractMethodError 异常。 Java 中任何一个普通方法都具备虚函数的特征（运行期确认，具备晚期绑定的特点），C++ 中则使用关键字 virtual 来显式定义。如果在 Java 程序中，不希望某个方法拥有虚函数的特征，则可以使用关键字 final 来标记这个方法。
2.4、本地方法栈（C 栈） 本地方法栈的定义：
本地方法栈是为 JVM 运行 Native 方法准备的空间，由于很多 Native 方法都是用 C 语言实现的，所以它通常又叫 C 栈。它与 Java 虚拟机栈实现的功能类似，只不过本地方法栈是描述本地方法运行过程的内存模型。
栈帧变化过程：
本地方法被执行时，在本地方法栈也会创建一块栈帧，用于存放该方法的局部变量表、操作数栈、动态链接、方法出口信息等。
方法执行结束后，相应的栈帧也会出栈，并释放内存空间。也会抛出 StackOverFlowError 和 OutOfMemoryError 异常。
如果 Java 虚拟机本身不支持 Native 方法，或是本身不依赖于传统栈，那么可以不提供本地方法栈。如果支持本地方法栈，那么这个栈一般会在线程创建的时候按线程分配。
2.5、堆 堆的定义：
堆是用来存放对象的内存空间，几乎所有的对象都存储在堆中。
堆的特点：
线程共享，整个 Java 虚拟机只有一个堆，所有的线程都访问同一个堆。而程序计数器、Java 虚拟机栈、本地方法栈都是一个线程对应一个。 在虚拟机启动时创建。 是垃圾回收的主要场所。 堆可分为新生代（Eden 区：From Survior，To Survivor）、老年代。 Java 虚拟机规范规定，堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的。 关于 Survivor s0，s1 区: 复制之后有交换，谁空谁是 to。 不同的区域存放不同生命周期的对象，这样可以根据不同的区域使用不同的垃圾回收算法，更具有针对性。
堆的大小既可以固定也可以扩展，但对于主流的虚拟机，堆的大小是可扩展的，因此当线程请求分配内存，但堆已满，且内存已无法再扩展时，就抛出 OutOfMemoryError 异常。
Java 堆所使用的内存不需要保证是连续的。而由于堆是被所有线程共享的，所以对它的访问需要注意同步问题，方法和对应的属性都需要保证一致性。
新生代与老年代：
老年代比新生代生命周期长。 新生代与老年代空间默认比例 1:2：JVM 调参数，XX:NewRatio=2，表示新生代占 1，老年代占 2，新生代占整个堆的 1/3。 HotSpot 中，Eden 空间和另外两个 Survivor 空间缺省所占的比例是：8:1:1。 几乎所有的 Java 对象都是在 Eden 区被 new 出来的，Eden 放不了的大对象，就直接进入老年代了。 对象分配过程：
new 的对象先放在 Eden 区，大小有限制 如果创建新对象时，Eden 空间填满了，就会触发 Minor GC，将 Eden 不再被其他对象引用的对象进行销毁，再加载新的对象放到 Eden 区，特别注意的是 Survivor 区满了是不会触发 Minor GC 的，而是 Eden 空间填满了，Minor GC 才顺便清理 Survivor 区 将 Eden 中剩余的对象移到 Survivor0 区 再次触发垃圾回收，此时上次 Survivor 下来的，放在 Survivor0 区的，如果没有回收，就会放到 Survivor1 区 再次经历垃圾回收，又会将幸存者重新放回 Survivor0 区，依次类推 默认是 15 次的循环，超过 15 次，则会将幸存者区幸存下来的转去老年区 jvm 参数设置次数 : -XX:MaxTenuringThreshold=N 进行设置 频繁在新生区收集，很少在养老区收集，几乎不在永久区/元空间搜集 Full GC /Major GC 触发条件：
显示调用System.gc()，老年代的空间不够，方法区的空间不够等都会触发 Full GC，同时对新生代和老年代回收，FUll GC 的 STW 的时间最长，应该要避免 在出现 Major GC 之前，会先触发 Minor GC，如果老年代的空间还是不够就会触发 Major GC，STW 的时间长于 Minor GC 2.6、堆-逃逸分析 对象和数组并非都是在堆上分配内存的 《深入理解 Java 虚拟机中》关于 Java 堆内存有这样一段描述：随着 JIT 编译期的发展与逃逸分析技术逐渐成熟，栈上分配,标量替换优化技术将会导致一些变化，所有的对象都分配到堆上也渐渐变得不那么"绝对"了。 这是一种可以有效减少 Java 内存堆分配压力的分析算法，通过逃逸分析，Java Hotspot 编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。 当一个对象在方法中被定义后，它可能被外部方法所引用，如作为调用参数传递到其他地方中，称为方法逃逸。 再如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸 使用逃逸分析，编译器可以对代码做如下优化： 同步省略：如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步。 将堆分配转化为栈分配：如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配。 分离对象或标量替换：有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在 CPU 寄存器中。 **方法逃逸：**对象逃出当前方法
对象在方法里面被定义后，它可能被外部方法所引用，如：
对象作为方法的返回值或对象的引用包含在返回值中
对象作为方法参数传递或者被参数引用
**线程逃逸：**对象逃出当前线程
对象可能被其它线程访问到
对象是一个静态变量
对象是一个可以在其它线程中访问的实例变量
2.6.1标量替换： 标量不可在分解的量，java 的基本数据类型就是标量，标量的对立就是可以被进一步分解的量，而这种量称之为聚合量。而在 JAVA 中对象就是可以被进一步分解的聚合量 替换过程，通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM 不会创建该对象，而会将该对象成员变量分解若干个被这个方法使用的成员变量所代替。这些代替的成员变量在栈帧或寄存器上分配空间。 如果对象不会逃逸，分配到栈内存的时候，会进行标量替换。
栈中直接分配对象难度太大，需要修改JVM中大量堆优先分配的代码，因此在HotSpot中并没有真正的实现栈中分配对象的功能，取而代之的是一个叫做标量替换的折中办法。
标量和聚合量：
**标量：**基础类型和对象的引用可以理解为标量，它们不能被进一步分解 **聚合量：**能被进一步分解的量就是聚合量，对象就是聚合量，它可以被进一步分解成标量 将对象的成员变量分解为分散的标量，这就叫做标量替换。
这样，如果一个对象没有发生逃逸，那压根就不需要在"堆"中创建它，只会在栈或者寄存器上创建一些能够映射这个对象标量即可，节省了内存空间，也提升了应用程序性能。
2.6.2锁消除： 如果对象不会逃逸，这个对象就永远不会被其它方法或者线程访问到。
这时对象锁synchronized(object) 没有任何意义（因为在任何线程中，object都是不同的锁对象）。所以JVM会对上述代码进行优化，删除锁。
public void lockEliminate() { User user = new User(); synchronized (user) { System.out.println("执行同步代码块"); } } 在lockEliminate() 方法中，对象user永远不会被其它方法或者线程访问到，因此user是不会逃逸对象，这就导致synchronized(user) 没有任何意义，因为在任何线程中，user都是不同的锁对象。
所以JVM会对上述代码进行优化，删除同步相关代码，如下：
public void lockEliminate() { User user = new User(); System.out.println("执行同步代码块"); } 常见的锁消除场景：StringBuffer
public void lockEliminate() { StringBuffer stringBuffer = new StringBuffer(); stringBuffer.append("1"); stringBuffer.append("2"); System.out.println(stringBuffer.toString()); } 此时append方法上的synchronized锁会被消除
@Override public synchronized StringBuffer append(String str) { toStringCache = null; super.append(str); return this; } //实际等同于 @Override public StringBuffer append(String str) { toStringCache = null; super.append(str); return this; } 2.6.3栈上分配： 如果对象不会逃逸，那么这个对象可能会被分配在栈内存上而非常见的堆内存上（对象分配消除）。
对象分配消除：是指将本该在"堆"中分配的对象，转化为由"栈"中分配。
上面为什么说的是可能呢？
因为Hotspot中采用的是解释器和编译器并行的架构，所谓的混合模式就是解释器和编译器搭配使用。
当程序启动初期，采用解释器执行（同时会记录相关的数据，比如函数的调用次数，循环语句执行次数），节省编译的时间。 在使用解释器执行期间，记录的函数运行的数据，通过这些数据发现某些代码是热点代码，采用编译器对热点代码进行编译，以及优化（逃逸分析就是其中一种优化技术）。 所以逃逸分析只在编译器进行编译才会有。
2.7、堆-本地分配缓存区 TLAB 的全称是 Thread Local Allocation Buffer，即线程本地分配缓存区，是属于 Eden 区的，这是一个线程专用的内存分配区域，线程私有，默认开启的（当然也不是绝对的，也要看哪种类型的虚拟机） 堆是全局共享的，在同一时间，可能会有多个线程在堆上申请空间，但每次的对象分配需要同步的进行（虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性）但是效率却有点下降 所以用 TLAB 来避免多线程冲突，在给对象分配内存时，每个线程使用自己的 TLAB，这样可以使得线程同步，提高了对象分配的效率 当然并不是所有的对象都可以在 TLAB 中分配内存成功，如果失败了就会使用加锁的机制来保持操作的原子性 -XX:+UseTLAB 使用 TLAB，-XX:+TLABSize 设置 TLAB 大小 2.8、堆-四种引用方式 **强引用：**创建一个对象并把这个对象赋给一个引用变量，普通 new 出来对象的变量引用都是强引用，有引用变量指向时永远不会被垃圾回收，jvm 即使抛出 OOM，可以将引用赋值为 null，那么它所指向的对象就会被垃圾回收。 **软引用：**如果一个对象具有软引用，内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。 **弱引用：**非必需对象，当 JVM 进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。 **虚引用：**虚引用并不会决定对象的生命周期，如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 2.9、方法区 方法区的定义：
Java 虚拟机规范中定义方法区是堆的一个逻辑部分。方法区存放以下信息：
已经被虚拟机加载的类信息 常量 静态变量 即时编译器编译后的代码 方法区的特点：
线程共享。 方法区是堆的一个逻辑部分，因此和堆一样，都是线程共享的。整个虚拟机中只有一个方法区。 永久代。 方法区中的信息一般需要长期存在，而且它又是堆的逻辑分区，因此用堆的划分方法，把方法区称为“永久代”。 内存回收效率低。 方法区中的信息一般需要长期存在，回收一遍之后可能只有少量信息无效。主要回收目标是：对常量池的回收；对类型的卸载。 Java 虚拟机规范对方法区的要求比较宽松。 和堆一样，允许固定大小，也允许动态扩展，还允许不实现垃圾回收。 运行时常量池：
方法区中存放：类信息、常量、静态变量、即时编译器编译后的代码。常量就存放在运行时常量池中。
当类被 Java 虚拟机加载后， .class 文件中的常量就存放在方法区的运行时常量池中。而且在运行期间，可以向常量池中添加新的常量。如 String 类的 intern() 方法就能在运行期间向常量池中添加字符串常量。
2.10、直接内存（堆外内存） 直接内存是除 Java 虚拟机之外的内存，但也可能被 Java 使用。
操作直接内存：
在 NIO 中引入了一种基于通道和缓冲的 IO 方式。它可以通过调用本地方法直接分配 Java 虚拟机之外的内存，然后通过一个存储在堆中的DirectByteBuffer对象直接操作该内存，而无须先将外部内存中的数据复制到堆中再进行操作，从而提高了数据操作的效率。
直接内存的大小不受 Java 虚拟机控制，但既然是内存，当内存不足时就会抛出 OutOfMemoryError 异常。
直接内存与堆内存比较：
直接内存申请空间耗费更高的性能 直接内存读取 IO 的性能要优于普通的堆内存 直接内存作用链： 本地 IO -> 直接内存 -> 本地 IO 堆内存作用链：本地 IO -> 直接内存 -> 非直接内存 -> 直接内存 -> 本地 IO 服务器管理员在配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制，从而导致动态扩展时出现OutOfMemoryError异常。
2.11、Java 虚拟机栈的特点 运行速度特别快，仅仅次于 PC 寄存器。 局部变量表随着栈帧的创建而创建，它的大小在编译时确定，创建时只需分配事先规定的大小即可。在方法运行过程中，局部变量表的大小不会发生改变。 Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。 StackOverFlowError 若 Java 虚拟机栈的大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度时，抛出 StackOverFlowError 异常。 OutOfMemoryError 若允许动态扩展，那么当线程请求栈时内存用完了，无法再动态扩展时，抛出 OutOfMemoryError 异常。 Java 虚拟机栈也是线程私有，随着线程创建而创建，随着线程的结束而销毁。 出现 StackOverFlowError 时，内存空间可能还有很多。 常见的运行时异常有：
NullPointerException - 空指针引用异常 ClassCastException - 类型强制转换异 IllegalArgumentException - 传递非法参数异常 ArithmeticException - 算术运算异常 ArrayStoreException - 向数组中存放与声明类型不兼容对象异常 IndexOutOfBoundsException - 下标越界异常 NegativeArraySizeException - 创建一个大小为负数的数组错误异常 NumberFormatException - 数字格式异常 SecurityException - 安全异常 UnsupportedOperationException - 不支持的操作异常</content></entry><entry><title>Stream流的最全分类和应用</title><url>https://zhang4014439175.github.io/post/stream%E6%B5%81/</url><categories><category>Java-Base</category></categories><tags><tag>Java</tag><tag>Stream</tag></tags><content type="html">  Java8 中添加了一个新的接口类 Stream，相当于高级版的Iterator，通过Lambda 表达式对集合进行各种非常便利、高效的聚合操作（Aggregate Operation），或者大批量数据操作(Bulk Data Operation）。Stream不仅可以通过串行的方式实现数据操作，还可以通过并行的方式处理大批量数据，提高数据的处理效率。 在《java8 in action》书中，作者说目前我们在几乎所有开发中都会用到集合，但是目前集合在程序开发中的表现还不够完美，比如你利用集合处理大量数据时，你不得不面对性能问题，不得不考虑进行并行代码的编写，这些工作都是比较繁重的，于是作者便创造了Stream 流。
一、Stream流 在Stream流中无法直接修改集合、数组等数据源中的数据，必须重新定义一个来接收结果集。
stream不存储数据，而是按照特定的规则对数据进行计算，一般会输出结果；
stream不会改变数据源，通常情况下会产生一个新的集合；
stream具有延迟执行特性，只有调用终端操作时，中间操作才会执行。
对stream操作分为终端操作和中间操作，那么这两者分别代表什么呢？
终端操作：会消费流，这种操作会产生一个结果的，如果一个流被消费过了，那它就不能被重用的。 中间操作：中间操作会产生另一个流。因此中间操作可以用来创建执行一系列动作的管道。一个特别需要注意的点是:中间操作不是立即发生的。相反，当在中间操作创建的新流上执行完终端操作后，中间操作指定的操作才会发生。所以中间操作是延迟发生的，中间操作的延迟行为主要是让流API能够更加高效地执行。
stream不可复用，对一个已经进行过终端操作的流再次调用，会抛出异常。
二、函数 1、收集(collect) 归集(toList,toMap,toSet) //tolist List&lt;Integer> result = list.stream.filter(number -> number % 2 == 0).collect(Collector.toList); //tomap Map&lt;String, Integer> map = list.stream().filter( s -> { String[] split = s.split(","); int age = Integer.parseInt(split[1]); return age >= 24; } ).collect(Collector.toMap( s -> s.split(",")[0], (String s) -> { return Integer.parseInt(s.split(",")[1]); } )); //toset List&lt;Integer> list = Arrays.asList(1, 6, 3, 4, 6, 7, 9, 6, 20); List&lt;Integer> listNew = list.stream().filter(x -> x % 2 == 0).collect(Collectors.toList()); Set&lt;Integer> set = list.stream().filter(x -> x % 2 == 0).collect(Collectors.toSet()); 统计(count,averaging) Collectors提供了一系列用于数据统计的静态方法：
计数： count 平均值：averagingInt、averagingLong、averagingDouble 最值： maxBy、minBy 求和： summingInt、summingLong、summingDouble 统计以上所有：summarizingInt、summarizingLong、summarizingDouble
案例：统计员工人数、平均工资、工资总额、最高工资。
List&lt;Person> personList = new ArrayList&lt;Person>(); personList.add(new Person("Tom", 8900, 23, "male", "New York")); personList.add(new Person("Jack", 7000, 25, "male", "Washington")); personList.add(new Person("Lily", 7800, 21, "female", "Washington")); // 求总数 Long count = personList.stream().collect(Collectors.counting()); // 求平均工资 Double average = personList.stream().collect(Collectors.averagingDouble(Person::getSalary)); // 求最高工资 Optional&lt;Integer> max = personList.stream().map(Person::getSalary).collect(Collectors.maxBy(Integer::compare)); // 求工资之和 Integer sum = personList.stream().collect(Collectors.summingInt(Person::getSalary)); // 一次性统计所有信息 DoubleSummaryStatistics collect = personList.stream().collect(Collectors.summarizingDouble(Person::getSalary)); System.out.println("员工总数：" + count); System.out.println("员工平均工资：" + average); System.out.println("员工工资总和：" + sum); System.out.println("员工工资所有统计：" + collect); 运行结果：
员工总数：3 员工平均工资：7900.0 员工工资总和：23700 员工工资所有统计：DoubleSummaryStatistics{count=3, sum=23700.000000,min=7000.000000, average=7900.000000, max=8900.000000} 分组(partitioningBy/gro..) partitioningBy/groupingBy
分区：将stream按条件分为两个Map，比如员工按薪资是否高于8000分为两部分。 分组：将集合分为多个Map，比如员工按性别分组。有单级分组和多级分组。 List&lt;Person> personList = new ArrayList&lt;Person>(); personList.add(new Person("Tom", 8900, "male", "New York")); personList.add(new Person("Jack", 7000, "male", "Washington")); personList.add(new Person("Lily", 7800, "female", "Washington")); personList.add(new Person("Anni", 8200, "female", "New York")); personList.add(new Person("Owen", 9500, "male", "New York")); personList.add(new Person("Alisa", 7900, "female", "New York")); // 将员工按薪资是否高于8000分组 Map&lt;Boolean, List&lt;Person>> part = personList.stream() .collect(Collectors.partitioningBy(x -> x.getSalary() > 8000)); // 将员工按性别分组 Map&lt;String, List&lt;Person>> group = personList.stream() .collect(Collectors.groupingBy(Person::getSex)); // 将员工先按性别分组，再按地区分组 Map&lt;String, Map&lt;String, List&lt;Person>>> group2 = personList.stream() .collect(Collectors.groupingBy(Person::getSex, Collectors.groupingBy(Person::getArea))); System.out.println("员工按薪资是否大于8000分组情况：" + part); System.out.println("员工按性别分组情况：" + group); System.out.println("员工按性别、地区：" + group2); 案例二：
//分组数目 System.out.println("分组数目："); Integer groupCount = peopleList .stream() .collect(Collectors .collectingAndThen(Collectors.groupingBy(People::getName), Map::size)); System.out.println(groupCount); System.out.println("-------------------------------------"); //按照名字分组 System.out.println("按照名字分组"); System.out.println(peopleList.stream() .collect(Collectors.groupingBy(People::getName)) ); System.out.println("-------------------------------------"); //按照名字分组(分组的结果是一个map)，并统计每一个分组(map中的每一个value)中的元素数目 System.out.println("统计每一个分组(map中的每一个value)中的元素数目"); System.out.println(peopleList.stream() .collect(Collectors.groupingBy(People::getName, Collectors.counting()))); System.out.println("-------------------------------------"); //按照名字分组(分组的结果是一个map)，并取出每一组的最大值 System.out.println("取出每一组的最大值"); System.out.println(peopleList.stream() .collect(Collectors .groupingBy(People::getName, Collectors.maxBy( new Comparator&lt;People>() { @Override public int compare(People o1, People o2) { return o1.getAge() - o2.getAge(); } })))); //7 //{小猪=[People{age=31, gender=0, name='小猪'},People{age=20, gender=0, name='小猪'},People{age=22, gender=0, name='小猪'}]} //{小猪=2,小龙=3,小白=4,小王=5} //{小猪=Optional[People{age=20, gender=0, name='小猪'}],小龙=Optional[People{age=30, gender=0, name='小龙'}]} 接合(joining) joining可以将stream中的元素用特定的连接符（没有的话，则直接连接）连接成一个字符串。
List&lt;Person> personList = new ArrayList&lt;Person>(); personList.add(new Person("Tom", 8900, 23, "male", "New York")); personList.add(new Person("Jack", 7000, 25, "male", "Washington")); personList.add(new Person("Lily", 7800, 21, "female", "Washington")); String names = personList.stream() .map(p -> p.getName()) .collect(Collectors.joining(",")); System.out.println("所有员工的姓名：" + names); List&lt;String> list = Arrays.asList("A", "B", "C"); String string = list.stream() .collect(Collectors.joining("-")); System.out.println("拼接后的字符串：" + string); 运行结果： 所有员工的姓名：Tom,Jack,Lily 拼接后的字符串：A-B-C 归约(reducing) Collectors类提供的reducing方法，相比于stream本身的reduce方法，增加了对自定义归约的支持。
List&lt;Person> personList = new ArrayList&lt;Person>(); personList.add(new Person("Tom", 8900, 23, "male", "New York")); personList.add(new Person("Jack", 7000, 25, "male", "Washington")); personList.add(new Person("Lily", 7800, 21, "female", "Washington")); // 每个员工减去起征点后的薪资之和（这个例子并不严谨，但一时没想到好的例子） Integer sum = personList.stream() .collect(Collectors.reducing(0, Person::getSalary, (i, j) -> (i + j - 5000))); System.out.println("员工扣税薪资总和：" + sum); // stream的reduce Optional&lt;Integer> sum2 = personList.stream() .map(Person::getSalary).reduce(Integer::sum); System.out.println("员工薪资总和：" + sum2.get()); 运行结果： 员工扣税薪资总和：8700 员工薪资总和：23700 2、过滤(filter) List&lt;String>strings = Arrays.asList("abc", "", "bc", "efg", "abcd","", "jkl"); // 获取空字符串的数量 long count = strings.stream() .filter(string -> string.isEmpty()) .count(); // filter().limit(2) 案例二： 筛选员工中工资高于8000的人，并形成新的集合。 形成新集合依赖collect（收集），后文有详细介绍。
List&lt;Person> personList = new ArrayList&lt;Person>(); personList.add(new Person("Tom", 8900, 23, "male", "New York")); personList.add(new Person("Jack", 7000, 25, "male", "Washington")); personList.add(new Person("Lily", 7800, 21, "female", "Washington")); personList.add(new Person("Anni", 8200, 24, "female", "New York")); personList.add(new Person("Owen", 9500, 25, "male", "New York")); personList.add(new Person("Alisa", 7900, 26, "female", "New York")); List&lt;String> fiterList = personList.stream() .filter(x -> x.getSalary() > 8000) .map(Person::getName) .collect(Collectors.toList()); System.out.print("高于8000的员工姓名：" + fiterList); 3、归约(reduce) 归约，也称缩减，顾名思义，是把一个流缩减成一个值，能实现对集合求和、求乘积和求最值操作。
案例一：求Integer集合的元素之和、乘积和最大值。
List&lt;Integer> list = Arrays.asList(1, 3, 2, 8, 11, 4); // 求和方式1 Optional&lt;Integer> sum = list.stream().reduce((x, y) -> x + y); // 求和方式2 Optional&lt;Integer> sum2 = list.stream().reduce(Integer::sum); // 求和方式3 Integer sum3 = list.stream().reduce(0, Integer::sum); // 求乘积 Optional&lt;Integer> product = list.stream().reduce((x, y) -> x * y); // 求最大值方式1 Optional&lt;Integer> max = list.stream().reduce((x, y) -> x > y ? x : y); // 求最大值写法2 Integer max2 = list.stream().reduce(1, Integer::max); System.out.println("list求和：" + sum.get() + "," + sum2.get() + "," + sum3); System.out.println("list求积：" + product.get()); System.out.println("list求和：" + max.get() + "," + max2); 4、聚合(count,max,min) 过滤出来数据数量合
long count = strings.stream().filter(string -> string.isEmpty()).count(); public class StreamTest { public static void main(String[] args) { List&lt;String> list = Arrays.asList("adnm", "admmt", "pot", "xbangd", "weoujgsd"); Optional&lt;String> max = list.stream().max(Comparator.comparing(String::length)); System.out.println("最长的字符串：" + max.get()); } } 5、遍历匹配(for,find,match) String流的生命周期：同一个流只能遍历一次，遍历完后，这个流就已经被消费掉了。你如果还需要在遍历，可以从原始数据源那里再获得一个新的流来重新遍历一遍。
Random random = new Random(); random.ints().limit(10).forEach(System.out::println); List&lt;Integer> list = Arrays.asList(7, 6, 9, 3, 8, 2, 1); // 遍历输出符合条件的元素 list.stream().filter(x -> x > 6).forEach(System.out::println); // 匹配第一个 Optional&lt;Integer> findFirst = list.stream().filter(x -> x > 6).findFirst(); // 匹配任意（适用于并行流） Optional&lt;Integer> findAny = list.parallelStream().filter(x -> x > 6).findAny(); // 是否包含符合特定条件的元素 boolean anyMatch = list.stream().anyMatch(x -> x > 6); System.out.println("匹配第一个值：" + findFirst.get()); System.out.println("匹配任意一个值：" + findAny.get()); System.out.println("是否存在大于6的值：" + anyMatch); 6、映射(map,faltMap) map 方法用于映射每个元素到对应的结果，以下代码片段使用 map 输出了元素对应的平方数：
map：接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。 flatMap：接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流。 // 获取对应的平方数 List&lt;Integer> numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5); List&lt;Integer> squaresList = numbers.stream().map( i -> i*i).distinct().collect(Collectors.toList()); //获取10个姓王的人并输出。 List&lt;Person> personList = fromDB(); // 获得List&lt;Person> personList.stream() .filter(item->item.age == 70) // 过滤条件 .limit(10) // limit限制条件 .filter(item->item.name.startWith("王")) // 过滤条件 .map(item->item.name) // 获得姓名 .forEach(System.out::println); //获取一个String 类型的Stream流 //使用map方法，把字符串类型的整数，转换（映射）为Integer类型的整数 //遍历stream2流 Stream&lt;String> stream = Stream.of("1", "2", "3", "4"); Stream&lt;Integer> stream2 = stream.map(s-> Integer.parseInt(s)); stream2.forEach(i-> System.out.println(i)); 7、提取组合(concat,limit ,sk..) //concat Stream.concat(stream1, stream2).forEach(name ->{ Actor actor = new Actor(name); System.out.println(name) }); //limit Random random = new Random(); random.ints().limit(10).forEach(System.out::println); String[] arr1 = { "a", "b", "c", "d" }; String[] arr2 = { "d", "e", "f", "g" }; Stream&lt;String> stream1 = Stream.of(arr1); Stream&lt;String> stream2 = Stream.of(arr2); // concat:合并两个流 distinct：去重 List&lt;String> newList = Stream.concat(stream1, stream2) .distinct() .collect(Collectors.toList()); // limit：限制从流中获得前n个数据 List&lt;Integer> collect = Stream.iterate(1, x -> x + 2) .limit(10) .collect(Collectors.toList()); // skip：跳过前n个数据 List&lt;Integer> collect2 = Stream.iterate(1, x -> x + 2) .skip(1) .limit(5) .collect(Collectors.toList()); System.out.println("流合并：" + newList); System.out.println("limit：" + collect); System.out.println("skip：" + collect2); 8、排序(Sorted) Random random = new Random(); random.ints().limit(10).sorted().forEach(System.out::println); 9、Collectors Collectors 类实现了很多归约操作，例如将流转换成集合和聚合元素。Collectors 可用于返回列表或字符串：
List&lt;String>strings = Arrays.asList("abc", "", "bc", "efg", "abcd","", "jkl"); List&lt;String> filtered = strings.stream().filter(string -> !string.isEmpty()).collect(Collectors.toList()); System.out.println("筛选列表: " + filtered); //筛选出来的string字符进行拼接 String mergedString = strings.stream().filter(string -> !string.isEmpty()).collect(Collectors.joining(", ")); System.out.println("合并字符串: " + mergedString); 三、统计 List&lt;Integer> numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5); IntSummaryStatistics stats = numbers.stream().mapToInt((x) -> x).summaryStatistics(); System.out.println("列表中最大的数 : " + stats.getMax()); System.out.println("列表中最小的数 : " + stats.getMin()); System.out.println("所有数之和 : " + stats.getSum()); System.out.println("平均数 : " + stats.getAverage()); 四、流创建 1、随机数流 
Random rand = new Random(47); show(rand.ints().boxed()); show(rand.longs().boxed()); show(rand.doubles().boxed()); // 控制上限和下限： show(rand.ints(10, 20).boxed()); show(rand.longs(50, 100).boxed()); show(rand.doubles(20, 30).boxed()); // 控制流大小： show(rand.ints(2).boxed()); show(rand.longs(2).boxed()); show(rand.doubles(2).boxed()); // 控制流的大小和界限 show(rand.ints(3, 3, 9).boxed()); show(rand.longs(3, 12, 22).boxed()); show(rand.doubles(3, 11.5, 12.3).boxed()); 具体看on java 8 第14章，流创建、随机数流 2、int类型的范围 public class Ranges { public static void main(String[] args) { // 传统方法: int result = 0; for (int i = 10; i &lt; 20; i++) result += i; System.out.println(result); // for-in 循环: result = 0; for (int i : range(10, 20).toArray()) result += i; System.out.println(result); // 使用流: System.out.println(range(10, 20).sum()); } }</content></entry><entry><title>String字符串</title><url>https://zhang4014439175.github.io/post/string/</url><categories><category>Java-Base</category></categories><tags><tag>Java</tag><tag>String</tag></tags><content type="html">  string是C++、java、VB等编程语言中的字符串，字符串是一个特殊的对象，属于引用类型。 在java、C#中，String类对象创建后，字符串一旦初始化就不能更改，因为string类中所有字符串都是常量，数据是无法更改，由于string对象的不可变，所以可以共享。一、Collectors.joining() 1、拼接字符串 List&lt;String> list = Arrays.asList("Ram","Shyam","Shiv","Mahesh"); String result= list.stream().collect(Collectors.joining()); System.out.println(result); //RamShyamShivMahesh result= list.stream().collect(Collectors.joining(",")); System.out.println(result); //Ram,Shyam,Shiv,Mahesh result= list.stream().collect(Collectors.joining("-","[","]")); System.out.println(result); //[Ram-Shyam-Shiv-Mahesh] 2、拼接对象 package com.concretepage; import java.util.List; import java.util.stream.Collectors; public class JoiningExampleWithListOfObject { public static void main(String[] args) { List&lt;Person> list = new ArrayList&lt;>(); list.add(new Person("Ram", 23)); list.add(new Person("Shyam", 20)); list.add(new Person("Shiv", 25)); list.add(new Person("Mahesh", 30)); String result= list.stream() .map(p -> p.getName()) .collect(Collectors.joining()); System.out.println(result); //RamShyamShivMahesh String result= list.stream() .map(p -> p.getName()) .collect(Collectors.joining("|")); System.out.println(result); //Ram|Shyam|Shiv|Mahesh String result= list.stream().map(p -> p.getName()).collect(Collectors.joining("-","[","]")); System.out.println(result); //[Ram-Shyam-Shiv-Mahesh] String result= list.stream() .map(p -> String.valueOf(p.getAge())) .collect(Collectors.joining()); System.out.println(result); //23202530 String result= list.stream() .map(p -> String.valueOf(p.getAge())) .collect(Collectors.joining("|")); System.out.println(result); //23|20|25|30 String result= list.stream() .map(p -> String.valueOf(p.getAge())) .collect(Collectors.joining("-","[","]")); System.out.println(result); //[23-20-25-30] String result= list.stream() .map(p -> p.getName()+"-" + p.getAge()) .collect(Collectors.joining("|")); System.out.println(result); //Ram-23|Shyam-20|Shiv-25|Mahesh-30 String result= list.stream() .map(p -> p.getName()+"-" + p.getAge()) .collect(Collectors.joining("|","[","]")); System.out.println(result); //[Ram-23|Shyam-20|Shiv-25|Mahesh-30] } } 3、遍历ArrayList中的元素
List&lt;Coffee> coffees = Stream.generate(new CoffeeSupplier()) .limit(10) .collect(Collectors.toList()); System.out.println(coffees); toString() 打印出类的内存地址
@Override public String toString() { //return " InfiniteRecursion address: " + this + "\n" //如果你真的想要打印对象的内存地址，应该调用 Object.toString() 方法，这才是负责此任务的方法。所以，不要使用 this，而是应该调用 super.toString() 方法。 } public static void main(String[] args) { Stream.generate(InfiniteRecursion::new) .limit(10) .forEach(System.out::println); } 二、常见方法 length()
charAt() 获取String中索引位置上的char
getChars()、getBytes() 复制char或byte到一个目标数组中
toCharArray() 生成一个char[]，包含String中的所有字符
equals()、equalsIgnoreCase() 比较两个String的内容是否相同。如果相同，结果为true
compareTo()、compareToIgnoreCase()
​ 按词典顺序比较String的内容，比较结果为负数、零或正数。注意，大小写不等价
contains()
contentEquals() 如果该String对象与参数的内容完全一致，则返回true
isEmpty() 返回boolean结果，以表明String对象的长度是否为0
​ Stringutils.isEmpty() 来判断是否为空null
regionMatches() 返回boolean结果，以表明所比较区域是否相等
startsWith() 返回boolean结果，以表明该String是否以传入参数开始
endsWith() 返回boolean结果，以表明此参数是否是该字符串的后缀
indexOf() 返回在String中的起始索引，如果不包含此参数，就返回-1；
lastIndexOf() lastIndexOf()是从后往前搜索
matches() 返回boolean结果，以表明该String和给出的正则表达式是否匹配
split() 按照正则表达式拆分String，返回一个结果数组
join() 用分隔符拼接字符片段，产生一个新的String
substring() 返回一个新的String对象，以包含参数指定的子串
concat() 拼接字符串
replace() 返回替换字符后的新String对象。如果没有替换发生，则返回原始的String对象
replaceFirst() 返回替换首个目标字符串后的String对象
replaceAll() 返回替换所有目标字符串后的String对象
toLowerCase()
toUpperCase()
trim() 将String两端的空白符删除后，返回一个新的String对象。
​ 如果没有任何改变，则返回原始的String对象
valueOf()
intern() 为每个唯一的字符序列生成一个且仅生成一个String引用。
format() 返回格式化结果String
1、练习 从0 - 100 共25个数字
String result = new Random(47) .ints(25, 0, 100) .mapToObj(Integer::toString) .collect(Collectors.joining(",")); 三、printf() System.out.printf("Row 1: [%d %f]%n", x, y); 这一行代码在运行的时候，首先将 x 的值插入到 %d_ 的位置，然后将 y 的值插入到 %f 的位置。这些占位符叫做格式修饰符，它们不仅指明了插入数据的位置，同时还指明了将会插入什么类型的变量，以及如何格式化。在这个例子中 %d 表示 x 是一个整数，%f 表示 y 是一个浮点数（float 或者 double）。
int x = 5; double y = 5.332542; // The old way: System.out.println("Row 1: [" + x + " " + y + "]"); // The new way: System.out.format("Row 1: [%d %f]%n", x, y); // or System.out.printf("Row 1: [%d %f]%n", x, y); /* Output: Row 1: [5 5.332542] Row 1: [5 5.332542] Row 1: [5 5.332542] */ 格式化修饰符 f.format("%-15s %5s %10s%n", "Item", "Qty", "Price"); f.format("%-15s %5s %10s%n", "----", "---", "-----"); f.format("%-15.15s %5d %10.2f%n", name, qty, price); receiptBuilder.add("Jack's Magic Beans", 4, 4.25); receiptBuilder.add("Princess Peas", 3, 5.1); receiptBuilder.add("Three Bears Porridge", 1, 14.29); total += price * qty; f.format("%-15s %5s %10.2f%n", "Tax", "", total * 0.06); f.format("%-15s %5s %10s%n", "", "", "-----"); f.format("%-15s %5s %10.2f%n", "Total", "", total * 1.06); Formatter转换 下面的表格展示了最常用的类型转换：
类型 含义 d 整型（十进制） c Unicode字符 b Boolean值 s String f 浮点数（十进制） e 浮点数（科学计数） x 整型（十六进制） h 散列码（十六进制） % 字面值“%” 四、正则表达式 System.out.println("-1234".matches("-?\\d+")); System.out.println("5678".matches("-?\\d+")); System.out.println("+911".matches("-?\\d+")); System.out.println("+911".matches("(-|\\+)?\\d+")); /* Output: true true false true */ (-|\+)?
这个正则表达式表示字符串的起始字符可能是一个 - 或 +，或者二者都没有（因为后面跟着 ? 修饰符）。因为字符 + 在正则表达式中有特殊的意义，所以必须使用 \ 将其转义，使之成为表达式中的一个普通字符。
String类还自带了一个非常有用的正则表达式工具——split() 方法，其功能是“将字符串从正则表达式匹配的地方切开。”
public class Splitting { public static String knights = "Then, when you have found the shrubbery, " + "you must cut down the mightiest tree in the " + "forest...with... a herring!"; public static void split(String regex) { System.out.println( Arrays.toString(knights.split(regex))); } public static void main(String[] args) { split(" "); // Doesn't have to contain regex chars split("\\W+"); // Non-word characters split("n\\W+"); // 'n' followed by non-words //按空格来划分字符串。 //一个非单词字符（如果 W 小写，\\w，则表示一个单词字符）。 //表示“字母n后面跟着一个或多个非单词字符。” } } /* Output: [Then,, when, you, have, found, the, shrubbery,, you, must, cut, down, the, mightiest, tree, in, the, forest...with..., a, herring!] [Then, when, you, have, found, the, shrubbery, you, must, cut, down, the, mightiest, tree, in, the, forest, with, a, herring] [The, whe, you have found the shrubbery, you must cut dow, the mightiest tree i, the forest...with... a herring!] */ 用正则表达式进行替换操作时，你可以只替换第一处匹配，也可以替换所有的匹配：
// strings/Replacing.java public class Replacing { static String s = Splitting.knights; public static void main(String[] args) { System.out.println(s.replaceFirst("f\\w+", "located")); //以字母 f 开头，后面跟一个或多个字母（注意这里的 w 是小写的）。并且只替换掉第一个匹配的部分，所以 “found” 被替换成 “located”。 System.out.println(s.replaceAll("shrubbery|tree|herring","banana")); //第二个表达式要匹配的是三个单词中的任意一个，因为它们以竖线分割表示“或”，并且替换所有匹配的部分。 } } /* Output: Then, when you have located the shrubbery, you must cut down the mightiest tree in the forest...with... a herring! Then, when you have found the banana, you must cut down the mightiest banana in the forest...with... a banana! */ 表达式 含义 B 指定字符B \xhh 十六进制值为0xhh的字符 \uhhhh 十六进制表现为0xhhhh的Unicode字符 \t 制表符Tab \n 换行符 \r 回车 \f 换页 \e 转义（Escape） 当你学会了使用字符类（character classes）之后，正则表达式的威力才能真正显现出来。以下是一些创建字符类的典型方式，以及一些预定义的类：
表达式 含义 . 任意字符 [abc] 包含a、b或c的任何字符（和`a [^abc] 除a、b和c之外的任何字符（否定） [a-zA-Z] 从a到z或从A到Z的任何字符（范围） [abc[hij]] a、b、c、h、i、j中的任意字符（与`a [a-z&amp;&amp;[hij]] 任意h、i或j（交） \s 空白符（空格、tab、换行、换页、回车） \S 非空白符（[^\s]） \d 数字（[0-9]） \D 非数字（[^0-9]） \w 词字符（[a-zA-Z_0-9]） \W 非词字符（[^\w]） for(String pattern : new String[]{ "Rudolph", "[rR]udolph", "[rR][aeiou][a-z]ol.*", "R.*" }) System.out.println("Rudolph".matches(pattern)); /* Output: true true true true */ 1、量词 贪婪型： 量词总是贪婪的，除非有其他的选项被设置。贪婪表达式会为所有可能的模式发现尽可能多的匹配。导致此问题的一个典型理由就是假定我们的模式仅能匹配第一个可能的字符组，如果它是贪婪的，那么它就会继续往下匹配。
勉强型： 用问号来指定，这个量词匹配满足模式所需的最少字符数。因此也被称作懒惰的、最少匹配的、非贪婪的或不贪婪的。
占有型： 目前，这种类型的量词只有在 Java 语言中才可用（在其他语言中不可用），并且也更高级，因此我们大概不会立刻用到它。当正则表达式被应用于 String 时，它会产生相当多的状态，以便在匹配失败时可以回溯。而“占有的”量词并不保存这些中间状态，因此它们可以防止回溯。它们常常用于防止正则表达式失控，因此可以使正则表达式执行起来更高效。
贪婪型 勉强型 占有型 如何匹配 X? X?? X?+ 一个或零个X X* X*? X*+ 零个或多个X X+ X+? X++ 一个或多个X X{n} X{n}? X{n}+ 恰好n次X X{n,} X{n,}? X{n,}+ 至少n次X X{n,m} X{n,m}? X{n,m}+ X至少n次，但不超过m次 A(B(C))D
中有三个组：组 0 是 ABCD，组 1 是 BC，组 2 是 C。
Matcher 对象提供了一系列方法，用以获取与组相关的信息：
public int groupCount() 返回该匹配器的模式中的分组数目，组 0 不包括在内。 public String group() 返回前一次匹配操作（例如 find()）的第 0 组（整个匹配）。 public String group(int i) 返回前一次匹配操作期间指定的组号，如果匹配成功，但是指定的组没有匹配输入字符串的任何部分，则将返回 null。 public int start(int group) 返回在前一次匹配操作中寻找到的组的起始索引。 public int end(int group) 返回在前一次匹配操作中寻找到的组的最后一个字符索引加一的值。 2、元字符 元字符：即为有特定含义的字符，常见的元字符如下
代码 说明 . 匹配除换行符以外的任意字符 \w 匹配字母或数字或下划线或汉字 \s 匹配任意的空白符 \d 匹配数字 \b 匹配单词的开始或结束 ^ 匹配字符串的开始（在集合字符里[^a]表示非（不匹配）的意思 $ 匹配字符串的结束 详解和示例：
（1）. 匹配任何任意字符 例如 . 可以匹配 1，n，*，+，- ,等
（2）\d\w\s 匹配第一个字符为数字，第二个字符为字母或数字、或下划线或汉字，第三字符为空格的字符串 例如：11 ，2a , 1_
（3）^\d\d\d$ 匹配三个全部都为数字的字符串 例如： 123,456,789
还可以用于验证输入的字符串是否符合qq（身份证号）的验证 ： 例如：^\d{8}$ 匹配8位数字的qq号，^\d{15}&amp;匹配15位均为数字的身份证号 （4）\bOlive\b 匹配单词Olive 例如： I Love Oliver and Olive .这个时候返回的是Olive 而不是Oliver,因为\b&hellip;.\b返回的匹配的单词
3、反义字符 反义字符：多用于查找除某个字符以外其他任意字符均可以的情况
常用的反义字符如下：
代码/语法 说明 \W 匹配任意不是字母，数字，下划线，汉字的字符 \S 匹配任意不是空白符的字符 \D 匹配任意非数字的字符 \B 匹配不是单词开头或结束的位置 [^x] 匹配除了x以外的任意字符 [^aeiou] 匹配除了aeiou这几个字母以外的任意字符 详解和示例：
（1）\W 匹配除字母、数字、下划线、汉字以为的字符形如 +，-，*
（2）\S 匹配除空格以外的任意字符形如：1，* ，）
（3）[^abcde]匹配除abcde以为的其他字符 如 e，f，g，h
4、限定字符 限定字符多用于重复匹配次数
常用的限定字符如下
代码/语法 说明 * 重复零次或更多次 + 重复一次或更多次 ? 重复零次或一次 {n} 重复n次 {n,} 重复n次或更多次 {n,m} 重复n到m次 详解和示例：
（1）\d* 匹配重复0次或多次数字 例如:可能为空 或 任意数字 （2,3。。。。）
（2）\d+ 匹配重复1次或多次数字 例如:可能为1个或多个数字 1,23,234,2345，&hellip;&hellip;..
（3）\d? 匹配重复次个或者一次数字 例如：可能为空或者任意的一个数字（1,2，。。。）
（4）\d{8}匹配重复8次数字 例如：123456768
（5）\d{4,}匹配重复至少4次数字 例如：1234,12345,124244,。。。。。
（6）^\d{8,11}$ 匹配重复8-11次数字 例如：12345678,123456789,1234567890,12345678901
5、转义字符 在实际的开发中，可能会遇到要比配元字符的情况，这个时候就需要进行字符转义，如元字符 . * \ 需要转换为. * \
例如： 需要匹配qq邮箱 \d{8,}+qq+.+com 在这里的. 就需要加斜杠
6、字符分枝 字符分枝多用于满足不同情况的选择，用“|”将不同的条件分割开来，比如有些固定电话区号有三位，有些有四位，这个时候可以采用字符分枝
例如：\d{3}-\d{8}|\d{4}-\d{8} 可以匹配两种不同长度区号的固定电话
下边的IP地址正则表达式也有用到字符分枝
7、字符分组 字符分组多用于将多个字符重复，主要通过使用小括号()来进行分组
形如：（\d\w){3} 重复匹配3次（\d\w)
常用于表示IP地址 形如： ((25[0-5]|2[0-4][0-9]|[0-1]\d\d).){3}(25[0-5]|2[0-4][0-9]|[0-1]\d\d)
解析：先把IP地址分为两部分一部分是123.123.123. 另一部分是123，又因Ip最大值为255，所以先使用分组，然后在组里边再进行选择，组里也有三部分，0-199,200-249,250-255，分别和上述的表达是对应，最后还要注意分组之后还要加上一个.，因为是元字符所以要转义故加上. 然后再把这部分整体看做是一个组，重复三次，再加上仅有数字的一组也就是不带.的那一组即可完成IP地址的校验
常用分组语法
分类 代码/语法 说明 (exp) 匹配exp,并捕获文本到自动命名的组里 捕 (?exp) 匹配exp,并捕获文本到名称为name的组里，也可以写成(?&rsquo;name&rsquo;exp) 获 (?:exp) 匹配exp,不捕获匹配的文本，也不给此分组分配组号 零 (?=exp) 匹配exp前面的位置 宽 (?&lt;=exp) 匹配exp后面的位置 断 (?!exp) 匹配后面跟的不是exp的位置 言 (?&lt;!exp) 匹配前面不是exp的位置 注释 (?#comment) 这种类型的分组不对正则表达式的处理产生任何影响，用于提供注释让人阅读 8、懒惰匹配和贪婪匹配 贪婪匹配：正则表达式中包含重复的限定符时，通常的行为是匹配尽可能多的字符。
懒惰匹配，有时候需要匹配尽可能少的字符。
例如： a.*b，它将会匹配最长的以a开始，以b结束的字符串。如果用它来搜索aabab的话，它会匹配整个字符串aabab。但是我们此时可能需要匹配的是ab这样的话就需要用到懒惰匹配了。懒惰匹配会匹配尽可能少的字符
常用的懒惰匹配限定符如下
代码/语法 说明 *? 重复任意次，但尽可能少重复 +? 重复1次或更多次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {n,m}? 重复n到m次，但尽可能少重复 {n,}? 重复n次以上，但尽可能少重复 9、后向引用 后向引用用于重复搜索前面某个分组匹配的文本。
使用小括号指定一个子表达式后，匹配这个子表达式的文本(也就是此分组捕获的内容)可以在表达式或其它程序中作进一步的处理。默认情况下，每个分组会自动拥有一个组号，规则是：从左向右，以分组的左括号为标志，第一个出现的分组的组号为1，第二个为2，以此类推
示例：\b(\w+)\b\s+\1\b可以用来匹配重复的单词，像go go, 或者kitty kitty。
这个表达式首先是一个单词，也就是单词开始处和结束处之间的多于一个的字母或数字(\b(\w+)\b)，这个单词会被捕获到编号为1的分组中，然后是1个或几个空白符(\s+)，最后是分组1中捕获的内容（也就是前面匹配的那个单词）(\1)。
你也可以自己指定子表达式的组名。要指定一个子表达式的组名，请使用这样的语法：(?\w+)(或者把尖括号换成&rsquo;也行：(?&lsquo;Word&rsquo;\w+)),这样就把\w+的组名指定为Word了。要反向引用这个分组捕获的内容，你可以使用\k,所以上一个例子也可以写成这样：\b(?\w+)\b\s+\k\b
10、零宽断言 有时候需要查找某些匹配之前或之后的东西，这个时候就需要用到们像\b,^,$那样用于指定一个位置，这个位置应该满足一定的条件(即断言)，因此它们也被称为零宽断言
(?=exp)也叫零宽度正预测先行断言，它断言自身出现的位置的后面能匹配表达式exp。比如 \b\w+(?=ing\b)，匹配以ing结尾的单词的前面部分(除了ing以外的部分)，如查找I&rsquo;m singing while you&rsquo;re dancing.时，它会匹配sing和danc。
(?&lt;=exp)也叫零宽度正回顾后发断言，它断言自身出现的位置的前面能匹配表达式exp。比如(?&lt;=\bre)\w+\b会匹配以re开头的单词的后半部分(除了re以外的部分)，例如在查找reading a book时，它匹配ading。
11、其他语法 12、常用的实用正则表达式整理 只能输入数字："^[0-9]*$"。
　只能输入n位的数字："^&ldquo;d{n}$"。
　只能输入至少n位的数字："^&ldquo;d{n,}$"。
　只能输入m~n位的数字：。"^&ldquo;d{m,n}$&rdquo;
　只能输入零和非零开头的数字："^(0|[1-9][0-9]*)$"。
　只能输入有两位小数的正实数："^[0-9]+(.[0-9]{2})?$"。
　只能输入有1~3位小数的正实数："^[0-9]+(.[0-9]{1,3})?$"。
　只能输入非零的正整数："^"+?[1-9][0-9]*$"。
　只能输入非零的负整数："^&rdquo;-[1-9][]0-9&rdquo;*$。
　只能输入长度为3的字符："^.{3}$"。
　只能输入由26个英文字母组成的字符串："^[A-Za-z]+$"。
　只能输入由26个大写英文字母组成的字符串："^[A-Z]+$"。
　只能输入由26个小写英文字母组成的字符串："^[a-z]+$"。
　只能输入由数字和26个英文字母组成的字符串："^[A-Za-z0-9]+$"。
　只能输入由数字、26个英文字母或者下划线组成的字符串："^&ldquo;w+$"。
　验证用户密码："^[a-zA-Z]&ldquo;w{5,17}$&ldquo;正确格式为：以字母开头，长度在6~18之间，只能包含字符、数字和下划线。
　验证是否含有^%&amp;’,;=?$&ldquo;&ldquo;等字符：&rdquo;[^%&amp;’,;=?$&ldquo;x22]+"。
　只能输入汉字："^[&ldquo;u4e00-&ldquo;u9fa5]{0,}$&rdquo;
　验证Email地址："^&ldquo;w+([-+.]&ldquo;w+)@&ldquo;w+([-.]&ldquo;w+)&rdquo;.&ldquo;w+([-.]&ldquo;w+)*$"。
　验证InternetURL："^http://([&ldquo;w-]+&rdquo;.)+[&ldquo;w-]+(/[&ldquo;w-./?%&amp;=]*)?$"。
　验证电话号码："^(&rdquo;(&ldquo;d{3,4}-)|&ldquo;d{3.4}-)?&ldquo;d{7,8}$&ldquo;正确格式为：&ldquo;XXX-XXXXXXX&rdquo;、&ldquo;XXXX- XXXXXXXX&rdquo;、&ldquo;XXX-XXXXXXX&rdquo;、&ldquo;XXX-XXXXXXXX&rdquo;、&ldquo;XXXXXXX"和"XXXXXXXX&rdquo;。
　验证身份证号(15位或18位数字)："^&ldquo;d{15}|&ldquo;d{18}$"。
　验证一年的12个月："^(0?[1-9]|1[0-2])$&ldquo;正确格式为：&ldquo;01"～"09"和"1"～"12&rdquo;。
　验证一个月的31天："^((0?[1-9])|((1|2)[0-9])|30|31)$&ldquo;正确格式为;&ldquo;01"～"09"和"1"～"31&rdquo;。</content></entry><entry><title>Java进阶-多线程并发-线程池</title><url>https://zhang4014439175.github.io/post/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url><categories><category>Java-Advanced</category><category>并发</category></categories><tags><tag>Java</tag><tag>并发</tag><tag>多线程</tag><tag>线程池</tag></tags><content type="html">  多线程并发是后端开发中常见问题，也是最难解决的问题，下功夫多研究研究，本文档是java juc 的学习笔记。
一、线程池 1、线程池概念 线程池(英语:thread pool):一种线程使用模式。线程过多会带来调度开销， 进而影响缓存局部性和整体性能。而线程池维护着多个线程，等待着监督管理 者分配可并发执行的任务。这避免了在处理短时间任务时创建与销毁线程的代 价。线程池不仅能够保证内核的充分利用，还能防止过分调度。
例子: 10 年前单核 CPU 电脑，假的多线程，像马戏团小丑玩多个球，CPU 需 要来回切换。 现在是多核电脑，多个线程各自跑在独立的 CPU 上，不用切换 效率高。
线程池的优势: 线程池做的工作只要是控制运行的线程数量，处理过程中将任 务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量， 超出数量的线程排队等候，等其他线程执行完毕，再从队列中取出任务来执行。
它的主要特点为:
降低资源消耗: 通过重复利用已创建的线程降低线程创建和销毁造成的销耗。 提高响应速度: 当任务到达时，任务可以不需要等待线程创建就能立即执行。 提高线程的可管理性: 线程是稀缺资源，如果无限制的创建，不仅会销耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 Java 中的线程池是通过 Executor 框架实现的，该框架中用到了 Executor**，Executors，**
ExecutorService**，**ThreadPoolExecutor 这几个类
2、线程池架构 3、线程池使用方式 1）Executors.newFixedThreadPool() 一池N线程
作用:创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这 些线程。在任意点，在大多数线程会处于处理任务的活动状态。如果在所有线 程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中 等待。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线 程将代替它执行后续的任务(如果需要)。在某个线程被显式地关闭之前，池 中的线程将一直存在。
特征:
线程池中的线程处于一定的量，可以很好的控制线程的并发量 • 线程可以重复被使用，在显示关闭之前，都将一直存在 超出一定量的线程被提交时候需在队列中等待 2）Executors.newSingleThreadExecutor() 一池1线程
作用:创建一个使用单个 worker 线程的 Executor，以无界队列方式来运行该 线程。(注意，如果因为在关闭前的执行期间出现失败而终止了此单个线程， 那么如果需要，一个新线程将代替它执行后续的任务)。可保证顺序地执行各 个任务，并且在任意给定的时间不会有多个线程是活动的。与其他等效的 newFixedThreadPool 不同，可保证无需重新配置此方法所返回的执行程序即 可使用其他的线程。
特征: 线程池中最多执行 1 个线程，之后提交的线程活动将会排在队列中以此执行
3）Executors.newCachedThreadPool() 一池可扩容的线程，根据需求创建线程，可扩容，遇强则强
作用:创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程.
特点:
线程池中数量没有固定，可达到最大值(Interger. MAX_VALUE) 线程池中的线程可进行缓存重复利用和回收(回收默认时间为 1 分钟) 当线程池中，没有可用线程，会重新创建一个线程 超出一定量的线程被提交时候需在队列中等待 场景: 适用于创建一个可无限扩大的线程池，服务器负载压力较轻，执行时间较 短，任务多的场景
4）ThreadPoolExecutor() 上述三种创建方式都使用了ThreadPoolExecutor方法来创建
int corePoolSize 线程池的核心线程数 int maximumPoolSize 能容纳的最大线程数 long keepAliveTime 空闲线程存活时间 TimeUnit unit 存活的时间单位 BlockingQueue workQueue 阻塞队列，常驻线程数量已经用完了，剩下的请求都放到阻塞队列里面存放，提交但未执行任务的队列。 ThreadFactory threadFactory 创建线程的工厂类 RejectedExecutionHandler handler 等待队列满后的拒绝策略，拒绝策略 4、线程池底层原理 ThreadPoolExecutor()
5、线程池的七个参数 int corePoolSize 线程池的核心线程数 int maximumPoolSize 能容纳的最大线程数 long keepAliveTime 空闲线程存活时间 TimeUnit unit 存活的时间单位 BlockingQueue workQueue 阻塞队列，常驻线程数量已经用完了，剩下的请求都放到阻塞队列里面存放，提交但未执行任务的队列。 ThreadFactory threadFactory 创建线程的工厂类 RejectedExecutionHandler handler 等待队列满后的拒绝策略，拒绝策略 6、线程池底层工作流程 ![image-20220730205848256](/Users/mac/Library/Application Support/typora-user-images/image-20220730205848256.png)
第一步先进corePool常驻线程
第二步进阻塞队列
第三步线程6进入maximumPool里新建线程放到corePool下面
在创建了线程池后，线程池中的线程数为零
当调用execute()方法添加一个请求任务时，线程池会做出如下判断:2.1如
果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务; 2.2 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入 队列; 2.3 如果这个时候队列满了且正在运行的线程数量还小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务; 2.4 如 果队列满了且正在运行的线程数量大于或等于 maximumPoolSize，那么线程 池会启动饱和拒绝策略来执行。
当一个线程完成任务时，它会从队列中取下一个任务来执行
当一个线程无事可做超过一定的时间(keepAliveTime)时，线程会判断:
4.1 如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。 4.2 所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。
第9个线程进来会执行拒绝策略
1）拒绝策略 **AbortPolicy：**直接抛出RejectedExecutionException异常阻止系统正常运行
**CallerRunsPolicy：**调用者运行，一种调节机制，该策略不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者，从而降低新任务的流量
**DiscardOldestPolicy：**抛弃队列中等待最久的任务，然后把当前任务加入队列中尝试再次提交当前任务。
**DiscardPolicy：**该策略默默的丢弃无法处理的任务，不予任何处理也不抛出异常。如果允许任务丢失，这是最好的一种策略
7、自定义线程池 ExecutorService threadPool = new ThreadPoolExecutor( 2, 5, 2L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;>(3), Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy() ); try { for (int i = 1; i &lt;= 10; i++) { threadPool.execute(() -> { System.out.println(Thread.currentThread().getName() + "办理业务"); }); } }catch (Exception e) { e.printStackTrace(); }finally { threadPool.shutdown(); }</content></entry><entry><title>Java进阶-多线程并发</title><url>https://zhang4014439175.github.io/post/%E5%B9%B6%E5%8F%91/</url><categories><category>Java-Advanced</category><category>并发</category></categories><tags><tag>Java</tag><tag>并发</tag><tag>锁</tag><tag>多线程</tag></tags><content type="html">  多线程并发是后端开发中常见问题，也是最难解决的问题，下功夫多研究研究，本文档是java juc 的学习笔记。
一、什么是 JUC 1、进程和线程
进程是计算机中的程序关于某数据集合上的一次运行活动，是系 统进行资源分配和调度的基本单位，是操作系统结构的基础。 在当代面向线程 设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的 描述，进程是程序的实体。是计算机中的程序关于某数据集合上的一次运行活 动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。程序是 指令、数据及其组织形式的描述，进程是程序的实体。
线程 是操作系统能够进行运算调度的最小单位。它被包含在进程之 中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流， 一个进程中可以并发多个线程，每条线程并行执行不同的任务。
总结来说
进程：指在系统中正在运行的一个应用程序;程序一旦运行就是进程;进程— —资源分配的最小单位。
线程：系统分配处理器时间资源的基本单元，或者说进程之内独立执行的一个 单元执行流。线程——程序执行的最小单位。
1.1线程的状态
2、wait和sleep
(1)sleep 是 Thread 的静态方法，wait 是 Object 的方法，任何对象实例都 能调用。
(2)sleep 不会释放锁，它也不需要占用锁。wait 会释放锁，但调用它的前提 是当前线程占有锁(即代码要在 synchronized 中)。
(3)它们都可以被 interrupted 方法中断。
3、并行和串行
**串行：**表示所有任务都一一按先后顺序进行。串行意味着必须先装完一车柴才能 运送这车柴，只有运送到了，才能卸下这车柴，并且只有完成了这整个三个步 骤，才能进行下一个步骤。串行是一次只能取得一个任务，并执行这个任务。
**并行：**意味着可以同时取得多个任务，并同时去执行所取得的这些任务。并行模 式相当于将长长的一条队列，划分成了多条短队列，所以并行缩短了任务队列 的长度。并行的效率从代码层次上强依赖于多进程/多线程代码，从硬件角度上 则依赖于多核 CPU。
并发(concurrent)：指的是多个程序可以同时运行的现象，更细化的是多进程可 以同时运行或者多指令可以同时运行。但这不是重点，在描述并发的时候也不 会去扣这种字眼是否精确，==并发的重点在于它是一种现象==, ==并发描述 的是多进程同时运行的现象==。但实际上，对于单核心 CPU 来说，同一时刻 只能运行一个线程。所以，这里的"同时运行"表示的不是真的同一时刻有多个 线程运行的现象，这是并行的概念，而是提供一种功能让用户看来多个程序同 时运行起来了，但实际上这些程序中的进程不是一直霸占 CPU 的，而是执行一 会停一会。
**管程(monitor)：**是保证了同一时刻只有一个进程在管程内活动,即管程内定义的操作在同 一时刻只被一个进程调用(由编译器实现).但是这样并不能保证进程以设计的顺序执行
JVM 中同步是基于进入和退出管程(monitor)对象实现的，每个对象都会有一个管程 (monitor)对象，管程(monitor)会随着 java 对象一同创建和销毁
执行线程首先要持有管程对象，然后才能执行方法，当方法完成之后会释放管程，方 法在执行时候会持有管程，其他线程无法再获取同一个管程
用户线程和守护线程：
用户线程：平时用到的普通线程,自定义线程
守护线程：运行在后台,是一种特殊的线程,比如垃圾回收
当主线程结束后,用户线程还在运行,JVM存活
如果没有用户线程,都是守护线程,JVM结束
isDaemon() 是否守护线程
setDaemon(true) 设置守护线程
1、线程的生命周期 state枚举：新建、就绪、运行、阻塞、死亡
suspend挂起：已经过时了
sleep
join
2、同步的操作 1）知识 共享数据：ticketnum就是共享数据
同步监视器：锁，任何一个类的对象，都可以充当锁
要求：多个线程必须同用一把锁
2） this表示同步监视器
public class Window1 implements Runnable{ private int ticket = 10000; Object object = new Object(); @Override public void run() { while (true) { synchronized (object) { if (ticket > 0) { ticket--; System.out.println(Thread.currentThread().getName() + "卖票，剩余 ： " + ticket); } else { break; } } } } } 二、Lock类 1、Synchronized
2.1.1 Synchronized 关键字回顾
synchronized 是 Java 中的关键字，是一种同步锁。它修饰的对象有以下几种:
修饰一个代码块，被修饰的代码块称为同步语句块，其作用的范围是大括号{} 括起来的代码，作用的对象是调用这个代码块的对象; 修饰一个方法，被修饰的方法称为同步方法，其作用的范围是整个方法，作用 的对象是调用这个方法的对象; 虽然可以使用 synchronized 来定义方法，但 synchronized 并不属于方法定 义的一部分，因此，synchronized 关键字不能被继承。如果在父类中的某个方 法使用了 synchronized 关键字，而在子类中覆盖了这个方法，在子类中的这 个方法默认情况下并不是同步的，而必须显式地在子类的这个方法中加上 synchronized 关键字才可以。当然，还可以在子类方法中调用父类中相应的方 法，这样虽然子类中的方法不是同步的，但子类调用了父类的同步方法，因此， 子类的方法也就相当于同步了。
修改一个静态的方法，其作用的范围是整个静态方法，作用的对象是这个类的 所有对象
修改一个类，其作用的范围是synchronized后面括号括起来的部分，作用主 的对象是这个类的所有对象。
如果一个代码块被 synchronized 修饰了，当一个线程获取了对应的锁，并执 行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里 获取锁的线程释放锁只会有两种情况:
1)获取锁的线程执行完了该代码块，然后线程释放对锁的占有;
2)线程执行发生异常，此时 JVM 会让线程自动释放锁。
那么如果这个获取锁的线程由于要等待 IO 或者其他原因(比如调用 sleep 方法)被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，试想一 下，这多么影响程序执行效率。
因此就需要有一种机制可以不让等待的线程一直无期限地等待下去(比如只等 待一定的时间或者能够响应中断)，通过 Lock 就可以办到。
三、线程间的通信 1、Synchronized方案 class Ticket { //票数 private int number = 30; //操作方法:卖票 public synchronized void sale() { //判断:是否有票 if(number > 0) { System.out.println(Thread.currentThread().getName()+" : "+(number--)+" "+number); } } } new Thread(new Runnable() { @Override public void run() { //调用卖票 for (int i = 0; i &lt; 40; i++) { ticket.sale(); } } }, "AA").start(); 2、Lock 提供了比synchronized方法和语句可获得的更广泛的锁定操作
可重入锁：
Lock与Synchronize的区别：
1）创建资源类，在资源类创建属性和操作方法
2）在资源类操作方法
​ 判断
​ 干活
​ 通知
3）创建多个线程，调用资源类的操作方法
4）避免虚假唤醒
public void sale() { lock.lock(); try { //判断是否有票可卖 if (number > 0) { System.out.println(Thread.currentThread().getName() + " : 卖出: " + number-- + "剩下： " + number); } }finally { //解锁、释放锁 lock.unlock(); } } 3、Condition lock.ThreadDemo2
是一个多线程协调通信的工具类，可以让某些线程一起等待某个条件（condition），只有满足条件时，线程才会被唤醒。
class Share { private int number = 0; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void incr () throws InterruptedException { lock.lock(); try { //判断 while (number != 0) { condition.await(); } //干活 number++; //通知 System.out.println(Thread.currentThread().getName() + " :: " + number); condition.signalAll(); }finally { lock.unlock(); } } public void decr () throws InterruptedException { lock.lock(); try { //判断 while (number != 1) { condition.await(); } //干活 number--; //通知 System.out.println(Thread.currentThread().getName() + " :: " + number); condition.signalAll(); }finally { lock.unlock(); } } } new Thread(() -> { for (int i = 1; i &lt;= 10; i++) { try { share.incr(); } catch (InterruptedException e) { e.printStackTrace(); } } },"AA").start(); new Thread(() -> { for (int i = 1; i &lt;= 10; i++) { try { share.decr(); } catch (InterruptedException e) { e.printStackTrace(); } } },"BB").start(); 4、虚假唤醒 aa + 1、 bb - 1、 cc + 1、 dd - 1
wait()在哪里睡的，就会在哪里醒，就会直接跳过判断的逻辑
if(number != 0) { this.wait(); 在这里睡，就会在这里醒来 } 解决方案就是换成while循环，以避免虚假唤醒 while(number != 0) { this.wait(); 在这里睡，就会在这里醒来 } 四、线程间定制化通信 Lock.ThreadDemo03
flag = 1 AA C1 打印5次，修改标志位flag = 2 ，通知BB
flag = 2 BB C2 打印10次，修改标志位flag = 3 ，通知CC
flag = 3 CC C3 打印15次，修改标志位flag = 1 ，通知AA
五、集合的线程安全 lock.ThreadDemo4
1、ArrayList线程安全问题 1）concurrentModificationException演示
List&lt;String> list = new ArrayList&lt;>(); for (int i = 0; i &lt; 30; i++) { new Thread(() -> { list.add(UUID.randomUUID().toString().substring(0, 8)); System.out.println(list); }, String.valueOf(i)).start(); } 2）解决方案Vector
List&lt;String> list = new Vector&lt;>(); 3）解决方案Collections
List&lt;String> list = Collections.synchronizedList(new ArrayList&lt;>()); 4）解决方案CopyOnWriteArrayList
List&lt;String> list = new CopyOnWriteArrayList&lt;>(); CopyOnWrite写时复制技术：
支持并发读和独立写，复制一块相同大小的区域，读之前的东西，往复制的区域里面写
两个区域进行和并，最后读新的区域内容
2、hashSet 1）解决方案CopyOnWriteArrayList
3、hashMap 1）解决方案ConcurrentHashMap
4、单例模式之懒汉式 SingleTest
class Bank { private Bank(){} private static Bank instance = null; private static synchronized Bank getInstance() { if (instance == null) { instance = new Bank(); } return instance; } } //效率差 class Bank { private Bank(){} private static Bank instance = null; private static Bank getInstance() { synchronized(Bank.class) { if (instance == null) { instance = new Bank(); } return instance; } } } //效率高,双重校验 class Bank { private Bank(){} private static Bank instance = null; private static Bank getInstance() { if (instance == null) { synchronized(Bank.class) { if (instance == null) { instance = new Bank(); } } } return instance; } } 六、多线程锁 1、锁的八种情况 锁的作用域
结论:
一个对象里面如果有多个 synchronized 方法，某一个时刻内，只要一个线程去调用其中的 一个 synchronized 方法了， 其它的线程都只能等待，换句话说，某一个时刻内，只能有唯一一个线程去访问这些 synchronized 方法
锁的是当前对象 this，被锁定后，其它的线程都不能进入到当前对象的其它的 synchronized 方法 加个普通方法后发现和同步锁无关 换成两个对象后，不是同一把锁了，情况立刻变化。
synchronized 实现同步的基础:Java 中的每一个对象都可以作为锁。 具体表现为以下 3 种形式。 对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的 Class 对象。 对于同步方法块，锁是 Synchonized 括号里配置的对象 当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。 也就是说如果一个实例对象的非静态同步方法获取锁后，该实例对象的其他非静态同步方 法必须等待获取锁的方法释放锁后才能获取锁， 可是别的实例对象的非静态同步方法因为跟该实例对象的非静态同步方法用的是不同的锁， 所以毋须等待该实例对象已获取锁的非静态同步方法释放锁就可以获取他们自己的锁。 所有的静态同步方法用的也是同一把锁——类对象本身，这两把锁是两个不同的对象，所 以静态同步方法与非静态同步方法之间是不会有竞态条件的。 但是一旦一个静态同步方法获取锁后，其他的静态同步方法都必须等待该方法释放锁后才 能获取锁，而不管是同一个实例对象的静态同步方法之间，还是不同的实例对象的静态同 步方法之间，只要它们同一个类的实例对象!
2、公平锁和非公平锁 公平锁：阳光普照，效率相对较低
非公平锁：造成一个线程把活都干了，会出现线程饿死的情况
三个售票员同时卖票
private Lock lock = new ReentrantLock(true); //ReentrantLock源码 public ReentrantLock() { sync = new NonfairSync(); } public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } 3、可重入锁 可重入锁：又叫递归锁，就是拥有了这把锁之后可以进入所有需要这把锁的地方
synchronized和lock都是可重入锁
synchronized是隐式、lock显式
new Thread(() -> { synchronized (o) { System.out.println(Thread.currentThread().getName() + " :: " + "外"); synchronized (o) { System.out.println(Thread.currentThread().getName() + " :: " + "中"); synchronized (o) { System.out.println(Thread.currentThread().getName() + " :: " + "内"); } } } }).start(); 递归锁
public synchronized void add() { add(); } new SyncLockDemo().add(); 4、死锁 lock.DeadLock
两个或两个以上的进程在执行过程中，因为争夺资源而造成一种互相等待的现象，如果没有外力干涉，他们无法再执行下去。
1）产生死锁的原因：
​ 系统资源不足
​ 进程运行推进顺序不合适
​ 资源分配不当
2）死锁的实现
new Thread(() -> { synchronized (a) { System.out.println(Thread.currentThread().getName() + "持有锁a， 视图获取锁b"); synchronized (b) { System.out.println(Thread.currentThread().getName() + "获取锁b"); } } }, "A").start(); new Thread(() -> { synchronized (b) { System.out.println(Thread.currentThread().getName() + "持有锁b， 视图获取锁a"); synchronized (a) { System.out.println(Thread.currentThread().getName() + "获取锁a"); } } }, "B").start(); 3）验证是否是死锁
​ ①jps，类似linux、ps -ef
​ ②jstack jvm自带堆栈的跟踪工具
Jps -l
Jstack 89810
七、创建线程的多种方式 1、继承Thread类 2、实现Runnable接口 3、Callable接口 ​ @FunctionalInterface函数式接口，可以使用lam表达式做简化
​ callable可以得到线程的返回结果
Callable和Runnable的区别：
1）是否有返回值
2）是否抛出异常
3）实现方法名称不同 run call
new Thread不能直接替换runnable，因为Thread类的构造方法根本没有Callable
找一个callable和runnable都有关系的类，FutureTask类
4、FutureTask FutureTask构造可以传递Callable
当 call()方法完成时，结果必须存储在主线程已知的对象中，以便主线程可 以知道该线程返回的结果。为此，可以使用 Future 对象。
Java 库具有具体的 FutureTask 类型，该类型实现 Runnable 和 Future，并方 便地将两种功能组合在一起。 可以通过为其构造函数提供 Callable 来创建 FutureTask。然后，将 FutureTask 对象提供给 Thread 的构造函数以创建 Thread 对象。因此，间接地使用 Callable 创建线程。
核心原理：
在主线程中需要执行比较耗时的操作时，但又不想阻塞主线程时，可以把这些 作业交给 Future 对象在后台完成
当主线程将来需要时，就可以通过 Future 对象获得后台作业的计算结果或者执 行状态 一般 FutureTask 多用于耗时的计算，主线程可以在完成自己的任务后，再去 获取结果。 仅在计算完成时才能检索结果;如果计算尚未完成，则阻塞 get 方法 一旦计算完成，就不能再重新开始或取消计算 get 方法而获取结果只有在计算完成时获取，否则会一直阻塞直到任务转入完成状态，然后会返回结果或者抛出异常 get 只计算一次,因此 get 方法放到最后 5、线程池方式 八、JUC强大的辅助类 1、减少计数CountDownLatch CountDownLatch 类可以设置一个计数器，然后通过 countDown 方法来进行 减 1 的操作，使用 await 方法等待计数器不大于 0，然后继续执行 await 方法 之后的语句。 CountDownLatch 主要有两个方法，当一个或多个线程调用 await 方法时，这 些线程会阻塞 其它线程调用 countDown 方法会将计数器减 1(调用 countDown 方法的线程 不会阻塞) 当计数器的值变为 0 时，因 await 方法阻塞的线程会被唤醒，继续执行 6个同学陆续离开教室后值班同学才可以关门
//创建CountDownLatch对象，设置初始值 CountDownLatch countDownLatch = new CountDownLatch(6); //6个同学陆续离开教室之后 for (int i = 1; i &lt;= 6; i++) { new Thread(() -> { System.out.println(Thread.currentThread().getName() + "同学离开教室"); countDownLatch.countDown(); },String.valueOf(i)).start(); } countDownLatch.await(); System.out.println(Thread.currentThread().getName() + " 班长锁门走人了"); 2、循环栅栏CyclicBarrier CyclicBarrier 看英文单词可以看出大概就是循环阻塞的意思，在使用中 CyclicBarrier 的构造方法第一个参数是目标障碍数，每次执行 CyclicBarrier 一 次障碍数会加一，如果达到了目标障碍数，才会执行 cyclicBarrier.await()之后 的语句。可以将 CyclicBarrier 理解为加 1 操作
例子：集齐7颗龙珠就可以召唤神龙
CyclicBarrier cyclicBarrier = new CyclicBarrier(NUMBER, () -> { System.out.println("集齐7颗龙珠可以召唤神龙"); }); for (int i = 1; i &lt; 7; i++) { new Thread(() -> { try { System.out.println(Thread.currentThread().getName() + "星龙珠被收集了"); cyclicBarrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }).start(); } 3、信号灯Semaphore Semaphore 的构造方法中传入的第一个参数是最大信号量(可以看成最大线 程池)，每个信号量初始化为一个最多只能分发一个许可证。使用 acquire 方 法获得许可证，release 方法释放许可
场景: 抢车位, 6 部汽车 3 个停车位
//创建具有给定的许可数和非公平的公平设置的Semaphore Semaphore(int permits) //创建具有给定的许可数和给定的公平设置的Semaphore Semaphore(int permits, boolean fair) 方法
acquair() 例子：
Semaphore semaphore = new Semaphore(3); for (int i = 1; i &lt;= 6; i++) { new Thread(() -> { try { semaphore.acquire(); System.out.println(Thread.currentThread().getName() + "抢到了车位"); TimeUnit.SECONDS.sleep(new SecureRandom().nextInt(5)); System.out.println(Thread.currentThread().getName() + "离开车位"); }catch (InterruptedException e) { e.printStackTrace(); }finally { semaphore.release(); } }).start(); } 九、读写锁 1、乐观锁、悲观锁 悲观锁：不支持并发
乐观锁：支持并发
2、表锁、行锁 表锁：对整张表上锁，表锁会产生死锁
行锁：对行上锁
3、读锁、写锁 读锁：共享锁，发生死锁
写锁：独占锁，发生死锁
线程1修改的时候，需要等待线程2读之后
线程2修改的时候，需要等待线程1读之后
4、读写锁ReadWriteLock 1）读写锁介绍
一个资源可以被多个读线程访问，或者被一个写线程访问，不能同事存在读写线程，读写互斥，读读共享
线程进入读锁的前提条件: 没有其他线程的写锁 没有写请求, 或者==有写请求，但调用线程和持有锁的线程是同一个(可重入锁)。== 线程进入写锁的前提条件: 没有其他线程的读锁
没有其他线程的写锁
而读写锁有以下三个重要的特性:
(1)公平选择性:支持非公平(默认)和公平的锁获取方式，吞吐量还是非公 平优于公平。
(2)重进入:读锁和写锁都支持线程重进入。
(3)锁降级:遵循获取写锁、获取读锁再释放写锁的次序，写锁能够降级成为 读锁。
2）读写锁演进
① 无锁：
​ 多线程抢夺
②添加锁：
​ 使用synchronized和ReentrantLock都是独占，每次只能一个操作，读读，读写，写写
③读写锁：
​ ReentrantReadWriteLock
​ 读读共享，提升性能，写写独占
​ 缺点一：造成锁饥饿，一直读，没有写操作，比如做地铁
​ 缺点二：读时候，不能写，只有读完之后，才可以写。写可以读，降级为读锁
3）读写锁使用案例
class MyCache { private volatile Map&lt;String, Object> map = new HashMap&lt;>(); private ReadWriteLock rwLock = new ReentrantReadWriteLock(); public void put(String key, Object value) { rwLock.writeLock().lock(); //暂停一会 try { System.out.println(Thread.currentThread().getName() + "正在写操作" + key); TimeUnit.MILLISECONDS.sleep(300); map.put(key, value); System.out.println(Thread.currentThread().getName() + "写完了" + key); } catch (InterruptedException e) { e.printStackTrace(); }finally { rwLock.writeLock().unlock(); } } //取数据 public Object get(String key) { Object result = null; rwLock.readLock().lock(); try { System.out.println(Thread.currentThread().getName() + "正在读取操作" + key); TimeUnit.MILLISECONDS.sleep(300); result = map.get(key); System.out.println(Thread.currentThread().getName() + "取到了" + key); } catch (InterruptedException e) { e.printStackTrace(); }finally { rwLock.readLock().unlock(); } return result; } } public class ReadWriteLockDemo { public static void main(String[] args) { MyCache myCache = new MyCache(); //创建线程放数据 for (int i = 1; i &lt;= 5; i++) { final int num = i; new Thread(() -> { myCache.put(num + "", num + ""); }, String.valueOf(i)).start(); } for (int i = 1; i &lt;= 5; i++) { final int num = i; new Thread(() -> { myCache.get(num + ""); }, String.valueOf(i)).start(); } } } //写是独占锁，读是共享锁 2正在写操作2 2写完了2 3正在写操作3 3写完了3 4正在写操作4 4写完了4 5正在写操作5 5写完了5 1正在写操作1 1写完了1 1正在读取操作1 3正在读取操作3 4正在读取操作4 2正在读取操作2 5正在读取操作5 5取到了5 4取到了4 2取到了2 3取到了3 1取到了1 4）锁降级：
将写入锁降级为读锁
获取写锁、获取读锁、释放写锁、释放读锁
ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock(); ReentrantReadWriteLock.ReadLock readLock = rwLock.readLock(); ReentrantReadWriteLock.WriteLock writeLock = rwLock.writeLock(); writeLock.lock(); System.out.println("上写锁"); readLock.lock(); System.out.println("上读锁"); writeLock.unlock(); System.out.println("释放写锁"); readLock.unlock(); System.out.println("释放读锁"); 十、阻塞队列BlockingQueue 队列：先进先出
栈：后进先出
![image-20220730154428259](/Users/mac/Library/Application Support/typora-user-images/image-20220730154428259.png)
当队列是空的，从队列中获取元素的操作将会被阻塞
当队列是满的，从队列中添加元素的操作将会被阻塞
试图从空的队列中获取元素的线程将会被阻塞，直到其他线程往空的队列插入新的元素
试图向已满的队列中添加新元素的线程将会被阻塞，直到其他线程从队列中移除一个或多 个元素或者完全清空，使队列变得空闲起来并后续新增
为什么需要 BlockingQueue
好处是我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切 BlockingQueue 都给你一手包办了
在 concurrent 包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细 节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。
1）阻塞队列的基本架构 2）阻塞队列的分类 ArrayBlockingQueue
基于数组的阻塞队列实现，在 ArrayBlockingQueue 内部，维护了一个定长数 组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数 组外，ArrayBlockingQueue 内部还保存着两个整形变量，分别标识着队列的 头部和尾部在数组中的位置。
ArrayBlockingQueue 在生产者放入数据和消费者获取数据，都是共用同一个 锁对象，由此也意味着两者无法真正并行运行，这点尤其不同于 LinkedBlockingQueue;按照实现原理来分析，ArrayBlockingQueue 完全可 以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea 之 所以没这样去做，也许是因为 ArrayBlockingQueue 的数据写入和获取操作已 经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其 在性能上完全占不到任何便宜。 ArrayBlockingQueue 和 LinkedBlockingQueue 间还有一个明显的不同之处在于，前者在插入或删除 元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的 Node 对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于 GC 的影响还是存在一定的区别。而在创建 ArrayBlockingQueue 时，我们还 可以控制对象的内部锁是否采用公平锁，默认采用非公平锁。
一句话总结：由数组结构组成的有界阻塞队列。
LinkedBlockingQueue
基于链表的阻塞队列，同 ArrayListBlockingQueue 类似，其内部也维持着一 个数据缓冲队列(该队列由一个链表构成)，当生产者往队列中放入一个数据 时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回; 只有当队列缓冲区达到最大值缓存容量时(LinkedBlockingQueue 可以通过 构造函数指定该值)，才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。 而 LinkedBlockingQueue 之所以能够高效的处理并发数据，还因为其对于生 产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发 的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列 的并发性能。
ArrayBlockingQueue 和 LinkedBlockingQueue 是两个最普通也是最常用 的阻塞队列，一般情况下，在处理多线程间的生产者消费者问题，使用这两个 类足以。
9.4.3 DelayQueue
DelayQueue 中的元素只有当其指定的延迟时间到了，才能够从队列中获取到 该元素。DelayQueue 是一个没有大小限制的队列，因此往队列中插入数据的 操作(生产者)永远不会被阻塞，而只有获取数据的操作(消费者)才会被阻 塞。
==一句话总结**:** 使用优先级队列实现的延迟无界阻塞队列。==
9.4.4 PriorityBlockingQueue
基于优先级的阻塞队列(优先级的判断通过构造函数传入的 Compator 对象来 决定)，但需要注意的是 PriorityBlockingQueue 并不会阻塞数据生产者，而 只会在没有可消费的数据时，阻塞数据的消费者。
因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费 数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。
在实现 PriorityBlockingQueue 时，内部控制线程同步的锁采用的是公平锁。 ==一句话总结**:** 支持优先级排序的无界阻塞队列。==
9.4.5 SynchronousQueue
一种无缓冲的等待队列，类似于无中介的直接交易，有点像原始社会中的生产 者和消费者，生产者拿着产品去集市销售给产品的最终消费者，而消费者必须 亲自去集市找到所要商品的直接生产者，如果一方没有找到合适的目标，那么 对不起，大家都在集市等待。相对于有缓冲的 BlockingQueue 来说，少了一 个中间经销商的环节(缓冲区)，如果有经销商，生产者直接把产品批发给经 销商，而无需在意经销商最终会将这些产品卖给那些消费者，由于经销商可以 库存一部分商品，因此相对于直接交易模式，总体来说采用中间经销商的模式 会吞吐量高一些(可以批量买卖);但另一方面，又因为经销商的引入，使得 产品从生产者到消费者中间增加了额外的交易环节，单个产品的及时响应性能 可能会降低。
声明一个 SynchronousQueue 有两种不同的方式，它们之间有着不太一样的行为。
公平模式和非公平模式的区别：
公平模式:SynchronousQueue 会采用公平锁，并配合一个 FIFO 队列来阻塞 多余的生产者和消费者，从而体系整体的公平策略; 非公平模式(SynchronousQueue 默认):SynchronousQueue 采用非公平 锁，同时配合一个 LIFO 队列来管理多余的生产者和消费者，而后一种模式， 如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有 某些生产者或者是消费者的数据永远都得不到处理。 ==一句话总结**:** 不存储元素的阻塞队列，也即单个元素的队列。==
9.4.6 LinkedTransferQueue
LinkedTransferQueue 是一个由链表结构组成的无界阻塞 TransferQueue 队 列。相对于其他阻塞队列，LinkedTransferQueue 多了 tryTransfer 和 transfer 方法。
LinkedTransferQueue 采用一种预占模式。意思就是消费者线程取元素时，如 果队列不为空，则直接取走数据，若队列为空，那就生成一个节点(节点元素 为 null)入队，然后消费者线程被等待在这个节点上，后面生产者线程入队时 发现有一个元素为 null 的节点，生产者线程就不入队了，直接就将元素填充到该节点，并唤醒该节点等待的线程，被唤醒的消费者线程取走元素，从调用的方法返回。
==一句话总结**:** 由链表组成的无界阻塞队列。==
9.4.7 LinkedBlockingDeque
LinkedBlockingDeque 是一个由链表结构组成的双向阻塞队列，即可以从队 列的两端插入和移除元素。对于一些指定的操作，在插入或者获取队列元素时如果队列状态不允许该操作可能会阻塞住该线程直到队列状态变更为允许操作，这里的阻塞一般有两种情况。
插入元素时: 如果当前队列已满将会进入阻塞状态，一直等到队列有空的位置时 再讲该元素插入，该操作可以通过设置超时参数，超时后返回 false 表示操作 失败，也可以不设置超时参数一直阻塞，中断后抛出 InterruptedException 异 常
读取元素时: 如果当前队列为空会阻塞住直到队列不为空然后返回元素，同样可 以通过设置超时参数
==一句话总结**:** 由链表组成的双向阻塞队列==
3）阻塞队列的核心方法 ![image-20220730160222323](/Users/mac/Library/Application Support/typora-user-images/image-20220730160222323.png)
1.放入数据
offer(anObject):表示如果可能的话,将 anObject 加到 BlockingQueue 里,即 如果 BlockingQueue 可以容纳,则返回 true,否则返回 false.(本方法不阻塞当 前执行方法的线程)
offer(E o, long timeout, TimeUnit unit):可以设定等待的时间，如果在指定 的时间内，还不能往队列中加入 BlockingQueue，则返回失败
put(anObject):把 anObject 加到 BlockingQueue 里,如果 BlockQueue 没有 空间,则调用此方法的线程被阻断直到 BlockingQueue 里面有空间再继续.
2.获取数据
poll(time): 取走 BlockingQueue 里排在首位的对象,若不能立即取出,则可以等 time 参数规定的时间,取不到时返回 null
poll(long timeout, TimeUnit unit):从 BlockingQueue 取出一个队首的对象， 如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则知 道时间超时还没有数据可取，返回失败。
take(): 取走 BlockingQueue 里排在首位的对象,若 BlockingQueue 为空,阻断 进入等待状态直到 BlockingQueue 有新的数据被加入;
drainTo(): 一次性从 BlockingQueue 获取所有可用的数据对象(还可以指定 获取数据的个数)，通过该方法，可以提升获取数据效率;不需要多次分批加 锁或释放锁。
4）小结 1. 在多线程领域:所谓阻塞，在某些情况下会挂起线程(即阻塞)，一旦条件 满足，被挂起的线程又会自动被唤起
2. 为什么需要 BlockingQueue?
在 concurrent 包发布以前，在多线程环境下， 我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全， 而这会给我们的程序带来不小的复杂度。
使用后我们不需要关心什么时候需要 阻塞线程，什么时候需要唤醒线程，因为这一切 BlockingQueue 都给你一手 包办了
十一、Fork/Join **Fork：**把一个负责任务进行分拆，大事化小
**Join：**把分拆任务的结果进行合并
Executor &lt;- ExecutorService &lt;- AbstractExecutorService &lt;- ForkJoinPool
Future &lt;- ForkJoinTask &lt;- RecursiveTask
class MyTask extends RecursiveTask&lt;Integer> { //拆分差值不能超过10 private static final Integer VALUE = 10; private int begin; private int end; private int result; public MyTask(int begin, int end) { this.begin = begin; this.end = end; } @Override protected Integer compute() { //判断相加两个数值是否大于10 if ((end - begin) &lt;= VALUE) { for (int i = begin; i &lt;= end; i++) { result = result + i; } }else { int middle = (begin + end) / 2; //拆分左边 MyTask task1 = new MyTask(begin, middle); //拆分右边 MyTask task2 = new MyTask(middle + 1, end); //调用方法拆分 task1.fork(); task2.fork(); //合并结果 result = task1.join() + task2.join(); } return result; } } public class ForkJoinDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { //创建MyTask MyTask myTask = new MyTask(0, 100); //创建分支合并池对象 ForkJoinPool forkJoinPool = new ForkJoinPool(); ForkJoinTask&lt;Integer> forkJoinTask = forkJoinPool.submit(myTask); //获取最终合并之后结果 Integer result = forkJoinTask.get(); System.out.println(result); //关闭池对象 forkJoinPool.shutdown(); } }</content></entry><entry><title>Java框架-Spring设计思想</title><url>https://zhang4014439175.github.io/post/springmvc%E4%B8%80/</url><categories><category>Java-Framework</category><category>Spring</category></categories><tags><tag>Java</tag><tag>框架</tag><tag>Spring</tag></tags><content type="html"> 一、简介 1、介绍 封装了servlet
MVC是一种软件架构的思想，将软件按照模型、视图、控制器来划分
M:Model，模型层，指工程中的JavaBean，作用是处理数据
JavaBean分为两类:
一类称为实体类Bean:专门存储业务数据的，如 Student、User 等 一类称为业务处理 Bean:指 Service 或 Dao 对象，专门用于处理业务逻辑和数据访问。
2、特点 Spring 家族原生产品，与 IOC 容器等基础设施无缝对接
基于原生的Servlet**，通过了功能强大的**前端控制器DispatcherServlet，对请求和响应进行统一处理
表述层各细分领域需要解决的问题全方位覆盖**，提供**全面解决方案
代码清新简洁**，大幅度提升开发效率 **
内部组件化程度高，可插拔式组件即插即用**，想要什么功能配置相应组件即可 **
性能卓著，尤其适合现代大型、超大型互联网项目要求
3、入门案例 IDE：idea 2019.2
构建工具：maven3.5.4
服务器：tomcat8.5
Spring版本：5.3.1
3.1、引入依赖 &lt;dependencies> &lt;!-- SpringMVC --> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-webmvc&lt;/artifactId> &lt;version>5.3.1&lt;/version> &lt;/dependency> &lt;!-- 日志 --> &lt;dependency> &lt;groupId>ch.qos.logback&lt;/groupId> &lt;artifactId>logback-classic&lt;/artifactId> &lt;version>1.2.3&lt;/version> &lt;/dependency> &lt;!-- ServletAPI --> &lt;dependency> &lt;groupId>javax.servlet&lt;/groupId> &lt;artifactId>javax.servlet-api&lt;/artifactId> &lt;version>3.1.0&lt;/version> &lt;scope>provided&lt;/scope> &lt;/dependency> &lt;!-- Spring5和Thymeleaf整合包 --> &lt;dependency> &lt;groupId>org.thymeleaf&lt;/groupId> &lt;artifactId>thymeleaf-spring5&lt;/artifactId> &lt;version>3.0.12.RELEASE&lt;/version> &lt;/dependency> &lt;/dependencies> 3.2、配置web.xml 注册SpringMVC的前端控制器DispatcherServlet，视图控制器来接收所有请求，转换为controller请求，然后进行跳转
1）默认配置方式
自己配置到src/main/webapp/WEB-INF/web.xml
此配置作用下，SpringMVC的配置文件默认位于WEB-INF下，默认名称为- servlet.xml，例如，以下配置所对应SpringMVC的配置文件位于WEB-INF下，文件名为springMVC- servlet.xml
&lt;!-- 配置SpringMVC的前端控制器，对浏览器发送的请求统一进行处理 --> &lt;servlet> &lt;servlet-name>springMVC&lt;/servlet-name> &lt;servlet-class>org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class> &lt;/servlet> &lt;servlet-mapping> springMVC-servlet.xml &lt;servlet-name>springMVC&lt;/servlet-name> &lt;!--设置springMVC的核心控制器所能处理的请求的请求路径 /所匹配的请求可以是/login或.html或.js或.css方式的请求路径 但是/不能匹配.jsp请求路径的请求--> &lt;url-pattern>/&lt;/url-pattern> &lt;/servlet-mapping> 2）扩展配置方式
可通过init-param标签设置SpringMVC配置文件的位置和名称，通过load-on-startup标签设置 SpringMVC前端控制器DispatcherServlet的初始化时间
&lt;!-- 配置SpringMVC的前端控制器，对浏览器发送的请求统一进行处理 --> &lt;servlet> &lt;servlet-name>springMVC&lt;/servlet-name> &lt;servlet-class>org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class> &lt;!-- 通过初始化参数指定SpringMVC配置文件的位置和名称 --> &lt;init-param> &lt;!-- contextConfigLocation为固定值 --> &lt;param-name>contextConfigLocation&lt;/param-name> &lt;!-- 使用classpath:表示从类路径查找配置文件，例如maven工程中的 src/main/resources --> &lt;param-value>classpath:springMVC.xml&lt;/param-value> &lt;/init-param> &lt;!-- 作为框架的核心组件，在启动过程中有大量的初始化操作要做 而这些操作放在第一次请求时才执行会严重影响访问速度 因此需要通过此标签将启动控制DispatcherServlet的初始化时间提前到服务器启动时 --> &lt;load-on-startup>1&lt;/load-on-startup> &lt;/servlet> &lt;servlet-mapping> &lt;servlet-name>springMVC&lt;/servlet-name> &lt;!-- 设置springMVC的核心控制器所能处理的请求的请求路径 /所匹配的请求可以是/login或.html或.js或.css方式的请求路径 但是/不能匹配.jsp请求路径的请求 /* 可以匹配。jsp的请求 --> &lt;url-pattern>/&lt;/url-pattern> &lt;/servlet-mapping> 3.3、springmvc配置文件 名称要以web.xml中servlet-name中的名称加上-servlet.xml
springMVC-servlet.xml
&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd"> &lt;!-- 自动扫描包 --> &lt;context:component-scan base-package="com.atguigu.mvc.controller"/> &lt;!-- 配置Thymeleaf视图解析器 --> &lt;bean id="viewResolver" class="org.thymeleaf.spring5.view.ThymeleafViewResolver"> &lt;!-- 顺序 --> &lt;property name="order" value="1"/> &lt;property name="characterEncoding" value="UTF-8"/> &lt;!-- 模板引擎 --> &lt;property name="templateEngine"> &lt;!-- 内部bean --> &lt;bean class="org.thymeleaf.spring5.SpringTemplateEngine"> &lt;property name="templateResolver"> &lt;bean class="org.thymeleaf.spring5.templateresolver .SpringResourceTemplateResolver"> &lt;!-- 视图前缀 --> &lt;property name="prefix" value="/WEB-INF/templates/"/> &lt;!-- 视图后缀 --> &lt;property name="suffix" value=".html"/> &lt;property name="templateMode" value="HTML5"/> &lt;property name="characterEncoding" value="UTF-8" /> &lt;/bean> &lt;/property> &lt;/bean> &lt;/property> &lt;/bean> &lt;!-- 配置默认的servlet处理静态资源 --> &lt;mvc:default-servlet-handler/> &lt;!-- 开启maven的注解驱动 --> &lt;mvc:annotation-driven/> &lt;!-- 配置视图控制器 --> &lt;mvc:view-controller path="/" view-name="index">&lt;/mvc:view-controller> &lt;!-- 配置上传解析器 --> &lt;!-- 配置拦截器 --> 下面拦截器章节 &lt;/beans> 3.4、请求 1）controller
@RequestMapping("/") public Sting protal() { /**将视图逻辑返回 * prefix：视图前缀，去前缀的路径找 * suffix：后缀，去后缀找 * templateMode：HTML5 * characterEncoding：UTF-8 * 逻辑视图：index * 物理视图：/WEB-INF/templates/index.xml **/ return "index"; } 2）html请求
&lt;!-- 自动加上上下文路径 localhost:8080/springMVC/hello --> &lt;a th:href="@{/hello}">HelloWorld&lt;/a>&lt;br/> &lt;!-- 不加上下文路径 localhost:8080/hello --> &lt;a href="/hello">HelloWorld&lt;/a> 二、RequestMapping注解 1、功能 从注解名称上我们可以看到，@RequestMapping注解的作用就是将请求和处理请求的控制器方法关联 起来，建立映射关系。
SpringMVC 接收到指定的请求，就会来找到在映射关系中对应的控制器方法来处理这个请求。
2、位置 @RequestMapping标识一个类:设置映射请求的请求路径的初始信息
@RequestMapping标识一个方法:设置映射请求请求路径的具体信息
@Controller @RequestMapping("/test") public class RequestMappingController { //此时请求映射所映射的请求的请求路径为:/test/testRequestMapping @RequestMapping("/testRequestMapping") public String testRequestMapping(){ return "success"; } } 3、value属性 1）注解的value属性通过请求的请求地址匹配请求映射
2）注解的value属性是一个字符串类型的数组，表示该请求映射能够匹配多个请求地址 所对应的请求
@RequestMapping( value = {"/testRequestMapping", "/test"} ) 3）注解的value属性必须设置，至少通过请求地址匹配请求映射
4、method属性 1）method属性通过请求的请求方式(get或post)匹配请求映射
2）method属性是一个RequestMethod类型的数组，表示该请求映射能够匹配 多种请求方式的请求
若当前请求的请求地址满足请求映射的value属性，但是请求方式不满足method属性，则浏览器报错 405:Request method &lsquo;POST&rsquo; not supported
@RequestMapping( value = {"/testRequestMapping", "/test"}, method = {RequestMethod.GET, RequestMethod.POST} ) public String testRequestMapping(){ return "success"; } 3）派生注解
@GetMapping@PostMapping@PutMapping@DeleteMapping
但是目前浏览器只支持get和post，若在form表单提交时，为method设置了其他请求方式的字符 串(put或delete)，则按照默认的请求方式get处理
若要发送put和delete请求，则需要通过spring提供的过滤器HiddenHttpMethodFilter，在 RESTful部分会讲到
5、params属性 params属性通过请求的请求参数匹配请求映射
params属性是一个字符串类型的数组，可以通过四种表达式设置请求参数 和请求映射的匹配关系
"param":要求请求映射所匹配的请求必须携带param请求参数 "!param":要求请求映射所匹配的请求必须不能携带param请求参数 "param=value":要求请求映射所匹配的请求必须携带param请求参数且param=value "param!=value":要求请求映射所匹配的请求必须携带param请求参数但是param!=value 若当前请求满足@RequestMapping注解的value和method属性，但是不满足params属性，此时 页面回报错400:Parameter conditions "username, password!=123456" not met for actual request parameters: username={admin}, password={123456} 案例：
@RequestMapping( value = {"/testRequestMapping", "/test"} ,method = {RequestMethod.GET, RequestMethod.POST} ,params = {"username","password!=123456"} ) public String testRequestMapping(){ return "success"; } 6、headers属性 headers属性通过请求的请求头信息匹配请求映射
headers属性是一个字符串类型的数组，可以通过四种表达式设置请求头信 息和请求映射的匹配关系
"header":要求请求映射所匹配的请求必须携带header请求头信息 "!header":要求请求映射所匹配的请求必须不能携带header请求头信息 "header=value":要求请求映射所匹配的请求必须携带header请求头信息且header=value "header!=value":要求请求映射所匹配的请求必须携带header请求头信息且header!=value 若当前请求满足@RequestMapping注解的value和method属性，但是不满足headers属性，此时页面 显示404错误，即资源未找到 7、支持ant风格的路径 ?:表示任意的单个字符 *:表示任意的0个或多个字符 **:表示任意层数的任意目录 注意:在使用**时，只能使用/**/xxx的方式 8、支持路径中的占位符 原始方式:/deleteUser?id=1
rest方式:/user/delete/1
SpringMVC路径中的占位符常用于RESTful风格中，当请求路径中将某些数据通过路径的方式传输到服 务器中，就可以在相应的@RequestMapping注解的value属性中通过占位符{xxx}表示传输的数据，在 通过@PathVariable注解，将占位符所表示的数据赋值给控制器方法的形参
&lt;a th:href="@{/testRest/1/admin}">测试路径中的占位符-->/testRest&lt;/a>&lt;br> @RequestMapping("/testRest/{id}/{username}") public String testRest(@PathVariable("id") String id, @PathVariable("username") String username){ System.out.println("id:"+id+",username:"+username); return "success"; } //最终输出的内容为-->id:1,username:admin 9、获取请求参数 1）通过ServletAPI获取 将HttpServletRequest作为控制器方法的形参，此时HttpServletRequest类型的参数表示封装了当前请 求的请求报文的对象
@RequestMapping("/testParam") public String testParam(HttpServletRequest request){ String username = request.getParameter("username"); String password = request.getParameter("password"); System.out.println("username:"+username+",password:"+password); return "success"; } 2）通过形参获取请求参数 在控制器方法的形参位置，设置和请求参数同名的形参，当浏览器发送请求，匹配到请求映射时，在DispatcherServlet中就会将请求参数赋值给相应的形参
&lt;a th:href="@{/testParam(username='admin',password=123456)}">测试获取请求参数-- >/testParam&lt;/a>&lt;br> @RequestMapping("/testParam") public String testParam(String username, String password){ System.out.println("username:"+username+",password:"+password); return "success"; } 注:
若请求所传输的请求参数中有多个同名的请求参数，此时可以在控制器方法的形参中设置字符串 数组或者字符串类型的形参接收此请求参数 若使用字符串数组类型的形参，此参数的数组中包含了每一个数据 若使用字符串类型的形参，此参数的值为每个数据中间使用逗号拼接的结果 3）@CookieValue @CookieValue是将cookie数据和控制器方法的形参创建映射关系
@CookieValue注解一共有三个属性:value、required、defaultValue，用法同@RequestParam
三、域对象共享数据 1、使用ServletAPI向request @RequestMapping("/testServletAPI") public String testServletAPI(HttpServletRequest request){ request.setAttribute("testScope", "hello,servletAPI"); return "success"; } 2、使用ModelAndView向request域对象共享数据 @RequestMapping("/testModelAndView") public ModelAndView testModelAndView(){ /** * ModelAndView有Model和View的功能 * Model主要用于向请求域共享数据 * View主要用于设置视图，实现页面跳转 */ ModelAndView mav = new ModelAndView(); //向请求域共享数据 mav.addObject("testScope", "hello,ModelAndView"); //设置视图，实现页面跳转 mav.setViewName("success"); return mav; } 3、使用Model向request域对象共享数据 @RequestMapping("/testModel") public String testModel(Model model){ model.addAttribute("testScope", "hello,Model"); return "success"; } 4、使用map向request域对象共享数据 @RequestMapping("/testMap") public String testMap(Map&lt;String, Object> map){ map.put("testScope", "hello,Map"); return "success"; } 5、使用ModelMap向request域对象共享数据 @RequestMapping("/testModelMap") public String testModelMap(ModelMap modelMap){ modelMap.addAttribute("testScope", "hello,ModelMap"); return "success"; } 6、Model、ModelMap、Map的关系 Model、ModelMap、Map类型的参数其实本质上都是 BindingAwareModelMap 类型的
public interface Model{} public class ModelMap extends LinkedHashMap&lt;String, Object> {} public class ExtendedModelMap extends ModelMap implements Model {} public class BindingAwareModelMap extends ExtendedModelMap {} 7、向session域共享数据 @RequestMapping("/testSession") public String testSession(HttpSession session){ session.setAttribute("testSessionScope", "hello,session"); return "success"; } 8、向application域共享数据 @RequestMapping("/testApplication") public String testApplication(HttpSession session){ ServletContext application = session.getServletContext(); application.setAttribute("testApplicationScope", "hello,application"); return "success"; } 所有的域对象共享数据最后都封装到了ModelAndView当中
四、SpringMVC视图 SpringMVC中的视图是View接口，视图的作用渲染数据，将模型Model中的数据展示给用户
SpringMVC视图的种类很多，默认有转发视图和重定向视图
当工程引入jstl的依赖，转发视图会自动转换为JstlView
若使用的视图技术为Thymeleaf，在SpringMVC的配置文件中配置了Thymeleaf的视图解析器，由此视 图解析器解析之后所得到的是ThymeleafView
1、ThymeleafView 当控制器方法中所设置的视图名称没有任何前缀时，此时的视图名称会被SpringMVC配置文件中所配置的视图解析器解析，视图名称拼接视图前缀和视图后缀所得到的最终路径，会通过转发的方式实现跳转
@RequestParam("/") public String getOne() { //返回首页，由springmvc中的ThymeleafViewResolver视图解析器来进行解析 return "index"; } 2、转发视图 SpringMVC中默认的转发视图是InternalResourceView
SpringMVC中创建转发视图的情况:
当控制器方法中所设置的视图名称以"forward:&ldquo;为前缀时，创建InternalResourceView视图，此时的视 图名称不会被SpringMVC配置文件中所配置的视图解析器解析，而是会将前缀"forward:&ldquo;去掉，剩余部分作为最终路径通过转发的方式实现跳转
例如"forward:/"，&ldquo;forward:/employee&rdquo;
@RequestMapping("/testForward") public String testForward(){ return "forward:/testHello"; } 3、重定向视图 SpringMVC中默认的重定向视图是RedirectView
当控制器方法中所设置的视图名称以"redirect:&ldquo;为前缀时，创建RedirectView视图，此时的视图名称不 会被SpringMVC配置文件中所配置的视图解析器解析，而是会将前缀"redirect:&ldquo;去掉，剩余部分作为最 终路径通过重定向的方式实现跳转
例如"redirect:/"，&ldquo;redirect:/employee&rdquo;
注：重定向视图在解析时，会先将redirect:前缀去掉，然后会判断剩余部分是否以/开头，若是则会自 动拼接上下文路径
@RequestMapping("/testRedirect") public String testRedirect(){ return "redirect:/testHello"; } 4、视图控制器view-controller 当控制器方法中，仅仅用来实现页面跳转，即只需要设置视图名称时，可以将处理器方法使用view-controller标签进行表示，在springmvc配置文件中
&lt;!-- path:设置处理的请求地址 view-name:设置请求地址所对应的视图名称 --> &lt;mvc:view-controller path="/testView" view-name="success">&lt;/mvc:view-controller> 注: 当SpringMVC中设置任何一个view-controller时，其他控制器中的请求映射将全部失效，此时需
要在SpringMVC的核心配置文件中设置开启mvc注解驱动的标签:
5、注解扫描驱动 &lt;mvc:annotation-driven />
四、Restful 1、简介 REST:Representational State Transfer，表现层资源状态转移。
1资源
资源是一种看待服务器的方式，即，将服务器看作是由很多离散的资源组成。每个资源是服务器上一个 可命名的抽象概念。因为资源是一个抽象的概念，所以它不仅仅能代表服务器文件系统中的一个文件、 数据库中的一张表等等具体的东西，可以将资源设计的要多抽象有多抽象，只要想象力允许而且客户端 应用开发者能够理解。与面向对象设计类似，资源是以名词为核心来组织的，首先关注的是名词。一个 资源可以由一个或多个URI来标识。URI既是资源的名称，也是资源在Web上的地址。对某个资源感兴 趣的客户端应用，可以通过资源的URI与其进行交互。
2资源的表述
资源的表述是一段对于资源在某个特定时刻的状态的描述。可以在客户端-服务器端之间转移(交 换)。资源的表述可以有多种格式，例如HTML/XML/JSON/纯文本/图片/视频/音频等等。资源的表述格 式可以通过协商机制来确定。请求-响应方向的表述通常使用不同的格式。
3状态转移
状态转移说的是:在客户端和服务器端之间转移(transfer)代表资源状态的表述。通过转移和操作资 源的表述，来间接实现操作资源的目的。
2、RESTful的实现 具体说，就是 HTTP 协议里面，四个表示操作方式的动词:GET、POST、PUT、DELETE。
它们分别对应四种基本操作:
GET 用来获取资源，
POST 用来新建资源，
PUT 用来更新资源，
DELETE 用来删除资源。
REST 风格提倡 URL 地址使用统一的风格设计，从前到后各个单词使用斜杠分开，不使用问号键值对方 式携带请求参数，而是将要发送给服务器的数据作为 URL 地址的一部分，以保证整体风格的一致性。
3、HiddenHttpMethodFilter 由于浏览器只支持发送get和post方式的请求，那么该如何发送put和delete请求呢?
SpringMVC 提供了 HiddenHttpMethodFilter 帮助我们将 POST 请求转换为 DELETE 或 PUT 请求
HiddenHttpMethodFilter 处理put和delete请求的条件:
a>当前请求的请求方式必须为post
b>当前请求必须传输请求参数_method
满足以上条件，HiddenHttpMethodFilter 过滤器就会将当前请求的请求方式转换为请求参数 _method的值，因此请求参数_method的值才是最终的请求方式
在web.xml中注册HiddenHttpMethodFilter
&lt;form th:action="@{/hello}" method="post"> &lt;input type="submit" value="测试method属性"> &lt;/form> &lt;filter> &lt;filter-name>HiddenHttpMethodFilter&lt;/filter-name> &lt;filter-class>org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class> &lt;/filter> &lt;filter-mapping> &lt;filter-name>HiddenHttpMethodFilter&lt;/filter-name> &lt;url-pattern>/*&lt;/url-pattern> &lt;/filter-mapping> 五、处理Ajax 六、文件上传和下载 七、拦截器 &lt;bean id="firstInterceptor" class="com.lizi.interceptor.FirstInterceptor"/> &lt;mvc:interceptors> &lt;!--1.直接填bean--> &lt;bean class="com.lizi.interceptor.FirstInterceptor"/> &lt;!--2.引用外面bean--> &lt;ref bean="firstInterceptor"/> &lt;!--3.规则添加bean--> &lt;mvc:interceptor> &lt;mvc:mapping path="/**"/> &lt;mvc:exclude-mapping path="/abc"/> &lt;ref bean="firstInterceptor"/> &lt;/mvc:interceptor> &lt;/mvc:interceptors> 八、异常处理器 九、注解配置SpringMVC 十、执行流程 十一、扩展使用 docker exec -it chemex ip addr</content></entry><entry><title>Java框架-Spring</title><url>https://zhang4014439175.github.io/post/spring%E4%B8%80/</url><categories><category>Java-Framework</category><category>Spring</category></categories><tags><tag>Java</tag><tag>框架</tag><tag>Spring</tag></tags><content type="html"> 一、IOC控制反转 1、概念 控制反转，把对象创建和对象之间的调用过程，交给 Spring 进行管理
使用 IOC 目的:为了耦合度降低
做入门案例就是 IOC 实现
2、底层原理 xml解析、工厂模式、反射
3、IOC过程 1）xml配置文件，配置创建的对象
&lt;bean id="dao" class="com.lizi.UserDao">&lt;/bean> 2）有service类和dao类，创建工厂类
public class UserFactory { public static UserDao getDao() { String classValue = class属性值; //xml解析 Class clazz = Class.forName(classValue); //通过反射创建对象 return (UserDao) clazz.newInstance(); } } 4、IOC（BeanFactory接口） 1、IOC 思想基于 IOC 容器完成，IOC 容器底层就是对象工厂
2、Spring 提供 IOC 容器实现两种方式：(两个接口)
1）BeanFactory：
IOC容器基本实现，是 Spring 内部的使用接口，不提供开发人员进行使用 * 加载配置文件时候不会创建对象，在获取对象（使用）才去创建对象
2）ApplicationContext：
BeanFactory 接口的子接口，提供更多更强大的功能，一般由开发人 员进行使用 * 加载配置文件时候就会把在配置文件对象进行创建
3、ApplicationContext 接口有实现类
5、IOC操作Bean管理 1）概念 (0)Bean 管理指的是两个操作
(1)Spring 创建对象
(2)Spirng 注入属性
2）Bean管理操作的两种方式 (1)基于 xml 配置文件方式实现
(2)基于注解方式实现
3）基于xml方式管理bean 基于xml方式创建对象
&lt;bean id="dao" class="com.lizi.UserDao">&lt;/bean> (1)在 spring 配置文件中，使用 bean 标签，标签里面添加对应属性，就可以实现对象创建 (2)在 bean 标签有很多属性，介绍常用的属性 ​ id 属性：唯一标识 ​ class 属性：类全路径(包类路径) (3)创建对象时候，默认也是执行无参数构造方法完成对象创建 基于 xml 方式注入属性
：依赖注入，就是注入属性 6、DI 依赖注入 1）使用 set 方法进行注入 创建类，定义属性和对应的 set 方法
public class Book { //创建属性 private String bname; private String bauthor; //创建属性对应的 set 方法 public void setBname(String bname) { this.bname = bname; } public void setBauthor(String bauthor) { this.bauthor = bauthor; } } 在 spring 配置文件配置对象创建，配置属性注入
&lt;!--2 set 方法注入属性--> &lt;bean id="book" class="com.atguigu.spring5.Book"> &lt;!--使用 property 完成属性注入 name:类里面属性名称 value:向属性注入的值 --> &lt;property name="bname" value="易筋经">&lt;/property> &lt;property name="bauthor" value="达摩老祖">&lt;/property> &lt;/bean> 2）使用有参数构造进行注入 (1)创建类，定义属性，创建属性对应有参数构造方法 public class Orders { //属性 private String oname; private String address; //有参数构造 public Orders(String oname,String address) { this.oname = oname; this.address = address; } } (2)在 spring 配置文件中进行配置 &lt;bean id="orders" class="com.atguigu.spring5.Orders"> &lt;constructor-arg name="oname" value="电脑">&lt;/constructor-arg> &lt;constructor-arg name="address" value="China">&lt;/constructor-arg> &lt;/bean> 3）p名称空间注入 使用p名称空间注入，可以简化基于 xml 配置方式
第一步 添加 p 名称空间在配置文件中
&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd"> &lt;!-- p命名空间注入，可直接注入属性的值，需要Java类中有无参构造器：property--> &lt;bean id="user" class="全限定类名" p:name="root" p:age="18"/> &lt;/beans> 第二步 进行属性注入，在 bean 标签里面进行操作
实体类的属性需要添加setter方法
&lt;!--2 set 方法注入属性--> &lt;bean id="book" class="com.atguigu.spring5.Book" p:bname="九阳神功"p:bauthor="无名氏">&lt;/bean> 4）字面量 null值
&lt;property name="address"> &lt;null/> &lt;/property> 属性值包含特殊符号
&lt;!--属性值包含特殊符号 1 把&lt;>进行转义 &amp;lt; &amp;gt; 2 把带特殊符号内容写到 CDATA --> &lt;property name="address"> &lt;value>&lt;![CDATA[&lt;&lt;南京>>]]>&lt;/value> &lt;/property> 5）外部、内部bean 1、外部
(1)创建两个类 service 类和 dao 类
(2)在 service 调用 dao 里面的方法
(3)在 spring 配置文件中进行配置
public class UserService { //创建 UserDao 类型属性，生成 set 方法 private UserDao userDao; public void setUserDao(UserDao userDao) { this.userDao = userDao; } public void add() { System.out.println("service add..............."); userDao.update(); } } &lt;!--1 service 和 dao 对象创建--> &lt;bean id="userService" class="com.atguigu.spring5.service.UserService"> &lt;!--注入 userDao 对象 name 属性:类里面属性名称 ref 属性:创建 userDao 对象 bean 标签 id 值 --> &lt;property name="userDao" ref="userDaoImpl">&lt;/property> &lt;/bean> &lt;bean id="userDaoImpl" class="com.atguigu.spring5.dao.UserDaoImpl">&lt;/bean> 2、内部
（1）一对多关系:部门和员工 一个部门有多个员工，一个员工属于一个部门 部门是一，员工是多
（2）在实体类之间表示一对多关系，员工表示所属部门，使用对象类型属性进行表示
//部门类 public class Dept { private String dname; public void setDname(String dname) { this.dname = dname; } } //员工类 public class Emp { private String ename; private String gender; //员工属于某一个部门，使用对象形式表示 private Dept dept; public void setDept(Dept dept) { this.dept = dept; } public void setEname(String ename) { this.ename = ename; } public void setGender(String gender) { this.gender = gender; } } (3)在 spring 配置文件中进行配置
&lt;!--内部 bean--> &lt;bean id="emp" class="com.atguigu.spring5.bean.Emp"> &lt;!--设置两个普通属性--> &lt;property name="ename" value="lucy">&lt;/property> &lt;property name="gender" value="女">&lt;/property> &lt;!--设置对象类型属性--> &lt;property name="dept"> &lt;bean id="dept" class="com.atguigu.spring5.bean.Dept"> &lt;property name="dname" value="安保部"> &lt;/bean> &lt;/property> &lt;/bean> 6）级联赋值 (1)第一种写法 &lt;bean id="emp" class="com.atguigu.spring5.bean.Emp"> &lt;!--设置两个普通属性--> &lt;property name="ename" value="lucy">&lt;/property> &lt;property name="gender" value="女">&lt;/property> &lt;!--级联赋值--> &lt;property name="dept" ref="dept">&lt;/property> &lt;/bean> &lt;bean id="dept" class="com.atguigu.spring5.bean.Dept"> &lt;property name="dname" value="财务部">&lt;/property> &lt;/bean> (2)第二种写法 private Dept dept; public Dept getDept() { return dept; } public void setDept(Dept dept) { this.dept = dept; } &lt;!--级联赋值--> &lt;bean id="emp" class="com.atguigu.spring5.bean.Emp"> &lt;!--设置两个普通属性--> &lt;property name="ename" value="lucy">&lt;/property> &lt;property name="gender" value="女">&lt;/property> &lt;!--级联赋值--> &lt;property name="dept" ref="dept">&lt;/property> &lt;property name="dept.dname" value="技术部">&lt;/property> &lt;/bean> &lt;bean id="dept" class="com.atguigu.spring5.bean.Dept"> &lt;property name="dname" value="财务部">&lt;/property> &lt;/bean> 7）数组、List、Map （1）注入数组类型属性
（2）注入List集合类型属性
（3）注入Map集合类型属性
1、创建类，定义数组、list、map、set 类型属性，生成对应 set 方法
public class Stu { //1 数组类型属性 private String[] courses; //2 list 集合类型属性 private List&lt;String> list; //3 map 集合类型属性 private Map&lt;String,String> maps; //4 set 集合类型属性 private Set&lt;String> sets; public void setSets(Set&lt;String> sets) { this.sets = sets; } public void setCourses(String[] courses) { this.courses = courses; } public void setList(List&lt;String> list) { this.list = list; } public void setMaps(Map&lt;String, String> maps) { this.maps = maps; } } 2、在 spring 配置文件进行配置
&lt;bean id="stu" class="com.atguigu.spring5.bean.Stu"> &lt;!--数组类型属性注入--> &lt;property name="courses"> &lt;array> &lt;value>java课程&lt;/value> &lt;value>数据库课程&lt;/value> &lt;/array> &lt;/property> &lt;!--list 类型属性注入--> &lt;property name="list"> &lt;list> &lt;value>java课程&lt;/value> &lt;value>数据库课程&lt;/value> &lt;/list> &lt;/property> &lt;!--map 类型属性注入--> &lt;property name="maps"> &lt;map> &lt;entry key="JAVA" value="java">&lt;/entry &lt;entry key="PHP" value="php">&lt;/entry> &lt;/map> &lt;/property> &lt;!--set 类型属性注入--> &lt;property name="sets"> &lt;set> &lt;value>java课程&lt;/value> &lt;value>数据库课程&lt;/value> &lt;/set> &lt;/property> &lt;/bean> （4）在集合里面设置对象类型值
&lt;!--创建多个 course 对象--> &lt;bean id="course1" class="com.atguigu.spring5.collectiontype.Course"> &lt;property name="cname" value="Spring5 框架">&lt;/property> &lt;/bean> &lt;bean id="course2" class="com.atguigu.spring5.collectiontype.Course"> &lt;property name="cname" value="MyBatis 框架">&lt;/property> &lt;/bean> &lt;!--注入 list 集合类型，值是对象--> &lt;property name="courseList"> &lt;list> &lt;ref bean="course1">&lt;/ref> &lt;ref bean="course2">&lt;/ref> &lt;/list> &lt;/property> （5）把集合注入部分提取出来
(1)在 spring 配置文件中引入名称空间 util &lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:util="http://www.springframework.org/schema/util" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd"> (2)使用 util 标签完成 list 集合注入提取 &lt;!--1 提取 list 集合类型属性注入--> &lt;util:list id="bookList"> &lt;value>java课程&lt;/value> &lt;value>数据库课程&lt;/value> &lt;/util:list> &lt;!--2 提取 list 集合类型属性注入使用--> &lt;bean id="book" class="com.atguigu.spring5.collectiontype.Book"> &lt;property name="list" ref="bookList">&lt;/property> &lt;/bean> 7、FactoryBean 1、Spring 有两种类型 bean，一种普通 bean，另外一种工厂 bean(FactoryBean)
2、普通 bean:在配置文件中定义 bean 类型就是返回类型
3、工厂 bean:在配置文件定义 bean 类型可以和返回类型不一样 第一步 创建类，让这个类作为工厂 bean，实现接口 FactoryBean 第二步 实现接口里面的方法，在实现的方法中定义返回的 bean 类型
public class MyBean implements FactoryBean&lt;Course> { //定义返回 bean @Override public Course getObject() throws Exception { Course course = new Course(); course.setCname("abc"); return course; } @Override public Class&lt;?> getObjectType() { return null; } @Override public boolean isSingleton() { return false; } } &lt;bean id="myBean" class="com.atguigu.spring5.factorybean.MyBean"/> @Test public void test3() { ApplicationContext context = new ClassPathXmlApplicationContext("bean3.xml"); Course course = context.getBean("myBean", Course.class); System.out.println(course); } 8、bean的作用域 1、在 Spring 里面，设置创建 bean 实例是单实例还是多实例
2、在 Spring 里面，默认情况下，bean 是单实例对象
//两个对象是同一个对象 Util01 book1 = context.getBean("book", Util01.class); Util01 book2 = context.getBean("book", Util01.class); 3、如何设置单实例还是多实例
（1）在 spring 配置文件 bean 标签里面有属性(scope)用于设置单实例还是多实例
（2）scope 属性值
​ 第一个值 默认值，singleton，表示是单实例对象
​ 第二个值 prototype，表示是多实例对象
&lt;bean id="book" class="com.lizi.spring5.test01.Util01" scope="prototype"/> （3）singleton 和 prototype 区别
​ 第一 singleton单实例，prototype多实例
​ 第二 设置 scope 值是 singleton 时候，加载 spring 配置文件时候就会创建单实例对象
​ 设置 scope 值是 prototype 时候，不是在加载 spring 配置文件时候创建 对象，在调用 getBean 方法时候创建多实例对象
9、bean的生命周期 一共7步生命周期
(1)通过构造器创建 bean 实例(无参数构造)
public Orders() { System.out.println("第一步 执行无参数构造创建 bean 实例"); } (2)为 bean 的属性设置值和对其他 bean 引用(调用 set 方法)
public void setOname(String oname) { this.oname = oname; System.out.println("第二步 调用 set 方法设置属性值"); } &lt;bean id="orders" class="com.atguigu.spring5.bean.Orders"> &lt;property name="oname" value="手机">&lt;/property> &lt;/bean> (3)把 bean 实例传递 bean 后置处理器的方法 postProcessBeforeInitialization
public class MyBeanPost implements BeanPostProcessor { @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println("在初始化之前执行的方法"); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println("在初始化之后执行的方法"); return bean; } } &lt;bean id="myBeanPost" class="com.atguigu.spring5.bean.MyBeanPost">&lt;/bean> (4)调用 bean 的初始化的方法(需要进行配置初始化的方法)
//创建执行的初始化的方法 public void initMethod() { System.out.println("第三步 执行初始化的方法"); } &lt;bean id="orders" class="com.atguigu.spring5.bean.Orders" init-method="initMethod"/> (5)把 bean 实例传递 bean 后置处理器的方法 postProcessAfterInitialization
//第四部的postProcessAfterInitialization (6)bean 可以使用了(对象获取到了)
ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("bean4.xml"); Orders orders = context.getBean("orders", Orders.class); System.out.println("第四步 获取创建 bean 实例对象"); System.out.println(orders); (7)当容器关闭时候，调用 bean 的销毁的方法(需要进行配置销毁的方法)
ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("bean4.xml"); Orders orders = context.getBean("orders", Orders.class); //手动让 bean 实例销毁 context.close(); 10、自动装配 1、什么是自动装配 (1)根据指定装配规则(属性名称或者属性类型)，Spring 自动将匹配的属性值进行注入
2、演示自动装配过程
(1)根据属性名称自动注入
&lt;!--实现自动装配 bean 标签属性 autowire，配置自动装配 autowire 属性常用两个值: byName 根据属性名称注入 ，注入值 bean 的 id 值和类属性名称一样 byType 根据属性类型注入 --> &lt;bean id="orders" class="com.atguigu.spring5.bean.Orders" autowire="byName"/>&lt;/bean> &lt;bean id="dept" class="com.atguigu.spring5.autowire.Dept">&lt;/bean> (2)根据属性类型自动注入
&lt;!--实现自动装配 bean 标签属性 autowire，配置自动装配 autowire 属性常用两个值: byName 根据属性名称注入 ，注入值 bean 的 id 值和类属性名称一样 byType 根据属性类型注入 --> &lt;bean id="emp" class="com.atguigu.spring5.autowire.Emp" autowire="byType"> &lt;!--&lt;property name="dept" ref="dept">&lt;/property>--> &lt;/bean> &lt;bean id="dept" class="com.atguigu.spring5.autowire.Dept">&lt;/bean> 11、管理外部配置文件 1、直接配置数据库信息
(1)配置德鲁伊连接池
(2)引入德鲁伊连接池依赖 jar 包
&lt;!--直接配置连接池--> &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource"> &lt;property name="driverClassName" value="com.mysql.jdbc.Driver">&lt;/property> &lt;property name="url" value="jdbc:mysql://localhost:3306/userDb">&lt;/property> &lt;property name="username" value="root">&lt;/property> &lt;property name="password" value="root">&lt;/property> &lt;/bean> 2、引入外部属性文件配置数据库连接池
(1)创建外部属性文件，properties 格式文件，写数据库信息
prop.driverClass=com.mysql.jdbc.Driver prop.url=jdbc:mysql://localhost:3306/userDb prop.username=root prop.password=root (2)把外部 properties 属性文件引入到 spring 配置文件中
&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:util="http://www.springframework.org/schema/util" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"> 12、注解开发 1、什么是注解
(1)注解是代码特殊标记，格式:@注解名称(属性名称=属性值, 属性名称=属性值..)
(2)使用注解，注解作用在类上面，方法上面，属性上面
(3)使用注解目的:简化 xml 配置
2、Spring 针对 Bean 管理中创建对象提供注解
(1)@Component
(2)@Service
(3)@Controller
(4)@Repository
上面四个注解功能是一样的，都可以用来创建 bean 实例
3、基于注解方式实现对象创建
第一步 引入依赖
第二步 开启组件扫描
&lt;!--开启组件扫描 1 如果扫描多个包，多个包使用逗号隔开 2 扫描包上层目录 --> &lt;context:component-scan base-package="com.atguigu">&lt;/context:component-scan> 第三步 创建类，在类上面添加创建对象注解
//在注解里面 value 属性值可以省略不写， //默认值是类名称，首字母小写 //UserService -- userService @Component(value = "userService") //&lt;bean id="userService" class=".."/> public class UserService { public void add() { System.out.println("service add......."); } } 4、开启组件扫描细节配置
&lt;!--示例 1 use-default-filters="false" 表示现在不使用默认 filter，自己配置 filter context:include-filter ，设置扫描哪些内容 --> &lt;context:component-scan base-package="com.atguigu" use-default-filters="false"> &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/> &lt;/context:component-scan> &lt;!--示例 2 下面配置扫描包所有内容 context:exclude-filter: 设置哪些内容不进行扫描 --> &lt;context:component-scan base-package="com.atguigu"> &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/> &lt;/context:component-scan> 5、基于注解方式实现属性注入
//(1)@Autowired:根据属性类型进行自动装配 //第一步 把 service 和 dao 对象创建，在 service 和 dao 类添加创建对象注解。 //第二步 在 service 注入 dao 对象，在 service 类添加 dao 类型属性，在属性上面使用注解。 @Service public class UserService { //定义 dao 类型属性 //不需要添加 set 方法 //添加注入属性注解 @Autowired private UserDao userDao; public void add() { System.out.println("service add......."); userDao.add(); } } //(2)@Qualifier:根据名称进行注入 //这个@Qualifier 注解的使用，和上面@Autowired 一起使用 //定义 dao 类型属性 //不需要添加 set 方法 //添加注入属性注解 @Autowired //根据类型进行注入 @Qualifier(value = "userDaoImpl1") //根据名称进行注入 private UserDao userDao; //(3)@Resource:可以根据类型注入，可以根据名称注入 //@Resource //根据类型进行注入 @Resource(name = "userDaoImpl1") //根据名称进行注入 private UserDao userDao; //(4)@Value:注入普通类型属性 @Value(value = "abc") private String name; 13、完全注解开发 (1)创建配置类，替代 xml 配置文件
@Configuration //作为配置类，替代xml配置文件 @ComponentScan(basePackages = {"com.atguigu"}) public class SpringConfig { } (2)编写测试类
@Test public void testService2() { //加载配置类 ApplicationContext context = new AnnotationConfigApplicationContext(SpringConfig.class); UserService userService = context.getBean("userService", UserService.class); System.out.println(userService); userService.add(); } 二、AOP面向切面编程 1、AspectJ注解 1）执行
public class TestAop { @Test public void testAopAnno() { ApplicationContext context = new ClassPathXmlApplicationContext("bean1.xml"); User user = context.getBean("uesr", User.class); user.add(); } } 2、jdk动态代理 3、cglib动态代理 4、AOP知识 1）连接点
2）切入点
3）通知（增强）
​ 前置
​ 后置
​ 环绕
​ 异常
​ 最终
4）切面
​ 把通知应用到切入点的过程
5、spring的aop 1、Spring 框架一般都是基于 AspectJ 实现 AOP 操作
(1)AspectJ 不是 Spring 组成部分，独立 AOP 框架，一般把 AspectJ 和 Spirng 框架一起使 用，进行 AOP 操作
2、基于 AspectJ 实现 AOP 操作
(1)基于 xml 配置文件实现
(2)基于注解方式实现(使用)
3、在项目工程里面引入 AOP 相关依赖
4、切入点表达式
(1)切入点表达式作用:知道对哪个类里面的哪个方法进行增强
(2)语法结构: execution([权限修饰符] [返回类型] [类全路径] 方法名称
)
@Pointcut(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))") 举例 1:对 com.atguigu.dao.BookDao 类里面的 add 进行增强
execution(* com.atguigu.dao.BookDao.add(..)) 举例 2:对 com.atguigu.dao.BookDao 类里面的所有的方法进行增强
execution(* com.atguigu.dao.BookDao.* (..)) 举例 3:对 com.atguigu.dao 包里面所有类，类里面所有方法进行增强
execution(* com.atguigu.dao.*.* (..)) 6、xml配置aop (1)在 spring 配置文件中，开启注解扫描
&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"> &lt;!-- 开启注解扫描 --> &lt;context:component-scan base-package="com.atguigu.spring5.aopanno"> &lt;/context:component-scan> (2)使用注解创建 User 和 UserProxy 对象
@Component public class User {} @Component public class UserProxy {} (3)在增强类上面添加注解 @Aspect
@Component @Aspect //生成代理对象 public class UserProxy {}s (4)在 spring 配置文件中开启生成代理对象
&lt;!-- 开启 Aspect 生成代理对象--> &lt;aop:aspectj-autoproxy>&lt;/aop:aspectj-autoproxy> 7、配置不同类型的通知 (1)在增强类的里面，在作为通知方法上面添加通知类型注解，使用切入点表达式配置
//增强的类 @Component @Aspect //生成代理对象 public class UserProxy { //前置通知 //@Before 注解表示作为前置通知 @Before(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))") public void before() { System.out.println("before........."); } //后置通知(返回通知) @AfterReturning(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))") public void afterReturning() { System.out.println("afterReturning........."); } //最终通知 @After(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))") public void after() { System.out.println("after........."); } //异常通知 @AfterThrowing(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))") public void afterThrowing() { System.out.println("afterThrowing........."); } //环绕通知 @Around(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))") public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println("环绕之前........."); //被增强的方法执行 proceedingJoinPoint.proceed(); System.out.println("环绕之后........."); } } 相同的切入点抽取
//相同切入点抽取 @Pointcut(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))") public void pointdemo() { } //前置通知 //@Before 注解表示作为前置通知 @Before(value = "pointdemo()") public void before() { System.out.println("before........."); } 8、增强类优先级 @Component @Aspect @Order(1) public class PersonProxy 9、完全使用注解开发 @Configuration @ComponentScan(basePackages = {"com.atguigu"}) @EnableAspectJAutoProxy(proxyTargetClass = true) public class ConfigAop { } 1）创建两个类，增强类和被增强类，创建方法
2）在 spring 配置文件中创建两个类对象
&lt;!--创建对象--> &lt;bean id="book" class="com.atguigu.spring5.aopxml.Book">&lt;/bean> &lt;bean id="bookProxy" class="com.atguigu.spring5.aopxml.BookProxy">&lt;/bean> 3）在 spring 配置文件中配置切入点
&lt;!--配置 aop 增强--> &lt;aop:config> &lt;!--切入点--> &lt;aop:pointcut id="p" expression="execution(*com.atguigu.spring5.aopxml.Book.buy(..))"/> &lt;!--配置切面--> &lt;aop:aspect ref="bookProxy"> &lt;!--增强作用在具体的方法上--> &lt;aop:before method="before" pointcut-ref="p"/> &lt;/aop:aspect> &lt;/aop:config> 三、事务操作 1、什么事务 1）事务是数据库操作最基本单元，逻辑上一组操作，要么都成功，如果有一个所以操作都失败。
2）典型场景：银行转账
​ lucy转账100元给Mary
2、事务四个特效（ACID） 1）原子性
2）一致性
3）隔离性
4）持久性
3、事务编码 3.1、Spring 事务管理介绍 1）事务添加到 JavaEE 三层结构里面 Service 层(业务逻辑层)
2）在 Spring 进行事务管理操作
​ (1)有两种方式：编程式事务管理和声明式事务管理(使用)
3）声明式事务管理
​ (1)基于注解方式(使用)
​ (2)基于 xml 配置文件方式
4）在 Spring 进行声明式事务管理，底层使用 AOP 原理
5）Spring 事务管理 API
​ (1)提供一个接口，代表事务管理器，这个接口针对不同的框架提供不同的实现类
​ (2)开启事务注解
&lt;!--开启事务注解--> &lt;tx:annotation-driven transaction-manager="transactionManager">&lt;/tx:annotation-driven> 3.2、注解声明式事务管理 1）在 spring 配置文件配置事务管理器
2）在 spring 配置文件，开启事务注解
​ (1)在 spring 配置文件引入名称空间 tx
&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"> 3）在service类上面（或者service类里面方法上面）添加事务注解
​ (1)@Transactional，这个注解添加到类上面，也可以添加到方法上面
​ (2)如果把这个注解添加类上面，这个类里面所有的方法都添加事务
​ (3)如果把这个注解添加方法上面，为这个方法添加事务
@Service @Transactional public class UserService { 3.3、声明式事务管理参数配置 1、在 service 类上面添加注解**@Transactional**，在这个注解里面可以配置事务相关参数
2、propagation:事务传播行为
ServiceA { void methodA() { ServiceB.methodB(); } } ServiceB { void methodB() { } } 1）PROPAGATION_REQUIRED
支持当前事务，假设当前没有事务。就新建一个事务
​ 假如当前正要运行的事务不在另外一个事务里，那么就起一个新的事务 比方说，ServiceB.methodB的事务级别定义PROPAGATION_REQUIRED, 那么因为执行ServiceA.methodA的时候，ServiceA.methodA已经起了事务。这时调用ServiceB.methodB，ServiceB.methodB看到自己已经执行在ServiceA.methodA的事务内部。就不再起新的事务。而假如ServiceA.methodA执行的时候发现自己没有在事务中，他就会为自己分配一个事务。这样，在ServiceA.methodA或者在ServiceB.methodB内的不论什么地方出现异常。事务都会被回滚。即使ServiceB.methodB的事务已经被提交，可是ServiceA.methodA在接下来fail要回滚，ServiceB.methodB也要回滚
2）PROPAGATION_SUPPORTS
 假设当前在事务中，就加入到当前事务以事务的形式执行。假设当前不在一个事务中，那么就以非事务的形式执行
3）PROPAGATION_MANDATORY
 必须在一个事务中执行。也就是说，他仅仅能被一个父事务调用。否则，他就要抛出异常
​ 表示当前方法必须在一个事务中运行，如果没有事务，将抛出异常
4）PROPAGATION_REQUIRES_NEW
 这个就比较绕口了。 比方我们设计ServiceA.methodA的事务级别为PROPAGATION_REQUIRED，ServiceB.methodB的事务级别为PROPAGATION_REQUIRES_NEW。那么当运行到ServiceB.methodB的时候，ServiceA.methodA所在的事务就会挂起。ServiceB.methodB会起一个新的事务。等待ServiceB.methodB的事务完毕以后，他才继续运行。
​ 他与PROPAGATION_REQUIRED 的事务差别在于事务的回滚程度了。由于ServiceB.methodB是新起一个事务，那么就是存在两个不同的事务。假设ServiceB.methodB已经提交，那么ServiceA.methodA失败回滚。ServiceB.methodB是不会回滚的。假设ServiceB.methodB失败回滚，假设他抛出的异常被ServiceA.methodA捕获，ServiceA.methodA事务仍然可能提交。
5）PROPAGATION_NOT_SUPPORTED
 当前不支持事务。比方ServiceA.methodA的事务级别是PROPAGATION_REQUIRED 。而ServiceB.methodB的事务级别是PROPAGATION_NOT_SUPPORTED ，那么当执行到ServiceB.methodB时。ServiceA.methodA的事务挂起。而他以非事务的状态执行完，再继续ServiceA.methodA的事务。
6）PROPAGATION_NEVER
 不能在事务中执行。 如果ServiceA.methodA的事务级别是PROPAGATION_REQUIRED。 而ServiceB.methodB的事务级别是PROPAGATION_NEVER ，那么ServiceB.methodB就要抛出异常了。
7）PROPAGATION_NESTED
 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。
异常状态 PROPAGATION_REQUIRES_NEW（两个独立事务） PROPAGATION_NESTED(B的事务嵌套在A的事务中) PROPAGATION_REQUIRED(同一个事务) methodA抛异常methodB正常 A回滚，B正常提交 A与B一起回滚 A与B一起回滚 methodA正常methodB抛异常 1.如果A中捕获B的异常，并没有继续向上抛异常，则B先回滚，A再正常提交；2.如果A未捕获B的异常，默认则会将B的异常向上抛，则B先回滚，A再回滚 B先回滚，A再正常提交 A与B一起回滚 methodA抛异常methodB抛异常 B先回滚，A再回滚 A与B一起回滚 A与B一起回滚 methodA正常methodB正常 B先提交，A再提交 A与B一起提交 A与B一起提交 3、ioslation:事务隔离级别
​ (1)事务有特性成为隔离性，多事务操作之间不会产生影响。不考虑隔离性产生很多问题
​ (2)有三个读问题：脏读、不可重复读、虚(幻)读
​ (3)脏读：一个未提交事务读取到另一个未提交事务的数据
​ (4)不可重复读：一个未提交事务读取到另一提交事务修改数据
​ (5)虚读：一个未提交事务读取到另一提交事务添加数据
​ (6)解决：通过设置事务隔离级别，解决读问题
脏读 不可重复读 幻读 READ UNCOMMITTED（读未提交） 有 有 有 READ COMMITTED（读已提交） 无 有 有 REPEATABLE READ（可重复读） 无 无 有 SERIALIZABLE（串行化） 无 无 无 @Service @Transactional(propagation = Propagation.REQUIRED,isolation = Isolation.REPEATABLE_READ) public class UserService() { } 4、timeout：超时时间 (1)事务需要在一定时间内进行提交，如果不提交进行回滚 (2)默认值是 -1 ，设置时间以秒单位进行计算
5、readOnly：是否只读
​ (1)读：查询操作，写：添加修改删除操作
​ (2)readOnly 默认值 false，表示可以查询，可以添加修改删除操作
​ (3)设置 readOnly 值是 true，设置成 true 之后，只能查询
6、rollbackFor：回滚
​ (1)设置出现哪些异常进行事务回滚
7、noRollbackFor：不回滚
​ (1)设置出现哪些异常不进行事务回滚
3.4、XML 声明式事务管理 1、在 spring 配置文件中进行配置
第一步 配置事务管理器
第二步 配置通知
第三步 配置切入点和切面
&lt;!--1 创建事务管理器--> &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"> &lt;!--1 创建事务管理器--> &lt;property name="dataSource" ref="dataSource">&lt;/property> &lt;/bean> &lt;!--2 配置通知--> &lt;tx:advice id="txadvice"> &lt;!--配置事务参数--> &lt;tx:attributes> &lt;!--指定哪种规则的方法上面添加事务--> &lt;tx:method name="accountMoney" propagation="REQUIRED"/> &lt;!--&lt;tx:method name="account*"/>--> &lt;/tx:attributes> &lt;/tx:advice> &lt;!--3 配置切入点和切面--> &lt;aop:config> &lt;!--配置切入点--> &lt;aop:pointcut id="pt" expression="execution(*com.atguigu.spring5.service.UserService.*(..))"/> &lt;!--配置切面--> &lt;aop:advisor advice-ref="txadvice" pointcut-ref="pt"/> &lt;/aop:config> 3.5、完全注解声明式事务管理 1、创建配置类，使用配置类替代 xml 配置文件
@Configuration //配置类 @ComponentScan(basePackages = "com.atguigu") //组件扫描 @EnableTransactionManagement //开启事务 public class TxConfig { //创建数据库连接池 @Bean public DruidDataSource getDruidDataSource() { DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName("com.mysql.jdbc.Driver"); dataSource.setUrl("jdbc:mysql:///user_db"); dataSource.setUsername("root"); dataSource.setPassword("root"); return dataSource; } //创建 JdbcTemplate 对象 @Bean public JdbcTemplate getJdbcTemplate(DataSource dataSource) { //到 ioc 容器中根据类型找到 dataSource JdbcTemplate jdbcTemplate = new JdbcTemplate(); //注入 dataSource jdbcTemplate.setDataSource(dataSource); return jdbcTemplate; } //创建事务管理器 @Bean public DataSourceTransactionManager getDataSourceTransactionManager(DataSource dataSource) { DataSourceTransactionManager transactionManager = new DataSourceTransactionManager(); transactionManager.setDataSource(dataSource); return transactionManager; } } 四、spring框架新功能 1、 Spring5代码基于 Java8 ​ 运行时兼容 JDK9， 法在代码库中删除
2、自带了通用的日志封装 (1)Spring5 已经移除 Log4jConfigListener，官方建议使用 Log4j2
(2)Spring5 框架整合 Log4j2
第一步引入jar包
第二步 创建 log4j2.xml 配置文件
&lt;?xml veresion="1.0" encoding="UTF-8"?> &lt;!--日志级别以及优先级排序: OFF > FATAL > ERROR > WARN > INFO > DEBUG > TRACE > ALL --> &lt;!--Configuration 后面的 status 用于设置 log4j2 自身内部的信息输出，可以不设置， 当设置成 trace 时，可以看到 log4j2 内部各种详细输出--> &lt;configuration status="INFO"> &lt;!--先定义所有的 appender--> &lt;appenders> &lt;!--输出日志信息到控制台--> &lt;console name="Console" target="SYSTEM_OUT"> &lt;!--控制日志输出的格式--> &lt;PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n"/> &lt;/console> &lt;/appenders> &lt;!--然后定义 logger，只有定义 logger 并引入的 appender，appender 才会生效--> &lt;!--root:用于指定项目的根日志，如果没有单独指定 Logger，则会使用 root 作为 默认的日志输出--> &lt;loggers> &lt;root level="info"> &lt;appender-ref ref="Console"/> &lt;/root> &lt;/loggers> &lt;/configuration> 许多不建议使用的类和方
Spring 5.0 框架自带了通用的日志封装
3、Spring5整合JUnit5 第一步 引入 JUnit5 的 jar 包
第二步 创建测试类，使用注解完成
@ExtendWith(SpringExtension.class) @ContextConfiguration("classpath:bean1.xml") public class JTest5 { @Autowired private UserService userService; @Test public void test1() { userService.accountMoney(); } } 第三步 使用一个复合注解替代上面两个注解完成整合
@SpringJUnitConfig(locations = "classpath:bean1.xml") public class JTest5 { @Autowired private UserService userService; @Test public void test1() { userService.accountMoney(); } } 4、spring5新功能（Webflux） 4.1、SpringWebflux介绍 1）是 Spring5 添加新的模块，用于 web 开发的，功能和 SpringMVC 类似的，Webflux 使用当前一种比较流程响应式编程出现的框架。
2）使用传统 web 框架，比如 SpringMVC，这些基于 Servlet 容器，Webflux 是一种异步非阻塞的框架，异步非阻塞的框架在Servlet3.1以后才支持，核心是基于Reactor的相关API实现的。
3）解释什么是异步非阻塞
异步和同步 非阻塞和阻塞 阻塞需要等待，非阻塞不需要等待 上面都是针对对象不一样 异步和同步针对调用者，调用者发送请求，如果等着对方回应之后才去做其他事情就是同 步，如果发送请求之后不等着对方回应就去做其他事情就是异步
阻塞和非阻塞针对被调用者，被调用者受到请求之后，做完请求任务之后才给出反馈就是阻 塞，受到请求之后马上给出反馈然后再去做事情就是非阻塞
4）Webflux 特点: 第一 非阻塞式：在有限资源下，提高系统吞吐量和伸缩性，以 Reactor 为基础实现响应式编程
第二 函数式编程：Spring5 框架基于 java8，Webflux 使用 Java8 函数式编程方式实现路由请求
5）比较 SpringMVC
第一 两个框架都可以使用注解方式，都运行在 Tomet 等容器中
第二 SpringMVC 采用命令式编程，Webflux 采用异步响应式编程
4.2、响应式编程（Java实现） 1）什么是响应式编程
响应式编程是一种面向数据流和变化传播的编程范式。这意味着可以在编程语言中很方便地表达静态或动态的数据流，而相关的计算模型会自动将变化的值通过数据流进行传播。电子表格程序就是响应式编程的一个例子。单元格可以包含字面值或类似"=B1+C1"的公式，而包含公式的单元格的值会依据其他单元格的值的变化而变化。
2）Java8 及其之前版本
提供的观察者模式两个类 Observer 和 Observable
public class ObserverDemo extends Observable { public static void main(String[] args) { ObserverDemo observer = new ObserverDemo(); //添加观察者 observer.addObserver((o,arg)->{ System.out.println("发生变化"); }); observer.addObserver((o,arg)->{ System.out.println("手动被观察者通知，准备改变"); }); observer.setChanged(); //数据变化 observer.notifyObservers(); //通知 } } 4.3、响应式编程（Reactor） 1）响应式编程操作中，Reactor是满足 Reactive 规范框架
2）Reactor有两个核心类，Mono 和 Flux，这两个类实现接口 Publisher，提供丰富操作符。Flux 对象实现发布者，返回 N 个元素；Mono实现发布者，返回 0 或者 1 个元素
3）Flux 和 Mono 都是数据流的发布者，使用 Flux 和 Mono 都可以发出三种数据信号:
元素值，错误信号，完成信号，错误信号和完成信号都代表终止信号，终止信号用于告诉 订阅者数据流结束了，错误信号终止数据流同时把错误信息传递给订阅者</content></entry><entry><title>Java反射机制-内省(IntroSpector)</title><url>https://zhang4014439175.github.io/post/%E5%8F%8D%E5%B0%84-%E5%86%85%E7%9C%81/</url><categories><category>Java-Base</category><category>Spring</category></categories><tags><tag>Java</tag><tag>反射</tag><tag>Spring</tag></tags><content type="html">  开发时，经常需要使用java对象的属性来封装程序的数据(其实就是操作对象的set/get方法来设值或取值)，每次都使用反射来完成此类操作过于麻烦，所以JDK里提供了一套API，专门用于操作java对象的属性(set/get方法)。既然内省是专门用于操作java对象属性的，那首先得搞懂什么是对象的属性。
一、java对象的属性 说到属性，大家觉得很熟悉，属性不就是类里最上边的那些全局变量吗？
public class Person { private String name； private int age; } 这种不都是属性吗？其实，这是不对的，刚才说的name、age，准确的来说它们应该称为：“字段”，而不是咱们所说的属性。
Java中的属性是指：设置和读取字段的方法，说白了就是咱们平常见到的set和get方法，只要是set和get开头的方法在java里都认为它是属性(请注意这句话，等下后边会写代码做验证)，属性名称就是set和get方法名称去掉前缀后的内容。
例如：
public void setName(String name) {undefined this.name = name; } 它的属性名称是：name（也就是方法名称”setName”去掉“set”）
当然setName( );和getName( )是指同一个属性 name。
所以，咱们平常说的类里的全局变量，它并不是属性，正确的来说，它应该是字段，只不过咱们平常set和get方法写的名字和字段保持一致，所以导致大家把字段和属性认为是同一个东西。
二、内省的概念和使用 1、内省概念 Introspector 类提供了一种标准方式来了解目标 Java Bean 支持的属性、事件和方法。 Java Bean指的是符合一定规范编写的Java类，具体的规范包括：
属性私有，属性包括普通的类型的属性，EventListener。 提供默认的无参构造函数 私有化的属性可以通过setXxx, getXxx, addXxx, removeXxx, isXxx等类似的方法设置或获得，其中EvenetListener的方法格式为addXxxEventListener, setXxxEventListener。getXxxEventListener,removeXxxEventListener等。 也就意味着我们可以通内省机制获取类的JavaBean的属性，事件和方法。
其实内省就是操作set和get方法的。
那怎么才能得到类中的set和get方法并去操作它呢？通过反射肯定可以，但是在文章开头就已经说了，每次通过反射做的话过于麻烦，所以就出现了下边要讲的内省（Introspector），它就是专门做这个的，它底层也是用反射，只不过给咱们封装了，简化了操作。
public class Student {undefined private String name = "张三";//这是字段 private int age;//这是字段 private Date birthday; public String getName() {//这才是属性，属性指的是设置setter和读取getter字段的方法 return name; } public void setName(String name) {undefined this.name = name; } public int getAge() {undefined return age; } public void setAge(int age) {undefined this.age = age; } public Date getBirthday() {undefined return birthday; } public void setBirthday(Date birthday) {undefined this.birthday = birthday; } //虽然上边的字段里没定义abc这个字段 //但这也是属性：属性名称是abc，注意：只要是set或者get开头的方法都叫属性 public String getAbc(){undefined return "abc"; } } 对上面的对象进行操作，看看有多少个属性。
//内省:操作属性的（类中的getter和setter方法） public class Demo1 {undefined //属性名称：getClass,他的属性名称class //getAbc --->abc @Test public void test1() throws Exception{undefined //得到Student类中的属性，被封装到了BeanInfo中 BeanInfo bi = Introspector.getBeanInfo(Student.class); //得到类中的所有的属性描述器 PropertyDescriptor[] pds = bi.getPropertyDescriptors(); System.out.println("属性的个数："+pds.length); for(PropertyDescriptor pd:pds){undefined System.out.println("属性:"+pd.getName()); } } } 从运行结果上来看，一共得到了5个属性，除了name，age，birthday 外还打印出了abc。
上边的代码验证了：“属性其实是set、get方法”，而并不是类上边的那些字段，不然的话abc不会被打印出来的，但是name，age，birthday再加上abc应该是4个才对，那为什么会打印出5个呢？原因很简单，因为Object类是所有类的父类，Object类里有个方法叫 getClass()。
所以这也验证了咱们刚才说的： “只要是set或者get开头的方法都叫属性”。
2、内省操作 刚才的代码里用到了PropertyDescriptor 这个类，PropertyDescriptor顾名思义，就是属性描述之意。它通过反射 快速操作JavaBean的getter/setter方法。 也就是说它底层也是反射去操作set和get方法，只不过它给咱们封装了，用起来更方便。
PropertyDescriptor中重要的方法：
写方法：getWriteMethod() – 对应set方法，它的返回值是Method对像
读方法：getReadMethod() – 对应get方法，它的返回值是Method对像
//Student s = new Student(); //利用反射生成对象 //com.cj.study.introspector.Student该参数可以配置到配置文件里，这才是我们想要的 //是不是很熟悉？很多框架都是这么做的 Class clazz = Class.forName("com.cj.study.introspector.Student"); Student s = (Student)clazz.newInstance(); PropertyDescriptor pd = new PropertyDescriptor("name", Student.class); Method m = pd.getReadMethod();//得到getName()方法 String value = (String)m.invoke(s, null);//调用getName()方法 System.out.println("调用get方法得到name的值："+value); //改变name的值 Method m1 = pd.getWriteMethod();//得到setName()方法 m1.invoke(s, "李四");//调用setName()方法去修改name的值 System.out.println("调用set方法改变name的值："+s.getName()); 调用get方法得到name的值：张三 调用set方法改变name的值：李四 3、BeanUtils内省操作 操作之前，首先需要导入BeanUtils的jar包，以及它依赖的jar包。
commons-beanutils-1.8.3.jar
commons-logging-1.1.1.jar
导入jar包后，可以看到BeanUtils里有两个重要的方法：
(1).BeanUtils.getProperty(s, &ldquo;name&rdquo;);//调用getName方法
(2).BeanUtils.setProperty(s, &ldquo;name&rdquo;, &ldquo;王五&rdquo;);//调用setName方法
//内省:操作属性的（类中的getter和setter方法） public class Demo1 {undefined //利用BeanUtils框架操作属性:实现原理类似test2 @Test public void test3() throws Exception{undefined Student s = new Student(); //为什么要返回字符串：用户的所有输入都是字符串 String str = BeanUtils.getProperty(s, "name");//调用getName方法 System.out.println(str); //设置值 BeanUtils.setProperty(s, "name", "王五"); System.out.println(s.getName()); } } 张三 王五 4、BeanUtils类型转换的问题 有个问题需要注意：BeanUtils可以进行类型的自动转换，但仅限基本类型。
比如说本来需要int型，给个字符串 “28”，是可以的。
但是仅限基本数据类型，像Date 这种的就不行，会报错，下边用代码体现一下：
//基本数据类型自动转换 @Test public void test4() throws Exception{undefined Student s = new Student(); String str = BeanUtils.getProperty(s, "age"); System.out.println(str); BeanUtils.setProperty(s, "age", "19"); System.out.println(s.getAge()); } //0 //19 //非基本数据类型 @Test public void test5() throws Exception{undefined Student s = new Student(); String str = BeanUtils.getProperty(s, "birthday"); System.out.println(str); BeanUtils.setProperty(s, "birthday", "1989-10-09"); System.out.println(s.getBirthday()); } 发现非基本数据类型值没set进去，而且有错误提示
所以这里涉及到了BeanUtils里的String和其他类型间的互相转换的问题
要想解决这个问题，需要给BeanUtils注册一个类型转换器
代码实现一下
//非基本类型的属性设置 //用户的输入都是String //String &lt;----->其他类型间的互相转换 //用户看到的结果都是String @Test public void test6() throws Exception{undefined Student s = new Student(); //给BeanUtils注册类型转换器：自定义的转换器 ConvertUtils.register(new Converter() {undefined //type:目标类型 //value:当前传入的值 public Object convert(Class type, Object value) {undefined // if(type.equals(Date.class)){undefined // //字符串转换为Date // }else{undefined // //Date转换为字符串 // } DateFormat df = new SimpleDateFormat("yyyy-MM-dd"); if(value instanceof String){undefined //字符串转换为Date String v = (String)value; Date d; try {undefined d = df.parse(v); } catch (ParseException e) {undefined throw new RuntimeException(e); } return d; }else{undefined //Date转换为字符串 Date d = (Date)value; return df.format(d); } } }, Date.class); BeanUtils.setProperty(s, "birthday", "1989-10-09"); System.out.println(s.getBirthday()); } 但是这么手动的去写一个类型转换器，是不是太麻烦了，所以BeanUtils提供了Converter接口很多的实现类
其中有一个DateLocaleConverter类
所以上边的代码可以直接用DateLocaleConverter
@Test//转换器原理参考test6 public void test7() throws Exception{undefined Student s = new Student(); ConvertUtils.register(new DateLocaleConverter(), Date.class); BeanUtils.setProperty(s, "birthday", "1999-10-09"); System.out.println(s.getBirthday()); } 运行结果 发现用了它提供的DateLocaleConverter类后变得很简单，DateLocaleConverter实现的功能就是咱们test6里实现的，它的内部实现，其实和咱们test6里的原理一样。
5、BeanUtils将Map属性自动放到Bean中 package com.cj.study.introspector; import java.util.Date; public class Person {undefined private String name1;//请注意这里我写的是name1，并不是name private int age; private Date birthday; public String getName() {undefined return name1; } public void setName(String name) {//这里的属性写的才是name，进一步验证了属性的定义 this.name1 = name; } public int getAge() {undefined return age; } public void setAge(int age) {undefined this.age = age; } public Date getBirthday() {undefined return birthday; } public void setBirthday(Date birthday) {undefined this.birthday = birthday; } @Override public String toString() {undefined return "Person [age=" + age + ", birthday=" + birthday + ", name1=" \+ name1 + "]"; } } package com.cj.study.introspector; import java.util.Date; import java.util.HashMap; import java.util.Map; import org.apache.commons.beanutils.BeanUtils; import org.apache.commons.beanutils.ConvertUtils; import org.apache.commons.beanutils.locale.converters.DateLocaleConverter; import org.junit.Test; //利用BeanUtils封装数据 public class Demo2 {undefined @Test public void test1() throws Exception{undefined Map map = new HashMap(); //map中的key与属性一致，为了做区分请注意Person类里的字段我写的是name1，进一步验证了对属性的定义 map.put("name", "王小二"); map.put("age", "36"); map.put("birthday", "1979-10-09"); Person p = new Person(); System.out.println("封装数据前："+p); ConvertUtils.register(new DateLocaleConverter(), Date.class); BeanUtils.populate(p, map); System.out.println("封装数据后："+p); } } 运行结果 可以看到值被set进去了
正如大家看到的一样，很多的框架都用到了BeanUtils这个jar包
关于框架中怎么使用BeanUtils，我之前写过一篇手写代码模拟Struts2框架的文章，那里用到了BeanUtils
利用Java反射模拟一个Struts2框架 Struts2主要核心设计 手动实现Struts2核心代码
感兴趣的朋友可以看一下
好了，关于Java的内省，就介绍到这，欢迎大家留言，一起讨论，学习，一起进步</content></entry><entry><title>MySql基础（四）</title><url>https://zhang4014439175.github.io/post/mysql%E5%9B%9B/</url><categories><category>MySql</category></categories><tags><tag>MySql</tag><tag>Sql</tag></tags><content type="html"> 一、变量 在MySQL数据库的存储过程和函数中，可以使用变量来存储查询或计算的中间结果数据，或者输出最终
的结果数据。 在 MySQL 数据库中，变量分为系统变量以及用户自定义变量。
1、系统变量 变量由系统定义，不是用户定义，属于 层面。启动MySQL服务，生成MySQL服务实例期间， MySQL将为MySQL服务器内存中的系统变量赋值，这些系统变量定义了当前MySQL服务实例的属性、特 征。这些系统变量的值要么是 的默认值，要么是 (例如my.ini等)中的参数 值。大家可以通过网址https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html查看MySQL文档的系统变量。
系统变量分为全局系统变量(需要添加 关键字)以及会话系统变量(需要添加 关键 字)，有时也把全局系统变量简称为全局变量，有时也把会话系统变量称为local变量。 **如果不写，默认会话级别。**静态变量(在 MySQL 服务实例运行期间它们的值不能使用 set 动态修改)属于特殊的全局系 统变量。
每一个MySQL客户机成功连接MySQL服务器后，都会产生与之对应的会话。会话期间，MySQL服务实例会在MySQL服务器内存中生成与该会话对应的会话系统变量，这些会话系统变量的初始值是全局系统变 量值的复制。
全局系统变量针对于所有会话(连接)有效，但不能跨重启
会话1对某个全局系统变量值的修改会导致会话2中同一个全局系统变量值的修改。
1）在MySQL中有些系统变量只能是全局的，例如：
​ max_connections 用于限制服务器的最大连接数;
2）有些系统变量作用域既可以是全局又可以是会话，例如：
​ character_set_client 用于设置客户端的字符集
3）有些系 统变量的作用域只能是当前会话，例如：
​ pseudo_thread_id 用于标记当前会话的 MySQL 连接 ID。
1.1、查看系统变量 查看所有或部分系统变量
#查看所有全局变量 SHOWGLOBALVARIABLES;#查看所有会话变量 SHOWSESSIONVARIABLES;或SHOWVARIABLES;#查看满足条件的部分系统变量。 SHOWGLOBALVARIABLESLIKE'%标识符%';#查看满足条件的部分会话变量 SHOWSESSIONVARIABLESLIKE'%标识符%';举例：
SHOWGLOBALVARIABLESLIKE'admin_%';1.2、查看指定系统变量 作为 MySQL 编码规范，MySQL 中的系统变量以 两个“@” 开头，其中“@@global”仅用于标记全局系统变 量，“@@session”仅用于标记会话系统变量。“@@”首先标记会话系统变量，如果会话系统变量不存在， 则标记全局系统变量。
#查看指定的系统变量的值 SELECT@@global.变量名;#查看指定的会话变量的值 SELECT@@session.变量名;#或者 SELECT@@变量名;修改系统变量的值
有些时候，数据库管理员需要修改系统变量的默认值，以便修改当前会话或者MySQL服务实例的属性、 特征。具体方法:
方式1：修改MySQL 配置文件 ，继而修改MySQL系统变量的值(该方法需要重启MySQL服务)
方式2：在MySQL服务运行期间，使用“set”命令重新设置系统变量的值
#为某个系统变量赋值 #方式1: SET@@global.变量名=变量值;#方式2: SETGLOBAL变量名=变量值;#为某个会话变量赋值 #方式1: SET@@session.变量名=变量值;#方式2: SETSESSION变量名=变量值;举例：
SELECT@@global.autocommit;SETGLOBALautocommit=0;SELECT@@session.tx_isolation;SET@@session.tx_isolation='read-uncommitted';SETGLOBALmax_connections=1000;SELECT@@global.max_connections;2、用户变量 2.1、用户变量分类 用户变量是用户自己定义的，作为 MySQL 编码规范，MySQL 中的用户变量以 一个“@” 开头。根据作用 范围不同，又分为 会话用户变量 和 局部变量 。
会话用户变量：作用域和会话变量一样，只对 当前连接 会话有效。 局部变量：只在 BEGIN 和 END 语句块中有效。局部变量只能在 存储过程和函数 中使用。 2.2、会话用户变量 变量的定义
#方式1:“=”或“:=” SET@用户变量=值;SET@用户变量:=值;#方式2:“:=” 或 INTO关键字 SELECT@用户变量:=表达式[FROM等子句];SELECT表达式INTO@用户变量[FROM等子句];查看用户变量的值 (查看、比较、运算等)
SELECT@用户变量举例：
SET@a=1;SELECT@a;SELECT@num:=COUNT(*)FROMemployees;SELECT@num;SELECTAVG(salary)INTO@avgsalaryFROMemployees;SELECT@avgsalary;SELECT@big;#查看某个未声明的变量时，将得到NULL值 2.3、局部变量 定义：可以使用 DECLARE 语句定义一个局部变量
作用域：仅仅在定义它的 BEGIN &hellip; END 中有效
位置：只能放在 BEGIN &hellip; END 中，而且只能放在第一句
BEGIN#声明局部变量 DECLARE变量名1变量数据类型[DEFAULT变量默认值];DECLARE变量名2,变量名3,...变量数据类型[DEFAULT变量默认值];#为局部变量赋值 SET变量名1=值;SELECT值INTO变量名2[FROM子句];#查看局部变量的值 SELECT变量1,变量2,变量3;END1）定义变量
DECLARE变量名类型[default值];# 如果没有DEFAULT子句，初始值为NULL 举例:DECLAREmyparamINTDEFAULT100;2）变量赋值
方式1：一般用于赋简单的值SET变量名=值;SET变量名:=值;方式2：一般用于赋表中的字段值SELECT字段名或表达式INTO变量名FROM表;3）使用变量（查看、比较、运算等）
SELECT局部变量名;举例1：
声明局部变量，并分别赋值为employees表中employee_id为102的last_name和salary
DELIMITER//CREATEPROCEDUREset_value()BEGINDECLAREemp_nameVARCHAR(25);DECLAREsalDOUBLE(10,2);SELECTlast_name,salaryINTOemp_name,salFROMemployeesWHEREemployee_id=102;SELECTemp_name,sal;END//DELIMITER;举例2：
声明两个变量，求和并打印（分别使用会话用户变量、局部变量的方式实现）
#方式1:使用用户变量 SET @m=1; SET@n=1;SET@sum=@m+@n;SELECT@sum;#方式2:使用局部变量 DELIMITER//CREATEPROCEDUREadd_value()BEGIN#局部变量 DECLAREmINTDEFAULT1;DECLAREnINTDEFAULT3;DECLARESUMINT;SETSUM=m+n;SELECTSUM;END//DELIMITER;举例3：
创建存储过程“different_salary”查询某员工和他领导的薪资差距，并用IN参数emp_id接收员工 id，用OUT参数dif_salary输出薪资差距结果。
#声明 DELIMITER // CREATEPROCEDUREdifferent_salary(INemp_idINT,OUTdif_salaryDOUBLE)BEGIN#声明局部变量 DECLAREemp_sal,mgr_salDOUBLEDEFAULT0.0;DECLAREmgr_idINT;SELECTsalaryINTOemp_salFROMemployeesWHEREemployee_id=emp_id;SELECTmanager_idINTOmgr_idFROMemployeesWHEREemployee_id=emp_id;SELECTsalaryINTOmgr_salFROMemployeesWHEREemployee_id=mgr_id;SETdif_salary=mgr_sal-emp_sal;END//DELIMITER;#调用 SET@emp_id=102;CALLdifferent_salary(@emp_id,@diff_sal);#查看 SELECT@diff_sal;2.4、会话用户变量与局部变量 作用域 定义位置 语法 会话用户变量 当前会话 会话的任何地方 加@符号，不用指定类型 局部变量 定义它的BEGIN END中 BEGIN END的第一句话 一般不用加@,需要指定类型 二、定义条件与处理程序 定义条件 是事先定义程序执行过程中可能遇到的问题， 处理程序定义了在遇到问题时应当采取的处理方式，并且保证存储过程或函数在遇到警告或错误时能继续执行。这样可以增强存储程序处理问题的能力，避免程序异常停止运行。
说明：定义条件和处理程序在存储过程、存储函数中都是支持的。
1、案例分析 创建一个名称为“UpdateDataNoCondition”的存储过程。代码如下:
DELIMITER//CREATEPROCEDUREUpdateDataNoCondition()BEGINSET@x=1;UPDATEemployeesSETemail=NULLWHERElast_name='Abel';SET@x=2;UPDATEemployeesSETemail='aabbel'WHERElast_name='Abel';SET@x=3;END//DELIMITER;# 调用存储过程: mysql>CALLUpdateDataNoCondition();ERROR1048(23000):Column'email'cannotbenullmysql>SELECT@x;+------+|@x|+------+|1|+------+1rowinset(0.00sec)可以看到，此时@x变量的值为1。结合创建存储过程的SQL语句代码可以得出：在存储过程中未定义条件和处理程序，且当存储过程中执行的SQL语句报错时，MySQL数据库会抛出错误，并退出当前SQL逻辑， 不再向下继续执行。
2、定义条件 定义条件就是给MySQL中的错误码命名，这有助于存储的程序代码更清晰。它将一个 错误名字 和 指定的
错误条件 关联起来。这个名字可以随后被用在定义处理程序的 DECLARE HANDLER 语句中。
定义条件使用DECLARE语句，语法格式如下：
DECLARE错误名称CONDITIONFOR错误码(或错误条件)错误码的说明:
MySQL_error_code 和 sqlstate_value 都可以表示MySQL的错误。
MySQL_error_code是数值类型错误代码。 sqlstate_value是长度为5的字符串类型错误代码。 例如，在ERROR 1418 (HY000)中，1418是MySQL_error_code，&lsquo;HY000&rsquo;是sqlstate_value。
例如，在ERROR 1142(42000)中，1142是MySQL_error_code，&lsquo;42000&rsquo;是sqlstate_value。
举例1：定义“Field_Not_Be_NULL”错误名与MySQL中违反非空约束的错误类型是“ERROR 1048 (23000)”对应。
#使用MySQL_error_code DECLAREField_Not_Be_NULLCONDITIONFOR1048;#使用sqlstate_value DECLAREField_Not_Be_NULLCONDITIONFORSQLSTATE'23000';举例2**:**定义"ERROR 1148(42000)&ldquo;错误，名称为command_not_allowed。
#使用MySQL_error_code DECLAREcommand_not_allowedCONDITIONFOR1148;#使用sqlstate_value DECLAREcommand_not_allowedCONDITIONFORSQLSTATE'42000';3、定义处理程序 可以为SQL执行过程中发生的某种类型的错误定义特殊的处理程序。定义处理程序时，使用DECLARE语句的语法如下:
DECLARE处理方式HANDLERFOR错误类型处理语句处理方式：处理方式有3个取值:CONTINUE、EXIT、UNDO。
CONTINUE： 表示遇到错误不处理，继续执行。 EXIT： 表示遇到错误马上退出。 UNDO： 表示遇到错误后撤回之前的操作。MySQL中暂时不支持这样的操作。
错误类型 (即条件)可以有如下取值:
SQLSTATE ’字符串错误码‘：表示长度为5的sqlstate_value类型的错误代码; MySQL_error_code： 匹配数值类型错误代码; 错误名称： 表示DECLARE ... CONDITION定义的错误条件名称。 SQLWARNING： 匹配所有以01开头的SQLSTATE错误代码; NOT FOUND： 匹配所有以02开头的SQLSTATE错误代码; SQLEXCEPTION： 匹配所有没有被SQLWARNING或NOT FOUND捕获的SQLSTATE错误代码; 处理语句：
如果出现上述条件之一，则采用对应的处理方式，并执行指定的处理语句。语句可以是 像“ SET 变量 = 值 ”这样的简单语句，也可以是使用 BEGIN &hellip; END 编写的复合语句。
定义处理程序的几种方式，代码如下:
#方法1:捕获sqlstate_value DECLARECONTINUEHANDLERFORSQLSTATE'42S02'SET@info='NO_SUCH_TABLE';#方法2:捕获mysql_error_value DECLARECONTINUEHANDLERFOR1146SET@info='NO_SUCH_TABLE';#方法3:先定义条件，再调用 DECLAREno_such_tableCONDITIONFOR1146;DECLARECONTINUEHANDLERFORNO_SUCH_TABLESET@info='NO_SUCH_TABLE';#方法4:使用SQLWARNING DECLAREEXITHANDLERFORSQLWARNINGSET@info='ERROR';#方法5:使用NOT FOUND DECLAREEXITHANDLERFORNOTFOUNDSET@info='NO_SUCH_TABLE';#方法6:使用SQLEXCEPTION DECLAREEXITHANDLERFORSQLEXCEPTIONSET@info='ERROR';4、案例解决 在存储过程中，定义处理程序，捕获sqlstate_value值，当遇到MySQL_error_code值为1048时，执行 CONTINUE操作，并且将@proc_value的值设置为-1。
DELIMITER//CREATEPROCEDUREUpdateDataNoCondition()BEGIN#定义处理程序 DECLARECONTINUEHANDLERFOR1048SET@proc_value=-1;SET@x=1;SET@x=2;UPDATEemployeesSETemail='aabbel'WHERElast_name='Abel';SET@x=3;END//DELIMITER;# 调用过程: mysql>CALLUpdateDataWithCondition();QueryOK,0rowsaffected(0.01sec)mysql>SELECT@x,@proc_value;+------+-------------+|@x|@proc_value|+------+-------------+|3|-1|+------+-------------+1rowinset(0.00sec)三、流程控制 解决复杂问题不可能通过一个 SQL 语句完成，我们需要执行多个 SQL 操作。流程控制语句的作用就是控 制存储过程中 SQL 语句的执行顺序，是我们完成复杂操作必不可少的一部分。只要是执行的程序，流程 就分为三大类:
顺序结构：程序从上往下依次执行
分支结构：程序按条件进行选择执行，从两条或多条路径中选择一条执行
循环结构：程序满足一定条件下，重复执行一组语句
针对于MySQL 的流程控制语句主要有 3 类。注意:只能用于存储程序。
条件判断语句：IF 语句和 CASE 语句
循环语句：LOOP、WHILE 和 REPEAT 语句
跳转语句：ITERATE 和 LEAVE 语句
1、分支结构之 IF IF 语句的语法结构是:
IF表达式1THEN操作1[ELSEIF表达式2THEN操作2]......[ELSE操作N]ENDIF根据表达式的结果为TRUE或FALSE执行相应的语句。这里“[]”中的内容是可选的。
特点:1 不同的表达式对应不同的操作 2 使用在begin end中
举例1：
IFvalISNULLTHENSELECT'val is null';ELSESELECT'val is not null';ENDIF;举例2：
声明存储过程“update_salary_by_eid1”，定义IN参数emp_id，输入员工编号。判断该员工 薪资如果低于8000元并且入职时间超过5年，就涨薪500元;否则就不变。
DELIMITER//CREATEPROCEDUREupdate_salary_by_eid1(INemp_idINT)BEGINDECLAREemp_salaryDOUBLE;DECLAREhire_yearDOUBLE;SELECTsalaryINTOemp_salaryFROMemployeesWHEREemployee_id=emp_id;SELECTDATEDIFF(CURDATE(),hire_date)/365INTOhire_yearFROMemployeesWHEREemployee_id=emp_id;IFemp_salary&lt;8000ANDhire_year>5THENUPDATEemployeesSETsalary=salary+500WHEREemployee_id=emp_id;ENDIF;END//DELIMITER;举例3：
声明存储过程“update_salary_by_eid2”，定义IN参数emp_id，输入员工编号。判断该员工 薪资如果低于9000元并且入职时间超过5年，就涨薪500元;否则就涨薪100元。
DELIMITER//CREATEPROCEDUREupdate_salary_by_eid2(INemp_idINT)BEGINDECLAREemp_salaryDOUBLE;DECLAREhire_yearDOUBLE;SELECTsalaryINTOemp_salaryFROMemployeesWHEREemployee_id=emp_id;SELECTDATEDIFF(CURDATE(),hire_date)/365INTOhire_yearFROMemployeesWHEREemployee_id=emp_id;IFemp_salary&lt;8000ANDhire_year>5THENUPDATEemployeesSETsalary=salary+500WHEREemployee_id=emp_id;ELSEUPDATEemployeesSETsalary=salary+100WHEREemployee_id=emp_id;ENDIF;END//DELIMITER;举例4：
声明存储过程“update_salary_by_eid3”，定义IN参数emp_id，输入员工编号。
判断该员工 薪资如果低于9000元，就更新薪资为9000元;
薪资如果大于等于9000元且低于10000的，但是奖金 比例为NULL的，就更新奖金比例为0.01;
其他的涨薪100元。
DELIMITER//CREATEPROCEDUREupdate_salary_by_eid3(INemp_idINT)BEGINDECLAREemp_salaryDOUBLE;DECLAREbonusDECIMAL(3,2);SELECTsalaryINTOemp_salaryFROMemployeesWHEREemployee_id=emp_id;SELECTcommission_pctINTObonusFROMemployeesWHEREemployee_id=emp_id;IFemp_salary&lt;9000THENUPDATEemployeesSETsalary=9000WHEREemployee_id=emp_id;ELSEIFemp_salary&lt;10000ANDbonusISNULLTHENUPDATEemployeesSETcommission_pct=0.01WHEREemployee_id=emp_id;ELSEUPDATEemployeesSETsalary=salary+100WHEREemployee_id=emp_id;ENDIF;END//DELIMITER;2、分支结构之 CASE CASE 语句的语法结构1：
#情况一:类似于switch CASE表达式WHEN值1THEN结果1或语句1(如果是语句，需要加分号)WHEN值2THEN结果2或语句2(如果是语句，需要加分号)...ELSE结果n或语句n(如果是语句，需要加分号)END[case](如果是放在beginend中需要加上case，如果放在select后面不需要)CASE 语句的语法结构2：
#情况二:类似于多重if CASEWHEN条件1THEN结果1或语句1(如果是语句，需要加分号)WHEN条件2THEN结果2或语句2(如果是语句，需要加分号)...ELSE结果n或语句n(如果是语句，需要加分号)END[case](如果是放在beginend中需要加上case，如果放在select后面不需要)举例1： 使用CASE流程控制语句的第1种格式，判断val值等于1、等于2，或者两者都不等。
CASEvalWHEN1THENSELECT'val is 1';WHEN2THENSELECT'val is 2';ELSESELECT'val is not 1 or 2';ENDCASE;举例2**：** 使用CASE流程控制语句的第2种格式，判断val是否为空、小于0、大于0或者等于0。
CASEWHENvalISNULLTHENSELECT'val is null';WHENval&lt;0THENSELECT'val is less than 0';WHENval>0THENSELECT'val is greater than 0';ELSESELECT'val is 0';ENDCASE;举例3**：**声明存储过程“update_salary_by_eid4”，定义IN参数emp_id，输入员工编号。判断该员工 薪资如果低于9000元，就更新薪资为9000元;薪资大于等于9000元且低于10000的，但是奖金比例 为NULL的，就更新奖金比例为0.01;其他的涨薪100元。
DELIMITER//CREATEPROCEDUREupdate_salary_by_eid4(INemp_idINT)BEGINDECLAREemp_salDOUBLE;DECLAREbonusDECIMAL(3,2);SELECTsalaryINTOemp_salFROMemployeesWHEREemployee_id=emp_id;SELECTcommission_pctINTObonusFROMemployeesWHEREemployee_id=emp_id;CASEWHENemp_sal&lt;9000THENUPDATEemployeesSETsalary=9000WHEREemployee_id=emp_id;WHENemp_sal&lt;10000ANDbonusISNULLTHENUPDATEemployeesSETcommission_pct=0.01WHEREemployee_id=emp_id;ELSEUPDATEemployeesSETsalary=salary+100WHEREemployee_id=emp_id;ENDCASE;END//DELIMITER;举例4：声明存储过程update_salary_by_eid5，定义IN参数emp_id，输入员工编号。判断该员工的 入职年限，如果是0年，薪资涨50;如果是1年，薪资涨100;如果是2年，薪资涨200;如果是3年， 薪资涨300;如果是4年，薪资涨400;其他的涨薪500。
DELIMITER//CREATEPROCEDUREupdate_salary_by_eid5(INemp_idINT)BEGINDECLAREemp_salDOUBLE;DECLAREhire_yearDOUBLE;SELECTsalaryINTOemp_salFROMemployeesWHEREemployee_id=emp_id;SELECTROUND(DATEDIFF(CURDATE(),hire_date)/365)INTOhire_yearFROMemployeesWHEREemployee_id=emp_id;CASEhire_yearWHEN0THENUPDATEemployeesSETsalary=salary+50WHEREemployee_id=emp_id;WHEN1THENUPDATEemployeesSETsalary=salary+100WHEREemployee_id=emp_id;WHEN2THENUPDATEemployeesSETsalary=salary+200WHEREemployee_id=emp_id;WHEN3THENUPDATEemployeesSETsalary=salary+300WHEREemployee_id=emp_id;WHEN4THENUPDATEemployeesSETsalary=salary+400WHEREemployee_id=emp_id;ELSEUPDATEemployeesSETsalary=salary+500WHEREemployee_id=emp_id;ENDCASE;END//DELIMITER;3、循环结构之LOOP LOOP循环语句用来重复执行某些语句。LOOP内的语句一直重复执行直到循环被退出(使用LEAVE子
句)，跳出循环过程。
LOOP语句的基本格式如下:
[loop_label:]LOOP循环执行的语句ENDLOOP[loop_label]举例1：
其中，loop_label表示LOOP语句的标注名称，该参数可以省略。
DECLAREidINTDEFAULT0;add_loop:LOOPSETid=id+1;IFid>=10THENLEAVEadd_loop;ENDIF;ENDLOOPadd_loop;举例2：
当市场环境变好时，公司为了奖励大家，决定给大家涨工资。声明存储过程 “update_salary_loop()”，声明OUT参数num，输出循环次数。存储过程中实现循环给大家涨薪，薪资涨为 原来的1.1倍。直到全公司的平均薪资达到12000结束。并统计循环次数。
DELIMITER//CREATEPROCEDUREupdate_salary_loop(OUTnumINT)BEGINDECLAREavg_salaryDOUBLE;DECLAREloop_countINTDEFAULT0;SELECTAVG(salary)INTOavg_salaryFROMemployees;label_loop:LOOPIFavg_salary>=12000THENLEAVElabel_loop;ENDIF;UPDATEemployeesSETsalary=salary*1.1;SETloop_count=loop_count+1;SELECTAVG(salary)INTOavg_salaryFROMemployees;ENDLOOPlabel_loop;SETnum=loop_count;END//DELIMITER;</content></entry><entry><title>Java反射机制</title><url>https://zhang4014439175.github.io/post/%E5%8F%8D%E5%B0%84/</url><categories><category>Java-Base</category><category>Spring</category></categories><tags><tag>Java</tag><tag>反射</tag><tag>Spring</tag></tags><content type="html">  JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。
 要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象.
一、Java中创建对象的方式 java中创建对象大概有这几种方式：
使用new关键字：这是我们最常见的也是最简单的创建对象的方式
使用Clone的方法：无论何时我们调用一个对象的clone方法，JVM就会创建一个新的对象，将前面的对象的内容全部拷贝进去
使用反序列化：当我们序列化和反序列化一个对象，JVM会给我们创建一个单独的对象
上边是Java中常见的创建对象的三种方式，其实除了上边的三种还有另外一种方式，就是接下来我们要讨论的 “反射”
二、反射概述 1、什么是反射 反射就是把Java类中的各个组成部分进行解剖，并映射成一个个的Java对象，拿到这些对象后可以做一些事情。
既然说反射是解剖Java类中的各个组成部分，所以说咱们得知道一个类中有哪些部分？
例如，一个类有：构造方法，方法，成员变量(字段)，等信息，利用反射技术咱们可以把这些组成部分映射成一个个对象
拿到映射后的构造方法，可以用它来生成对象；拿到映射后的方法，可以调用它来执行对应的方法；拿到映射后的字段，可以用它来获取或改变对应字段的值；
2、反射能干什么 说完反射的概念后，咱们说一下反射能干什么？
一般来说反射是用来做框架的，或者说可以做一些抽象度比较高的底层代码，反射在日常的开发中用到的不多，但是咱们还必须搞懂它，因为搞懂了反射以后，可以帮助咱们理解框架的一些原理。所以说有一句很经典的话：反射是框架设计的灵魂。现在说完这个可能还不太能理解，不急，等下说完一个快速入门的例子后，应该会稍微有点感觉
3、怎么得到想反射的类 刚才已经说过，反射是对一个类进行解剖，想解剖一个东西，前提是首先你得拿到这个东西，那么怎么得到咱们想解剖的类呢？
首先大家要明白一点，咱们写的代码是存储在后缀名是 .java的文件里的，但是它会被编译，最终真正去执行的是编译后的 .class文件。Java是面向对象的语言，一切皆对象，所以java认为 这些编译后的 class文件，这种事物也是一种对象，它也给抽象成了一种类，这个类就是Class。
三、常用方法与应用 1、构造方法 1）获取单个构造方法 Class class = class.forName("com.lizi.pojo.Person"); Person person = new Person(); Class class = Person.class; //反射“一个和多个参数”的构造函数 Constructor c = class.getConstructor(String.class, int.class); c.newInstance("zhangsan",20); //暴力反射私有构造函数 Constructor c = class.getDeclaredConstructor(String.class, int.class); c.setAccessible(true); c.newInstance(20); 2）获取所有的构造方法 Constructor[] cs = class.getDeclaredConstructors(); Constructor[] cs = class.getConstructors()(); for(Constructor c: cs) { sout(c); } 3）获取main方法(同下) //1.获取Class对象 Class stuClass = Class.forName("fanshe.method.Student"); //2.获取所有公有方法 System.out.println("***************获取所有的”公有“方法*******************"); stuClass.getMethods(); Method[] methodArray = stuClass.getMethods(); for(Method m : methodArray){ System.out.println(m); } System.out.println("***************获取所有的方法，包括私有的*******************"); methodArray = stuClass.getDeclaredMethods(); for(Method m : methodArray){ System.out.println(m); } System.out.println("***************获取公有的show1()方法*******************"); Method m = stuClass.getMethod("show1", String.class); System.out.println(m); //实例化一个Student对象 Object obj = stuClass.getConstructor().newInstance(); m.invoke(obj, "刘德华"); System.out.println("***************获取私有的show4()方法******************"); m = stuClass.getDeclaredMethod("show4", int.class); System.out.println(m); m.setAccessible(true);//解除私有限定 Object result = m.invoke(obj, 20);//需要两个参数，一个是要调用的对象（获取有反射），一个是实参 System.out.println("返回值：" + result); 2、方法 批量的：
public Method[] getMethods():获取所有"公有方法"；（包含了父类的方法也包含Object类）
public Method[] getDeclaredMethods():获取所有的成员方法，包括私有的(不包括继承的)
获取单个的：
public Method getMethod(String name,Class&hellip; parameterTypes):
参数：
name : 方法名；
Class &hellip; : 形参的Class类型对象
public Method getDeclaredMethod(String name,Class&hellip; parameterTypes)
调用方法：
Method &ndash;> public Object invoke(Object obj,Object&hellip; args):
参数说明：
obj : 要调用方法的对象；
args:调用方式时所传递的实参；
1）获取所有的方法 //1.获取Class对象 Class stuClass = Class.forName("fanshe.method.Student"); //2.获取所有公有方法 System.out.println("***************获取所有的”公有“方法*******************"); stuClass.getMethods(); Method[] methodArray = stuClass.getMethods(); for(Method m : methodArray){ System.out.println(m); } System.out.println("***************获取所有的方法，包括私有的*******************"); methodArray = stuClass.getDeclaredMethods(); for(Method m : methodArray){ System.out.println(m); } System.out.println("***************获取公有的show1()方法*******************"); Method m = stuClass.getMethod("show1", String.class); System.out.println(m); //实例化一个Student对象 Object obj = stuClass.getConstructor().newInstance(); m.invoke(obj, "刘德华"); System.out.println("***************获取私有的show4()方法******************"); m = stuClass.getDeclaredMethod("show4", int.class); System.out.println(m); m.setAccessible(true);//解除私有限定 Object result = m.invoke(obj, 20);//需要两个参数，一个是要调用的对象（获取有反射），一个是实参 System.out.println("返回值：" + result); 2）获取单个方法 public void m1() { System.out.println("m1"); } public void m2(String name) { System.out.println(name); } public String m3(String name,int age) { System.out.println(name+":"+age); return "aaa"; } private void m4(Date d) { System.out.println(d); } public static void m5() { System.out.println("m5"); } public static void m6(String[] strs) { System.out.println(strs.length); } public class Demo2 { //获取单个方法 @Test//public void m1() public void test1() throws Exception{ Class clazz = Class.forName("com.cj.test.Person"); Person p = (Person)clazz.newInstance(); Method m = clazz.getMethod("m1", null); m.invoke(p, null); } @Test//public void m2(String name) public void test2() throws Exception{ Class clazz = Person.class; Person p = (Person) clazz.newInstance(); Method m = clazz.getMethod("m2", String.class); m.invoke(p, "张三"); } @Test//public String m3(String name,int age) public void test3() throws Exception{ Class clazz = Person.class; Person p = (Person) clazz.newInstance(); Method m = clazz.getMethod("m3", String.class,int.class); String returnValue = (String)m.invoke(p, "张三",23); System.out.println(returnValue); } @Test//private void m4(Date d) public void test4() throws Exception{ Class clazz = Person.class; Person p = (Person) clazz.newInstance(); Method m = clazz.getDeclaredMethod("m4", Date.class); m.setAccessible(true); m.invoke(p,new Date()); } @Test//public static void m5() public void test5() throws Exception{ Class clazz = Person.class; Method m = clazz.getMethod("m5", null); m.invoke(null,null); } @Test//private static void m6(String[] strs) public void test6() throws Exception{ Class clazz = Person.class; Method m = clazz.getDeclaredMethod("m6",String[].class); m.setAccessible(true); m.invoke(null,(Object)new String[]{"a","b"}); } @Test public void test7() throws Exception{ Class clazz = Person.class; Method m = clazz.getMethod("main",String[].class); m.invoke(null,new Object[]{new String[]{"a","b"}}); } public static void main(String[] args) { System.out.println("main"); } } 注意：看下上边代码里test6和test7的invoke方法里传的参数和其他的有点不一样
这是因为 jdk1.4和jdk1.5处理invoke方法有区别
1.5：public Object invoke(Object obj,Object…args)
1.4：public Object invoke(Object obj,Object[] args)
由于JDK1.4和1.5对invoke方法的处理有区别， 所以在反射类似于main(String[] args) 这种参数是数组的方法时需要特殊处理
启动Java程序的main方法的参数是一个字符串数组，即public static void main(String[] args)，通过反射方式来调用这个main方法时，如何为invoke方法传递参数呢？按jdk1.5的语法，整个数组是一个参数，而按jdk1.4的语法，数组中的每个元素对应一个参数，当把一个字符串数组作为参数传递给invoke方法时，javac会到底按照哪种语法进行处理呢？jdk1.5肯定要兼容jdk1.4的语法，会按jdk1.4的语法进行处理，即把数组打散成为若干个单独的参数。所以，在给main方法传递参数时，不能使用代码mainMethod.invoke(null,new String[]{“xxx”})，javac只把它当作jdk1.4的语法进行理解，而不把它当作jdk1.5的语法解释，因此会出现参数个数不对的问题。
上述问题的解决方法：
（1）mainMethod.invoke(null,new Object[]{new String[]{&ldquo;xxx&rdquo;}});
这种方式，由于你传的是一个数组的参数，所以为了向下兼容1.4的语法，javac遇到数组会给你拆开成多个参数，但是由于咱们这个Object[ ] 数组里只有一个元素值，所以就算它拆也没关系
（2）mainMethod.invoke(null,(Object)new String[]{&ldquo;xxx&rdquo;});
这种方式相当于你传的参数是一个对象，而不是数组，所以就算是按照1.4的语法它也不会拆，所以问题搞定
编译器会作特殊处理，编译时不把参数当作数组看待，也就不会数组打散成若干个参数了
对上边的描述进行一下总结：在反射方法时，如果方法的参数是一个数组，考虑到向下兼容问题，会按照JDK1.4的语法来对待（JVM会把传递的数组参数拆开，拆开就会报参数的个数不匹配的错误） 解决办法：防止JVM拆开你的数组 方式一：把数组看做是一个Object对象 方式二：重新构建一个Object数组，那个参数数组作为唯一的元素存在。
3、属性 1）获取类中的属性字段 获取成员变量并调用：
批量的
1).Field[] getFields():获取所有的"公有字段"
2).Field[] getDeclaredFields():获取所有字段，包括：私有、受保护、默认、公有；
获取单个的：
1).public Field getField(String fieldName):获取某个"公有的"字段；
2).public Field getDeclaredField(String fieldName):获取某个字段(可以是私有的)
设置字段的值：
Field &ndash;> public void set(Object obj,Object value):
参数说明：
1.obj:要设置的字段所在的对象；
2.value:要为字段设置的值；
//1.获取Class对象 Class stuClass = Class.forName("fanshe.field.Student"); //2.获取字段 System.out.println("************获取所有公有的字段********************"); Field[] fieldArray = stuClass.getFields(); for(Field f : fieldArray){ System.out.println(f); } System.out.println("************获取所有的字段(包括私有、受保护、默认的)********************"); fieldArray = stuClass.getDeclaredFields(); for(Field f : fieldArray){ System.out.println(f); } System.out.println("*************获取公有字段**并调用***********************************"); Field f = stuClass.getField("name"); System.out.println(f); //获取一个对象 Object obj = stuClass.getConstructor().newInstance();//产生Student对象--》Student stu = new Student(); //为字段设置值 f.set(obj, "刘德华");//为Student对象中的name属性赋值--》stu.name = "刘德华" //验证 Student stu = (Student)obj; System.out.println("验证姓名：" + stu.name); System.out.println("**************获取私有字段****并调用********************************"); f = stuClass.getDeclaredField("phoneNum"); System.out.println(f); f.setAccessible(true);//暴力反射，解除私有限定 f.set(obj, "18888889999"); System.out.println("验证电话：" + stu); 2）反射类中的属性字段 public String name="李四"; private int age = 18; public static Date time; @Test public void test1() throws Exception{ Class clazz = Person.class; Person p = (Person)clazz.newInstance(); Field f = clazz.getField("name"); String s = (String)f.get(p); System.out.println(s); //更改name的值 f.set(p, "王六"); System.out.println(p.name); } @Test//private int age = 18; public void test2() throws Exception{ Class clazz = Person.class; Person p = (Person)clazz.newInstance(); Field f = clazz.getDeclaredField("age"); f.setAccessible(true); int age = (Integer)f.get(p); System.out.println(age); f.set(p, 28); age = (Integer)f.get(p); System.out.println(age); } @Test//public static Date time; public void test3() throws Exception{ Class clazz = Person.class; Field f = clazz.getField("time"); f.set(null, new Date()); System.out.println(Person.time); } 以上就是自己对Java中反射的一些学习总结，欢迎大家留言一起学习、讨论。看完上边有关反射的东西， 对常用框架里的配置文件是不是有点思路了。
&lt;context:component-scan base-package="com.fztx"/> &lt;bean id="userService" class="com.fztx.service.UserService"/> 上边是Spring配置文件里的常见的bean配置，这看起来是不是可以用反射很轻易的就可以实现：解析xml然后把xml里的内容作为参数，利用反射创建对象。
拓展：
1、除了上述的Spring配置文件里会用到反射生成bean对象，其他常见的MVC框架，比如Struts2、SpringMVC等等一些框架里还有很多地方都会用到反射。
前端夜页面录入的一些信息通过表单或者其他形式传入后端，后端框架就可以利用反射生成对应的对象，并利用反射操作它的set、get方法把前端传来的信息封装到对象里。
感兴趣的话可以看下这篇：利用Java反射模拟一个Struts2框架 Struts2主要核心设计 手动实现Struts2核心代码，这篇里边包含了XML解析、反射的东西，模拟了一个Struts2的核心代码
2、框架的代码里经常需要利用反射来操作对象的set、get方法，来把程序的数据封装到Java对象中去。
如果每次都使用反射来操作对象的set、get方法进行设置值和取值的话，过于麻烦，所以JDK里提供了一套API，专门用于操作Java对象的属性(set/get方法)，这就是内省
关于内省相关的内容我也整理了一篇文章，感兴趣可以点击：Java反射——内省（Introspector）以及BeanUtils内省框架
3、平常用到的框架，除了配置文件的形式，现在很多都使用了注解的形式。
其实注解也和反射息息相关：使用反射也能轻而易举的拿到类、字段、方法上的注解，然后编写注解解析器对这些注解进行解析，做一些相关的处理
所以说不管是配置文件还是注解的形式，它们都和反射有关。注解和自定义注解的内容，最近也抽时间大概整理了一下，感兴趣的小可爱可以点击了解：Java中的注解以及自定义注解
写在最后：反射是框架的灵魂，具备反射知识和思想，是看懂框架的基础。希望看完文章后对你能有所帮助。
四、其他使用方法 1、通过反射运行配置文件内容 当我们升级这个系统时，不要Student类，而需要新写一个Student2的类时，这时只需要更改pro.txt的文件内容就可以了。代码就一点不用改动
配置文件：
//pro.txt className = cn.fanshe.Student methodName = show 使用案例：
public static void main(String[] args) throws Exception { //通过反射获取Class对象 Class stuClass = Class.forName(getValue("className"));//"cn.fanshe.Student" //2获取show()方法 Method m = stuClass.getMethod(getValue("methodName"));//show //3.调用show()方法 m.invoke(stuClass.getConstructor().newInstance()); } //此方法接收一个key，在配置文件中获取相应的value public static String getValue(String key) throws IOException{ Properties pro = new Properties();//获取配置文件的对象 FileReader in = new FileReader("pro.txt");//获取输入流 pro.load(in);//将流加载到配置文件对象中 in.close(); return pro.getProperty(key);//返回根据key获取的value值 } 2、通过反射越过泛型检查 有一个泛型为String的集合，通过反射向集合中添加一个Integer对象
public static void main(String[] args) throws Exception{ ArrayList&lt;String> strList = new ArrayList&lt;>(); strList.add("aaa"); strList.add("bbb"); // strList.add(100); //获取ArrayList的Class对象，反向的调用add()方法，添加数据 Class listClass = strList.getClass(); //得到 strList 对象的字节码 对象 //获取add()方法 Method m = listClass.getMethod("add", Object.class); //调用add()方法 m.invoke(strList, 100); //遍历集合 for(Object obj : strList){ System.out.println(obj); } 控制台输出： aaa bbb 100 反射就总结到这，下面的内省章节也和反射有关，可以算是反射的高级使用吧，如果有兴趣，可以继续查看总结的内省
部分。</content></entry><entry><title>MySql基础（三）</title><url>https://zhang4014439175.github.io/post/mysql%E4%B8%89/</url><categories><category>MySql</category></categories><tags><tag>MySql</tag><tag>Sql</tag></tags><content type="html"> 一、约束 1、为什么需要约束 数据完整性(Data Integrity)是指数据的精确性(Accuracy)和可靠性(Reliability)。它是防止数据库中 存在不符合语义规定的数据和防止因错误信息的输入输出造成无效操作或错误信息而提出的。
为了保证数据的完整性，SQL规范以约束的方式对 表数据进行额外的条件限制 。从以下四个方面考虑:
实体完整性：例如，同一个表中，不能存在两条完全相同无法区分的记录
域完整性：例如:年龄范围0-120，性别范围“男/女”
引用完整性：例如:员工所在部门，在部门表中要能找到这个部门
用户自定义完整性：例如:用户名唯一、密码不能为空等，本部门经理的工资不得高于本部门职工的平均工资的5倍。
2、什么是约束 约束是表级的强制规定。
可以在创建表时规定约束(通过 CREATE TABLE 语句)，或者在表创建之后通过 ALTER TABLE 语句规定 约束。
3、约束的分类 根据约束数据列的限制， 约束可分为:
单列约束 :每个约束只约束一列
多列约束 :每个约束可约束多列数据
根据约束的作用范围 ，约束可分为:
列级约束 :只能作用在一个列上，跟在列的定义后面
表级约束 :可以作用在多个列上，不与列一起，而是单独定义
根据约束起的作用 ，约束可分为:
NOT NULL 非空约束，规定某个字段不能为空
UNIQUE 唯一约束，规定某个字段在整个表中是唯一的
PRIMARY KEY 主键(非空且唯一)约束
FOREIGN KEY 外键约束
CHECK 检查约束
DEFAULT 默认值约束
4、非空约束 默认，所有的类型的值都可以是NULL，包括INT、FLOAT等数据类型
非空约束只能出现在表对象的列上，只能某个列单独限定非空，不能组合非空
一个表可以有很多列都分别限定了非空
空字符串&rsquo;&lsquo;不等于NULL，0也不等于NULL
建表前
CREATETABLE表名称(字段名数据类型,字段名数据类型NOTNULL,字段名数据类型NOTNULL);CREATETABLEstudent(sidint,snamevarchar(20)notnull,telchar(11),cardidchar(18)notnull);建表后
altertable表名称modify字段名数据类型notnull;altertablestudentmodifysnamevarchar(20)notnull;5、唯一性约束 用来限制某个字段/某列的值不能重复。
同一个表可以有多个唯一约束。
唯一约束可以是某一个列的值唯一，也可以多个列组合的值唯一。
唯一性约束允许列值为空。
在创建唯一约束的时候，如果不给唯一约束命名，就默认和列名相同。
MySQL会给唯一约束的列上默认创建一个唯一索引。
(1)建表时
createtable表名称(字段名数据类型,字段名数据类型unique,字段名数据类型uniquekey,字段名数据类型);createtable表名称(字段名数据类型,字段名数据类型,字段名数据类型,[constraint约束名]uniquekey(字段名));createtablestudent(sidint,snamevarchar(20),telchar(11)unique,cardidchar(18)uniquekey);CREATETABLEt_course(cidINTUNIQUE,cnameVARCHAR(100)UNIQUE,descriptionVARCHAR(200));CREATETABLEUSER(idINTNOTNULL,NAMEVARCHAR(25),PASSWORDVARCHAR(16),-- 使用表级约束语法 CONSTRAINTuk_name_pwdUNIQUE(NAME,PASSWORD));(2)建表后指定唯一键约束
#字段列表中如果是一个字段，表示该列的值唯一。如果是两个或更多个字段，那么复合唯一，即多个字段的组合是唯一的#方式1:altertable表名称adduniquekey(字段列表);#方式2:altertable表名称modify字段名字段类型unique;举例:
ALTERTABLEUSERADDUNIQUE(NAME,PASSWORD);ALTERTABLEUSERADDCONSTRAINTuk_name_pwdUNIQUE(NAME,PASSWORD);ALTERTABLEUSERMODIFYNAMEVARCHAR(20)UNIQUE;createtablestudent(sidintprimarykey,snamevarchar(20),telchar(11),cardidchar(18));altertablestudentadduniquekey(tel);altertablestudentadduniquekey(cardid);6、复合唯一约束 createtable表名称(字段名数据类型,字段名数据类型,字段名数据类型,uniquekey(字段列表)#字段列表中写的是多个字段名，多个字段名用逗号分隔，表示那么是复合唯一，即多个字段的组合是唯一的);#学生表createtablestudent(sidint,#学号snamevarchar(20),#姓名telchar(11)uniquekey,#电话cardidchar(18)uniquekey#身份证号);#课程表createtablecourse(cidint,#课程编号cnamevarchar(20)#课程名称);#选课表createtablestudent_course(idint,sidint,cidint,scoreint,uniquekey(sid,cid)#复合唯一);insertintostudentvalues(1,'张三','13710011002','101223199012015623');#成功insertintostudentvalues(2,'李四','13710011003','101223199012015624');#成功insertintocoursevalues(1001,'Java'),(1002,'MySQL');#成功7、主键约束 主键约束相当于 唯一约束+非空约束的组合 ，主键约束列不允许重复，也不允许出现空值。
一个表最多只能有一个主键约束，建立主键约束可以在列级别创建，也可以在表级别上创建。
主键约束对应着表中的一列或者多列(复合主键) 如果是多列组合的复合主键约束，那么这些列都不允许为空值，并且组合的值不允许重复。
MySQL的主键名总是PRIMARY ，就算自己命名了主键约束名也没用。
创建主键约束时，系统默认会在所在的列或列组合上建立对应的 主键索引 (能够根据主键查询 的，就根据主键查询，效率更高)。如果删除主键约束了，主键约束对应的索引就自动删除了。
需要注意的一点是，不要修改主键字段的值。因为主键是数据记录的唯一标识，如果修改了主键的值，就有可能会破坏数据的完整性。
1）建表时指定主键约束
createtable表名称(字段名数据类型primarykey,#列级模式字段名数据类型,字段名数据类型);createtable表名称(字段名数据类型,字段名数据类型,字段名数据类型,[constraint约束名]primarykey(字段名)#表级模式);举例：
createtabletemp(idintprimarykey,namevarchar(20));insertintotempvalues(1,'张三');#成功insertintotempvalues(2,'李四');#成功insertintotempvalues(1,'张三');#失败ERROR1062(23000):Duplicate(重复)entry(键入，输入)'1'forkey'PRIMARY'insertintotempvalues(1,'王五');#失败ERROR1062(23000):Duplicateentry'1'forkey'PRIMARY'insertintotempvalues(3,'张三');#成功2）复合主键
createtable表名称(字段名数据类型,字段名数据类型,字段名数据类型,primarykey(字段名1,字段名2)#表示字段1和字段2的组合是唯一的，也可以有更多个字段);#学生表createtablestudent(sidintprimarykey,#学号snamevarchar(20)#学生姓名);#课程表createtablecourse(cidintprimarykey,#课程编号cnamevarchar(20)#课程名称);#选课表createtablestudent_course(sidint,cidint,scoreint,primarykey(sid,cid)#复合主键);insertintostudentvalues(1,'张三'),(2,'李四');insertintocoursevalues(1001,'Java'),(1002,'MySQL');insertintostudent_coursevalues(1,1001,89),(1,1002,90),(2,1001,88),(2,1002,56);8、列级约束、表级约束 （1）作用范围
列级约束：只能应用于一列上。
表级约束：可以应用于一列上，也可以应用在一个表中的多个列上。
（即：如果你创建的约束涉及到该表的多个属性列，则必须创建的是表级约束（必须定义在表级上）；否则既可以定义在列级上也可以定义在表级上此时只是SQL语句格式不同而已）
（2）指定
列级约束：包含在列定义中，直接跟在该列的其它定义之后 ，用空格分隔；不必指定列名
表级约束：与列定义相互独立，不包含在列定义中；与定义用‘，’分隔；必须指出要约束的列的名称
（注：因为在创建列级约束时，只需将创建列约束的语句添加到该字段（列）的定义子句后面；而在创建表级约束时，需要将创建表级约束的语句添加到各个字段（列）定义语句的后面，因为并不是每个定义的字段都要创建约束，所以必须指明需要创建的约束的列名。）
9、自增列 auto_increment
1)一个表最多只能有一个自增长列
(2)当需要产生唯一标识符或顺序值时，可设置自增长
(3)自增长列约束的列必须是键列(主键列，唯一键列)
(4)自增约束的列的数据类型必须是整数类型
(5)如果自增列指定了 0 和 null，会在当前最大值的基础上自增;如果自增列手动指定了具体值，直接 赋值为具体值。
createtable表名称(字段名数据类型primarykeyauto_increment,字段名数据类型uniquekeynotnull,字段名数据类型uniquekey,字段名数据类型notnulldefault默认值,);createtable表名称(字段名数据类型default默认值,字段名数据类型uniquekeyauto_increment,字段名数据类型notnulldefault默认值,,primarykey(字段名));--建表前 createtableemployee(eidintprimarykeyauto_increment,enamevarchar(20));--建表后 altertable表名称modify字段名数据类型auto_increment;createtableemployee(eidintprimarykey,enamevarchar(20));altertableemployeemodifyeidintauto_increment;--删除主键自增 altertable表名称modify字段名数据类型;10、外键 FOREIGN KEY
1）主表和从表/父表和子表 主表(父表)：被引用的表，被参考的表
从表(子表)：引用别人的表，参考别人的表
例如：员工表的员工所在部门这个字段的值要参考部门表:部门表是主表，员工表是从表。
例如：学生表、课程表、选课表:选课表的学生和课程要分别参考学生表和课程表，学生表和课程表是主表，选课表是从表。
2）特点 (1)、从表的外键列，必须引用/参考主表的主键或唯一约束的列为什么？因为被依赖/被参考的值必须是唯一的
(2)、在创建外键约束时，如果不给外键约束命名， 默认名不是列名，而是自动产生一个外键名 (例如 student_ibfk_1;)，也可以指定外键约束名。
(3)、创建(CREATE)表时就指定外键约束的话，先创建主表，再创建从表 (4)删表时，先删从表(或先删除外键约束)，再删除主表
(5)、当主表的记录被从表参照时，主表的记录将不允许删除，如果要删除数据，需要先删除从表中依赖 该记录的数据，然后才可以删除主表的数据
(6)、在“从表”中指定外键约束，并且一个表可以建立多个外键约束
(7)、从表的外键列与主表被参照的列名字可以不相同，但是数据类型必须一样，逻辑意义一致。如果类 型不一样，创建子表时，就会出现错误“ERROR 1005 (HY000): Can&rsquo;t create table&rsquo;database.tablename&rsquo;(errno: 150)”。
(8)、当创建外键约束时，系统默认会在所在的列上建立对应的普通索引 。但是索引名是外键的约束 名。(根据外键查询效率很高)
(9)、删除外键约束后，必须 手动 删除对应的索引
3）建表时建立 createtable主表名称(字段1数据类型primarykey,字段2数据类型);createtable从表名称(字段1数据类型primarykey,字段2数据类型,[CONSTRAINT&lt;外键约束名称>]FOREIGNKEY(从表的某个字段)references主表名(被参考字段));#(从表的某个字段)的数据类型必须与主表名(被参考字段)的数据类型一致，逻辑意义也一样#(从表的某个字段)的字段名可以与主表名(被参考字段)的字段名一样，也可以不一样-- FOREIGN KEY: 在表级指定子表中的列 -- REFERENCES: 标示在父表中的列 createtabledept(#主表didintprimarykey,#部门编号dnamevarchar(50)#部门名称);createtableemp(#从表eidintprimarykey,#员工编号enamevarchar(5),#员工姓名deptidint,#员工所在的部门foreignkey(deptid)referencesdept(did)#emp表的deptid和和dept表的did的数据类型一致，意义都是表示部门的编号);说明:(1)主表dept必须先创建成功，然后才能创建emp表，指定外键成功。(2)删除表时，先删除从表emp，再删除主表dept4）建表后建立 一般情况下，表与表的关联都是提前设计好了的，因此，会在创建表的时候就把外键约束定义好。不过，如果需要修改表的设计(比如添加新的字段，增加新的关联关系)，但没有预先定义外键约束，那么，就要用修改表的方式来补充定义。
格式:
ALTERTABLE从表名ADD[CONSTRAINT约束名]FOREIGNKEY(从表的字段)REFERENCES主表名(被引用字段)[onupdatexx][ondeletexx];ALTERTABLEemp1ADD[CONSTRAINTemp_dept_id_fk]FOREIGNKEY(dept_id)REFERENCESdept(dept_id);createtabledept(didintprimarykey,#部门编号dnamevarchar(50)#部门名称);createtableemp(eidintprimarykey,#员工编号enamevarchar(5),#员工姓名deptidint#员工所在的部门);#这两个表创建时，没有指定外键的话，那么创建顺序是随意altertableempaddforeignkey(deptid)referencesdept(did);createtabledept(didintprimarykey,#部门编号dnamevarchar(50)#部门名称);createtableemp(eidintprimarykey,#员工编号enamevarchar(5),#员工姓名didint,#员工所在的部门foreignkey(did)referencesdept(did)#emp表的deptid和和dept表的did的数据类型一致，意义都是表示部门的编号#是否重名没问题，因为两个did在不同的表中);5）约束等级 Cascade方式：在父表上update/delete记录时，同步update/delete掉子表的匹配记录
Set null方式：在父表上update/delete记录时，将子表上匹配记录的列设为null，但是要注意子表的外键列不能为not null
No action方式：如果子表中有匹配的记录，则不允许对父表对应候选键进行update/delete操作
Restrict方式：同no action， 都是立即检查外键约束
Set default方式：(在可视化工具SQLyog中可能显示空白):父表有变更时，子表将外键列设置成一个默认的值，但Innodb不能识别
(1)演示1:on update cascade on delete set null
createtabledept(didintprimarykey,#部门编号dnamevarchar(50)#部门名称);createtableemp(eidintprimarykey,#员工编号enamevarchar(5),#员工姓名deptidint,#员工所在的部门foreignkey(deptid)referencesdept(did)onupdatecascadeondeletesetnull#把修改操作设置为级联修改等级，把删除操作设置为setnull等级);insertintodeptvalues(1001,'教学部');insertintodeptvalues(1002,'财务部');insertintodeptvalues(1003,'咨询部');insertintoempvalues(1,'张三',1001);#在添加这条记录时，要求部门表有1001部门insertintoempvalues(2,'李四',1001);insertintoempvalues(3,'王五',1002);#修改主表成功，从表也跟着修改，修改了主表被引用的字段1002为1004，从表的引用字段就跟着修改为1004了updatedeptsetdid=1004wheredid=1002;select*fromdept;select*fromemp;#删除主表的记录成功，从表对应的字段的值被修改为nulldeletefromdeptwheredid=1001;(2)演示2:on update set null on delete cascade
createtabledept(didintprimarykey,#部门编号dnamevarchar(50)#部门名称);createtableemp(eidintprimarykey,#员工编号enamevarchar(5),#员工姓名deptidint,#员工所在的部门foreignkey(deptid)referencesdept(did)onupdatesetnullondeletecascade#把修改操作设置为setnull等级，把删除操作设置为级联删除等级);insertintodeptvalues(1001,'教学部');insertintodeptvalues(1002,'财务部');insertintodeptvalues(1003,'咨询部');insertintoempvalues(1,'张三',1001);#在添加这条记录时，要求部门表有1001部门insertintoempvalues(2,'李四',1001);insertintoempvalues(3,'王五',1002);#修改主表，从表对应的字段设置为null，主表是dept，从表是empupdatedeptsetdid=1004wheredid=1002;#删除主表的记录成功，主表的1001行被删除了，从表相应的记录也被删除了deletefromdeptwheredid=1001;(3)演示:on update cascade on delete cascade
createtabledept(didintprimarykey,#部门编号dnamevarchar(50)#部门名称);createtableemp(eidintprimarykey,#员工编号enamevarchar(5),#员工姓名deptidint,#员工所在的部门foreignkey(deptid)referencesdept(did)onupdatecascadeondeletecascade#把修改操作设置为级联修改等级，把删除操作也设置为级联删除等级);insertintodeptvalues(1001,'教学部');insertintodeptvalues(1002,'财务部');insertintodeptvalues(1003,'咨询部');insertintoempvalues(1,'张三',1001);#在添加这条记录时，要求部门表有1001部门insertintoempvalues(2,'李四',1001);insertintoempvalues(3,'王五',1002);#修改主表，从表对应的字段自动修改mysql>updatedeptsetdid=1004wheredid=1002;#删除主表的记录成功，主表的1001行被删除了，从表相应的记录也被删除了mysql>deletefromdeptwheredid=1001;6）删除 (1)第一步先查看约束名和删除外键约束SELECT*FROMinformation_schema.table_constraintsWHEREtable_name='表名称';#查看某个表的约束名ALTERTABLE从表名DROPFOREIGNKEY外键约束名;(2)第二步查看索引名和删除索引。(注意，只能手动删除)SHOWINDEXFROM表名称;#查看某个表的索引名ALTERTABLE从表名DROPINDEX索引名;mysql>SELECT*FROMinformation_schema.table_constraintsWHEREtable_name='emp';mysql>altertableempdropforeignkeyemp_ibfk_1;mysql>showindexfromemp;mysql>altertableempdropindexdeptid;问题1**:如果两个表之间有关系(一对一、一对多)，比如:员工表和部门表(一对多)，它们之间是否一定要建外键约束?**
答:不是的
问题2**:建和不建外键约束有什么区别?**
答:建外键约束，你的操作(创建表、删除表、添加、修改、删除)会受到限制，从语法层面受到限制。例如:在员工表中不可能添加一个员工信息，它的部门的值在部门表中找不到。
不建外键约束，你的操作(创建表、删除表、添加、修改、删除)不受限制，要保证数据的 引用完整 性 ，只能依 靠程序员的自觉 ，或者是 在Java程序中进行限定 。例如:在员工表中，可以添加一个员工的 信息，它的部门指定为一个完全不存在的部门。
问题3**:那么建和不建外键约束和查询有没有关系?**
答:没有
11、CHECK约束 检查某个字段的值是否符号xx要求，一般指的是值的范围
createtableemployee(eidintprimarykey,enamevarchar(5),gendercharcheck('男'or'女'));insertintoemployeevalues(1,'张三','妖');CREATETABLEtemp(idINTAUTO_INCREMENT,NAMEVARCHAR(20),ageINTCHECK(age>20),PRIMARYKEY(id));agetinyintcheck(age>20)或sexchar(2)check(sexin(‘男’,’女’))CHECK(height>=0ANDheight&lt;3)12、DEFAULT约束 给某个字段/某列指定默认值，一旦设置默认值，在插入数据时，如果此字段没有显式赋值，则赋值为默 认值。
1）建表时添加 createtable表名称(字段名数据类型primarykey,字段名数据类型uniquekeynotnull,字段名数据类型uniquekey,字段名数据类型notnulldefault默认值,);createtable表名称(字段名数据类型default默认值,字段名数据类型notnulldefault默认值,字段名数据类型notnulldefault默认值,primarykey(字段名),uniquekey(字段名));说明：默认值约束一般不在唯一键和主键列上加createtableemployee(eidintprimarykey,enamevarchar(20)notnull,genderchardefault'男',telchar(11)notnulldefault''#默认是空字符串);2）建表后添加 altertable表名称modify字段名数据类型default默认值;#如果这个字段原来有非空约束，你还保留非空约束，那么在加默认值约束时，还得保留非空约束，否则非空约束就被 删除了 #同理，在给某个字段加非空约束也一样，如果这个字段原来有默认值约束，你想保留，也要在modify语句中保留默 认值约束，否则就删除了 altertable表名称modify字段名数据类型default默认值notnull;createtableemployee(eidintprimarykey,enamevarchar(20),genderchar,telchar(11)notnull);altertableemployeemodifygenderchardefault'男';#给gender字段增加默认值约束 altertableemployeemodifytelchar(11)default'';#给tel字段增加默认值约束 altertableemployeemodifytelchar(11)default''notnull;#给tel字段增加默认值约束，并 保留非空约束 altertable表名称modify字段名数据类型;#删除默认值约束，也不保留非空约束 altertable表名称modify字段名数据类型notnull;#删除默认值约束，保留非空约束 altertableemployeemodifygenderchar;#删除gender字段默认值约束，如果有非空约束，也一并删除 altertableemployeemodifytelchar(11)notnull;#删除tel字段默认值约束，保留非空约束 面试1**、为什么建表时，加** not null default &rsquo;&rsquo; 或 default 0
答:不想让表中出现null值。
面试2**、为什么不想要** null 的值
答:
(1)不好比较。null是一种特殊值，比较时只能用专门的is null 和 is not null来比较。碰到运算符，通 常返回null。
(2)效率不高。影响提高索引效果。因此，我们往往在建表时 not null default &rsquo;&rsquo; 或 default 0
面试3**、带AUTO_INCREMENT约束的字段值是从1开始的吗?**
在MySQL中，默认AUTO_INCREMENT的初始 值是1，每新增一条记录，字段值自动加1。设置自增属性(AUTO_INCREMENT)的时候，还可以指定第 一条插入记录的自增字段的值，这样新插入的记录的自增字段值从初始值开始递增，如在表中插入第一 条记录，同时指定id值为5，则以后插入的记录的id值就会从6开始往上增加。添加主键约束时，往往需要 设置字段自动增加属性。
面试4**、并不是每个表都可以任意选择存储引擎?** 外键约束(FOREIGN KEY)不能跨引擎使用。
MySQL支持多种存储引擎，每一个表都可以指定一个不同的存储引擎，需要注意的是:外键约束是用来 保证数据的参照完整性的，如果表之间需要关联外键，却指定了不同的存储引擎，那么这些表之间是不 能创建外键约束的。所以说，存储引擎的选择也不完全是随意的。
二、视图 视图一方面可以帮我们使用表的一部分而不是所有的表，另一方面也可以针对不同的用户制定不同的查 询视图。比如，针对一个公司的销售人员，我们只想给他看部分数据，而某些特殊的数据，比如采购的 价格，则不会提供给他。再比如，人员薪酬是个敏感的字段，那么只给某个级别以上的人员开放，其他 人的查询视图中则不提供这个字段。 刚才讲的只是视图的一个使用场景，实际上视图还有很多作用。最后，我们总结视图的优点。 视图是一种 虚拟表 ，本身是 不具有数据 的，占用很少的内存空间，它是 SQL 中的一个重要概念。
视图建立在已有表的基础上, 视图赖以建立的这些表称为基表。
视图的创建和删除只影响视图本身，不影响对应的基表。但是当对视图中的数据进行增加、删除和修改操作时，数据表中的数据会相应地发生变化，反之亦然。
向视图提供数据内容的语句为 SELECT 语句, 可以将视图理解为存储起来的 SELECT 语句
在数据库中，视图不会保存数据，数据真正保存在数据表中。当对视图中的数据进行增加、删 除和修改操作时，数据表中的数据会相应地发生变化;反之亦然。 视图，是向用户提供基表数据的另一种表现形式。通常情况下，小型项目的数据库可以不使用视图，但是在大型项目中，以及数据表比较复杂的情况下，视图的价值就凸显出来了，它可以帮助我们把经常查询的结果集放到虚拟表中，提升使用效率。理解和使用起来都非常方便。
1、创建视图 在 CREATE VIEW 语句中嵌入子查询
CREATE[ORREPLACE][ALGORITHM={UNDEFINED|MERGE|TEMPTABLE}]VIEW视图名称[(字段列表)]AS查询语句[WITH[CASCADED|LOCAL]CHECKOPTION]举例：
CREATEVIEWempvu80ASSELECTemployee_id,last_name,salaryFROMemployeesWHEREdepartment_id=80;CREATEVIEWemp_year_salary(ename,year_salary)ASSELECTename,salary*12*(1+IFNULL(commission_pct,0))FROMt_employee;说明1:实际上就是我们在 SQL 查询语句的基础上封装了视图 VIEW，这样就会基于 SQL 语句的结果集形 成一张虚拟表。
说明2:在创建视图时，没有在视图名后面指定字段列表，则视图中字段列表默认和SELECT语句中的字 段列表一致。如果SELECT语句中给字段取了别名，那么视图中的字段名和别名相同。
1）多表联合视图 CREATEVIEWempviewASSELECTemployee_idemp_id,last_nameNAME,department_nameFROMemployeese,departmentsdWHEREe.department_id=d.department_id;CREATEVIEWemp_deptASSELECTename,dnameFROMt_employeeLEFTJOINt_departmentONt_employee.did=t_department.did;CREATEVIEWdept_sum_vu(name,minsal,maxsal,avgsal)ASSELECTd.department_name,MIN(e.salary),MAX(e.salary),AVG(e.salary)FROMemployeese,departmentsdWHEREe.department_id=d.department_idGROUPBYd.department_name;2）利用视图对数据进行格式化 --我们经常需要输出某个格式的内容，比如我们想输出员工姓名和对应的部门名，对应格式为 emp_name(department_name)，就可以使用视图来完成数据格式化的操作: CREATEVIEWemp_departASSELECTCONCAT(last_name,'(',department_name,')')ASemp_deptFROMemployeeseJOINdepartmentsdWHEREe.department_id=d.department_id3）基于视图创建视图 当我们创建好一张视图之后，还可以在它的基础上继续创建视图。
举例:联合“emp_dept”视图和“emp_year_salary”视图查询员工姓名、部门名称、年薪信息创建 “emp_dept_ysalary”视图。
CREATEVIEWemp_dept_ysalaryASSELECTemp_dept.ename,dname,year_salaryFROMemp_deptINNERJOINemp_year_salaryONemp_dept.ename=emp_year_salary.ename;2、查看视图 语法1：查看数据库的表对象、视图对象
SHOWTABLES;语法2：查看视图的结构
DESC/DESCRIBE视图名称;语法3：查看视图的属性信息
# 查看视图信息(显示数据表的存储引擎、版本、数据行数和数据大小等) SHOWTABLESTATUSLIKE'视图名称'\G执行结果显示，注释Comment为VIEW，说明该表为视图，其他的信息为NULL，说明这是一个虚表。
语法4：查看视图的详细定义信息
SHOWCREATEVIEW视图名称;3、更新视图数据 3.1、一般情况
MySQL支持使用INSERT、UPDATE和DELETE语句对视图中的数据进行插入、更新和删除操作。当视图中的 数据发生变化时，数据表中的数据也会发生变化，反之亦然。
3.2 不可更新的视图 要使视图可更新，视图中的行和底层基本表中的行之间必须存在 一对一 的关系。另外当视图定义出现如下情况时，视图不支持更新操作:
在定义视图的时候指定了“ALGORITHM = TEMPTABLE”，视图将不支持INSERT和DELETE操作;
视图中不包含基表中所有被定义为非空又未指定默认值的列，视图将不支持INSERT操作;
在定义视图的SELECT语句中使用了JOIN联合查询，视图将不支持INSERT和DELETE操作;
在定义视图的SELECT语句后的字段列表中使用了数学表达式或子查询 ，视图将不支持INSERT，也不支持UPDATE使用了数学表达式、子查询的字段值;
在定义视图的SELECT语句后的字段列表中使用 DISTINCT、聚合函数、GROUP BY、HAVING 、UNION 等，视图将不支持INSERT、UPDATE、DELETE;
定义视图的SELECT语句中包含了子查询，而子查询中引用了FROM后面的表，视图将不支持 INSERT、UPDATE、DELETE;
视图定义基于一个 不可更新视图 ;
常量视图。
4、修改视图 1）使用CREATE OR REPLACE VIEW子句修改视图
CREATEORREPLACEVIEWempvu80(id_number,name,sal,department_id)ASSELECTemployee_id,first_name||' '||last_name,salary,department_idFROMemployeesWHEREdepartment_id=80;2）ALTER VIEW
ALTERVIEW视图名称AS查询语句5、删除视图 删除视图只是删除视图的定义，并不会删除基表的数据。
删除视图的语法是:
DROPVIEWIFEXISTS视图名称;举例:
DROPVIEWempvu80;说明:基于视图a、b创建了新的视图c，如果将视图a或者视图b删除，会导致视图c的查询失败。这样的视图c需要手动删除或修改，否则影响使用。
6、总结 操作简单 将经常使用的查询操作定义为视图，可以使开发人员不需要关心视图对应的数据表的结构、表与表之间 的关联关系，也不需要关心数据表之间的业务逻辑和查询条件，而只需要简单地操作视图即可，极大简 化了开发人员对数据库的操作。
减少数据冗余 视图跟实际数据表不一样，它存储的是查询语句。所以，在使用的时候，我们要通过定义视图的查询语句来获取结果集。而视图本身不存储数据，不占用数据存储的资源，减少了数据冗余。
数据安全 MySQL将用户对数据的访问限制在某些数据的结果集上，而这些数据的结果集可以使用视图来实现。用 户不必直接查询或操作数据表。这也可以理解为视图具有隔离性 。视图相当于在用户和实际的数据表之间加了一层虚拟表。
同时，MySQL可以根据权限将用户对数据的访问限制在某些视图上， 用户不需要查询数据表，可以直接通过视图获取数据表中的信息 。这在一定程度上保障了数据表中数据的安全性。
适应灵活多变的需求 当业务系统的需求发生变化后，如果需要改动数据表的结构，则工作量相对较大，可以使用视图来减少改动的工作量。这种方式在实际工作中使用得比较多。
能够分解复杂的查询逻辑 数据库中如果存在复杂的查询逻辑，则可以将问题进行分解，创建多个视图获取数据，再将创建的多个视图结合起来，完成复杂的查询逻辑。
三、存储过程 1、理解 1.1、含义 存储过程的英文是 Stored Procedure 。它的思想很简单，就是一组经过 预先编译 的 SQL 语句
的封装。 执行过程:存储过程预先存储在 MySQL 服务器上，需要执行的时候，客户端只需要向服务器端发出调用
存储过程的命令，服务器端就可以把预先存储好的这一系列 SQL 语句全部执行。
1.2、好处 1、简化操作，提高了sql语句的重用性，减少了开发程序员的压力
2、减少操作过程中的失误，提高效率
3、减少网络传输量(客户端不需要把所有的 SQL 语句通过网络发给服务器)
4、减少了 SQL 语句暴露在 网上的风险，也提高了数据查询的安全性
1.3、和视图、函数的对比 它和视图有着同样的优点，清晰、安全，还可以减少网络传输量。不过它和视图不同，视图是虚拟表，通常不对底层数据表直接操作，而存储过程是程序化的 SQL，可以直接操作底层数据表 ，相比于面向集合的操作方式，能够实现一些更复杂的数据处理。
一旦存储过程被创建出来，使用它就像使用函数一样简单，我们直接通过调用存储过程名即可。相较于函数，存储过程是没有返回值的。
2、分类 存储过程的参数类型可以是IN、OUT和INOUT。根据这点分类如下:
1、没有参数(无参数无返回)
2、仅仅带 IN 类型(有参数无返回)
3、仅仅带 OUT 类型(无参数有返 回)
4、既带 IN 又带 OUT(有参数有返回)
5、带 INOUT(有参数有返回)
注意:IN、OUT、INOUT 都可以在一个存储过程中带多个。
3、创建 语法:
CREATEPROCEDURE存储过程名(IN|OUT|INOUT参数名参数类型,...)[characteristics...]BEGIN存储过程体END类似于Java中的方法:
修饰符返回类型方法名(参数类型参数名,...){方法体;}说明:
3.1、参数前面的符号的意思 IN :当前参数为输入参数，也就是表示入参; 存储过程只是读取这个参数的值。如果没有定义参数种类， 默认就是 IN ，表示输入参数。
OUT :当前参数为输出参数，也就是表示出参; 执行完成之后，调用这个存储过程的客户端或者应用程序就可以读取这个参数返回的值了。
INOUT :当前参数既可以为输入参数，也可以为输出参数。
3.2、形参类型 可以是 MySQL数据库中的任意类型。
3.3、characteristics 表示创建存储过程时指定的对存储过程的约束条件，其取值信息如下:
LANGUAGESQL|[NOT]DETERMINISTIC|{CONTAINSSQL|NOSQL|READSSQLDATA|MODIFIESSQLDATA}|SQLSECURITY{DEFINER|INVOKER}|COMMENT'string' LANGUAGE SQL :说明存储过程执行体是由SQL语句组成的，当前系统支持的语言为SQL。
[NOT] DETERMINISTIC :指明存储过程执行的结果是否确定。DETERMINISTIC表示结果是确定 的。每次执行存储过程时，相同的输入会得到相同的输出。NOT DETERMINISTIC表示结果是不确定 的，相同的输入可能得到不同的输出。如果没有指定任意一个值，默认为NOT DETERMINISTIC。
{ CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA } :指明子程序使 用SQL语句的限制。
CONTAINS SQL表示当前存储过程的子程序包含SQL语句，但是并不包含读写数据的SQL语句;
NO SQL表示当前存储过程的子程序中不包含任何SQL语句;
READS SQL DATA表示当前存储过程的子程序中包含读数据的SQL语句;
MODIFIES SQL DATA表示当前存储过程的子程序中包含写数据的SQL语句。
默认情况下，系统会指定为CONTAINS SQL。
SQL SECURITY { DEFINER | INVOKER } :执行当前存储过程的权限，即指明哪些用户能够执 行当前存储过程。
DEFINER表示只有当前存储过程的创建者或者定义者才能执行当前存储过程; INVOKER表示拥有当前存储过程的访问权限的用户能够执行当前存储过程。 如果没有设置相关的值，则MySQL默认指定值为DEFINER。
3.4、BEGIN和END 存储过程体中可以有多条 SQL 语句，如果仅仅一条SQL 语句，则可以省略 BEGIN 和 END
编写存储过程并不是一件简单的事情，可能存储过程中需要复杂的 SQL 语句。
1.BEGIN...END:BEGIN...END中间包含了多个语句，每个语句都以(;)号为结束符。2.DECLARE:DECLARE用来声明变量，使用的位置在于BEGIN...END语句中间，而且需要在其他语句使用之前进行变量的声明。3.SET:赋值语句，用于对变量进行赋值。4.SELECT...INTO:把从数据表中查询的结果存放到变量中，也就是为变量赋值。3.5、需要设置新的结束标记 DELIMITER新的结束标记因为MySQL默认的语句结束符号为分号‘;’。为了避免与存储过程中SQL语句结束符相冲突，需要使用 DELIMITER改变存储过程的结束符。
比如:“DELIMITER //”语句的作用是将MySQL的结束符设置为//，并以“END //”结束存储过程。存储过程定 义完毕之后再使用“DELIMITER ;”恢复默认结束符。DELIMITER也可以指定其他符号作为结束符。
当使用DELIMITER命令时，应该避免使用反斜杠(‘\’)字符，因为反斜线是MySQL的转义字符。
示例:
DELIMITER$CREATEPROCEDURE存储过程名(IN|OUT|INOUT参数名参数类型,...)[characteristics...]BEGINsql语句1;sql语句2;END$代码举例：
举例1：创建存储过程select_all_data()，查看 emps 表的所有数据
DELIMITER$CREATEPROCEDUREselect_all_data()BEGINSELECT*FROMemps;END$DELIMITER;举例2：创建存储过程avg_employee_salary()，返回所有员工的平均工资
DELIMITER//CREATEPROCEDUREavg_employee_salary()BEGINSELECTAVG(salary)ASavg_salaryFROMemps;END//DELIMITER;举例3：创建存储过程show_max_salary()，用来查看“emps”表的最高薪资值。
CREATEPROCEDUREshow_max_salary()LANGUAGESQLNOTDETERMINISTICCONTAINSSQLSQLSECURITYDEFINERCOMMENT'查看最高薪资'BEGINSELECTMAX(salary)FROMemps;END//DELIMITER;举例4：创建存储过程show_min_salary()，查看“emps”表的最低薪资值。并将最低薪资通过OUT参数“ms” 输出
DELIMITER//CREATEPROCEDUREshow_min_salary(OUTmsDOUBLE)BEGINSELECTMIN(salary)INTOmsFROMemps;END//DELIMITER;举例5：创建存储过程show_someone_salary()，查看“emps”表的某个员工的薪资，并用IN参数empname 输入员工姓名。
DELIMITER//CREATEPROCEDUREshow_someone_salary(INempnameVARCHAR(20))BEGINSELECTsalaryFROMempsWHEREename=empname;END//DELIMITER;举例6：创建存储过程show_someone_salary2()，查看“emps”表的某个员工的薪资，并用IN参数empname 输入员工姓名，用OUT参数empsalary输出员工薪资。
DELIMITER//CREATEPROCEDUREshow_someone_salary2(INempnameVARCHAR(20),OUTempsalaryDOUBLE)BEGINSELECTsalaryINTOempsalaryFROMempsWHEREename=empname;END//DELIMITER;举例7：创建存储过程show_mgr_name()，查询某个员工领导的姓名，并用INOUT参数“empname”输入员 工姓名，输出领导的姓名。
DELIMITER//CREATEPROCEDUREshow_mgr_name(INOUTempnameVARCHAR(20))BEGINSELECTenameINTOempnameFROMempsWHEREeid=(SELECTMIDFROMempsWHEREename=empname);END//DELIMITER;4、使用 4.1、调用格式 存储过程有多种调用方法。存储过程必须使用CALL语句调用，并且存储过程和数据库相关，如果要执行其他数据库中的存储过程，需要指定数据库名称，例如CALL dbname.procname。
CALL存储过程名(实参列表)格式:
1、调用in模式的参数:
CALLsp1('值');2、调用out模式的参数:
SET@name;CALLsp1(@name);SELECT@name;3、调用inout模式的参数:
SET@name;CALLsp1(@name);SELECT@name;示例1：
DELIMITER//CREATEPROCEDURECountProc(INsidINT,OUTnumINT)BEGINSELECTCOUNT(*)INTOnumFROMfruitsWHEREs_id=sid;END//DELIMITER;# 调用存储过程 mysql>CALLCountProc(101,@num);QueryOK,1rowaffected(0.00sec)# 查看返回结果: mysql>SELECT@num;# 该存储过程返回了指定 s_id=101 的水果商提供的水果种类，返回值存储在num变量中，使用SELECT查看，返回结果为3 示例2：
# 创建存储过程，实现累加运算，计算 1+2+...+n 等于多少。具体的代码如下: DELIMITER//CREATEPROCEDURE`add_num`(INnINT)BEGINDECLAREiINT;DECLAREsumINT;SETi=1;SETsum=0;WHILEi&lt;=nDOSETsum=sum+i;SETi=i+1;ENDWHILE;SELECTsum;END//DELIMITER;如果你用的是 Navicat 工具，那么在编写存储过程的时候，Navicat 会自动设置 DELIMITER 为其他符号， 我们不需要再进行 DELIMITER 的操作。
直接使用 CALL add_num(50); 即可。这里我传入的参数为 50，也就是统计 1+2+&hellip;+50 的积累之和。
4.2、如何调试 在 MySQL 中，存储过程不像普通的编程语言(比如 VC++、Java 等)那样有专门的集成开发环境。因此，你可以通过 SELECT 语句，把程序执行的中间结果查询出来，来调试一个 SQL 语句的正确性。调试 成功之后，把 SELECT 语句后移到下一个 SQL 语句之后，再调试下一个 SQL 语句。这样 逐步推进 ，就可 以完成对存储过程中所有操作的调试了。当然，你也可以把存储过程中的 SQL 语句复制出来，逐段单独 调试。
5、存储函数的使用 前面学习了很多函数，使用这些函数可以对数据进行的各种处理操作，极大地提高用户对数据库的管理效率。MySQL支持自定义函数，定义好之后，调用方式与调用MySQL预定义的系统函数一样。
5.1、语法 CREATEFUNCTION函数名(参数名参数类型,...)RETURNS返回值类型[characteristics...]BEGIN函数体#函数体中肯定有 RETURN 语句 END说明:
1、参数列表:指定参数为IN、OUT或INOUT只对PROCEDURE是合法的，FUNCTION中总是默认为IN参 数。
2、RETURNS type 语句表示函数返回数据的类型; RETURNS子句只能对FUNCTION做指定，对函数而言这是 强制 的。它用来指定函数的返回类型，而且函
数体必须包含一个 RETURN value 语句。 3、characteristic 创建函数时指定的对函数的约束。取值与创建存储过程时相同，这里不再赘述。
4、函数体也可以用BEGIN&hellip;END来表示SQL代码的开始和结束。如果函数体只有一条语句，也可以省略 BEGIN&hellip;END。
5.2、调用存储函数 在MySQL中，存储函数的使用方法与MySQL内部函数的使用方法是一样的。换言之，用户自己定义的存 储函数与MySQL内部函数是一个性质的。区别在于，存储函数是 用户自己定义 的，而内部函数是MySQL 的 开发者定义 的。
SELECT函数名(实参列表)示例1：
创建存储函数，名称为email_by_name()，参数定义为空，该函数查询Abel的email，并返回，数据类型为 字符串型。
DELIMITER//CREATEFUNCTIONemail_by_name()RETURNSVARCHAR(25)DETERMINISTICCONTAINSSQLBEGINRETURN(SELECTemailFROMemployeesWHERElast_name='Abel');END//DELIMITER;# 调用: SELECTemail_by_name();举例2：
创建存储函数，名称为email_by_id()，参数传入emp_id，该函数查询emp_id的email，并返回，数据类型 为字符串型。
DELIMITER//CREATEFUNCTIONemail_by_id(emp_idINT)RETURNSVARCHAR(25)DETERMINISTICCONTAINSSQLBEGINRETURN(SELECTemailFROMemployeesWHEREemployee_id=emp_id);END//DELIMITER;#调用 SET@emp_id=102;SELECTemail_by_id(102);举例3：
创建存储函数count_by_id()，参数传入dept_id，该函数查询dept_id部门的员工人数，并返回，数据类型
为整型。
DELIMITER//CREATEFUNCTIONcount_by_id(dept_idINT)RETURNSINTLANGUAGESQLNOTDETERMINISTICREADSSQLDATASQLSECURITYDEFINERCOMMENT'查询部门平均工资'BEGINRETURN(SELECTCOUNT(*)FROMemployeesWHEREdepartment_id=dept_id);END//DELIMITER;# 调用: SET@dept_id=50;SELECTcount_by_id(@dept_id);注意：
若在创建存储函数中报错“you might want to use the less safe log_bin_trust_function_creators variable”，有两种处理方法:
方式1：
加上必要的函数特性“[NOT] DETERMINISTIC”和“{CONTAINS SQL | NO SQL | READS SQL DATA |MODIFIES SQL DATA}”
方式2：
mysql> SET GLOBAL log_bin_trust_function_creators = 1; 5.3、对比存储过程和存储函数 关键字 语法 返回值 应用场景 存储过程 PROCEDURE CALL 存储过程() 理解为有0个或多个 一般用于更新 存储函数 FUNCTION SELECT 函数() 只能是一个 一般用于查询结果为一个值并返回时 5.4、存储过程和函数的查看、修改、删除 1）查看
创建完之后，怎么知道我们创建的存储过程、存储函数是否成功了呢?
MySQL存储了存储过程和函数的状态信息，用户可以使用SHOW STATUS语句或SHOW CREATE语句来查 看，也可直接从系统的information_schema数据库中查询。这里介绍3种方法。
使用SHOW CREATE语句查看存储过程和函数的创建信息 基本语法结构如下:
SHOWCREATE{PROCEDURE|FUNCTION}存储过程名或函数名举例：
SHOWCREATEFUNCTIONtest_db.CountProc\G使用SHOW STATUS语句查看存储过程和函数的状态信息 基本语法结构如下:
SHOW{PROCEDURE|FUNCTION}STATUS[LIKE'pattern']这个语句返回子程序的特征，如数据库、名字、类型、创建者及创建和修改日期。
mysql>SHOWPROCEDURESTATUSLIKE'SELECT%'\G***************************1.row***************************Db:test_dbName:SelectAllDataType:PROCEDUREDefiner:root@localhostModified:2021-10-1615:55:07Created:2021-10-1615:55:07Security_type:DEFINERComment:character_set_client:utf8mb4collation_connection:utf8mb4_general_ciDatabaseCollation:utf8mb4_general_ci1rowinset(0.00sec)从information_schema.Routines表中查看存储过程和函数的信息 MySQL中存储过程和函数的信息存储在information_schema数据库下的Routines表中。可以通过查询该表的记录来查询存储过程和函数的信息。其基本语法形式如下:
SELECT*FROMinformation_schema.RoutinesWHEREROUTINE_NAME='存储过程或函数的名'[ANDROUTINE_TYPE={'PROCEDURE|FUNCTION'}];说明：如果在MySQL数据库中存在存储过程和函数名称相同的情况，最好指定ROUTINE_TYPE查询条件来 指明查询的是存储过程还是函数。
举例：从Routines表中查询名称为CountProc的存储函数的信息，代码如下:
SELECT*FROMinformation_schema.RoutinesWHEREROUTINE_NAME='count_by_id'ANDROUTINE_TYPE='FUNCTION'\G2）修改
修改存储过程或函数，不影响存储过程或函数功能，只是修改相关特性。使用ALTER语句实现。
ALTER{PROCEDURE|FUNCTION}存储过程或函数的名[characteristic...]其中，characteristic指定存储过程或函数的特性，其取值信息与创建存储过程、函数时的取值信息略有不同。
{CONTAINSSQL|NOSQL|READSSQLDATA|MODIFIESSQLDATA}|SQLSECURITY{DEFINER|INVOKER}|COMMENT'string' CONTAINS SQL ，表示子程序包含SQL语句，但不包含读或写数据的语句。
NO SQL ，表示子程序中不包含SQL语句。
READS SQL DATA ，表示子程序中包含读数据的语句。
MODIFIES SQL DATA ，表示子程序中包含写数据的语句。
SQL SECURITY { DEFINER | INVOKER } ，指明谁有权限来执行。
DEFINER，表示只有定义者自己才能够执行 INVOKER，表示调用者可以执行 COMMENT &lsquo;string&rsquo;，表示注释信息
举例1：
修改存储过程CountProc的定义。将读写权限改为MODIFIES SQL DATA，并指明调用者可以执行，代码如下:
ALTERPROCEDURECountProcMODIFIESSQLDATASQLSECURITYINVOKER;查询修改后的信息：
SELECTspecific_name,sql_data_access,security_typeFROMinformation_schema.`ROUTINES`WHEREroutine_name='CountProc'ANDroutine_type='PROCEDURE';结果显示，存储过程修改成功。从查询的结果可以看出，访问数据的权限(SQL_DATA_ ACCESS)已经变 成MODIFIES SQL DATA，安全类型(SECURITY_TYPE)已经变成INVOKER。
举例2：
修改存储函数CountProc的定义。将读写权限改为READS SQL DATA，并加上注释信息“FIND NAME”，代码如下:
ALTERFUNCTIONCountProcREADSSQLDATACOMMENT'FIND NAME';存储函数修改成功。从查询的结果可以看出，访问数据的权限（SQL_DATA_ACCESS）已经变成READS SQL DATA，函数注释（ROUTINE_COMMENT）已经变成FIND NAME。
3）删除
删除存储过程和函数，可以使用DROP语句，其语法结构如下:
DROP{PROCEDURE|FUNCTION}[IFEXISTS]存储过程或函数的名IF EXISTS:如果程序或函数不存储，它可以防止发生错误，产生一个用SHOW WARNINGS查看的警告。
举例:
DROPPROCEDURECountProc;DROPFUNCTIONCountProc;5.5、存储过程使用的争议
尽管存储过程有诸多优点，但是对于存储过程的使用， 一直都存在着很多争议 ，比如有些公司对于大型 项目要求使用存储过程，而有些公司在手册中明确禁止使用存储过程，为什么这些公司对存储过程的使 用需求差别这么大呢?
优点：
1**、存储过程可以一次编译多次使用。** 存储过程只在创建时进行编译，之后的使用都不需要重新编译，这就提升了 SQL 的执行效率。
2**、可以减少开发工作量。**将代码封装成模块，实际上是编程的核心思想之一，这样可以把复杂的问题拆解成不同的模块，然后模块之间可以重复使用 ，在减少开发工作量的同时，还能保证代码的结构清晰。
3**、存储过程的安全性强。**我们在设定存储过程的时候可以设置对用户的使用权限 ，这样就和视图一样具有较强的安全性。
4**、可以减少网络传输量。** 因为代码封装到存储过程中，每次使用只需要调用存储过程即可，这样就减少了网络传输量。
5**、良好的封装性。**在进行相对复杂的数据库操作时，原本需要使用一条一条的 SQL 语句，可能要连接 多次数据库才能完成的操作，现在变成了一次存储过程，只需要 连接一次即可 。
缺点：
基于上面这些优点，不少大公司都要求大型项目使用存储过程，比如微软、IBM 等公司。但是国内的阿里并不推荐开发人员使用存储过程，这是为什么呢?
【阿里开发规范】 【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。 存储过程虽然有诸如上面的好处，但缺点也是很明显的。
1**、可移植性差。**
存储过程不能跨数据库移植，比如在 MySQL、Oracle 和 SQL Server 里编写的存储过程，在换成其他数据库时都需要重新编写。
2**、调试困难。**
只有少数 DBMS 支持存储过程的调试。对于复杂的存储过程来说，开发和维护都不容易。虽然也有一些第三方工具可以对存储过程进行调试，但要收费。
3**、存储过程的版本管理很困难。**
比如数据表索引发生变化了，可能会导致存储过程失效。我们在开发软件的时候往往需要进行版本管理，但是存储过程本身没有版本控制，版本迭代更新的时候很麻烦。
4**、它不适合高并发的场景。**
高并发的场景需要减少数据库的压力，有时数据库会采用分库分表的方 式，而且对可扩展性要求很高，在这种情况下，存储过程会变得难以维护， 增加数据库的压力 ，显然就不适用了。
小结:
存储过程既方便，又有局限性。尽管不同的公司对存储过程的态度不一，但是对于我们开发人员来说， 不论怎样，掌握存储过程都是必备的技能之一。</content></entry><entry><title>MySql基础（二）</title><url>https://zhang4014439175.github.io/post/mysql%E4%BA%8C/</url><categories><category>MySql</category></categories><tags><tag>MySql</tag><tag>Sql</tag></tags><content type="html"> 一、分页 1、公式 LIMIT [位置偏移量,] 行数 举例
--前10条记录: SELECT*FROM表名LIMIT0,10;或者SELECT*FROM表名LIMIT10;--第11至20条记录: SELECT*FROM表名LIMIT10,10;--第21至30条记录: SELECT*FROM表名LIMIT20,10;MySQL 8.0中可以使用“LIMIT 3 OFFSET 4”，意思是获取从第5条记录开始后面的3条记录，和“LIMIT 4,3;”返回的结果相同。
2、分页显式公式 (当前页数-1)*每页条数，每页条数SELECT*FROMtableLIMIT(PageNo-1)*PageSize,PageSize;3、使用limit的好处 约束返回结果的数量可以 ，也可以 提升查询效率 。如果我们知道返回结果只有 1 条，就可以使用 ，告诉 SELECT 语句只需要返回一条记录即可。这样的好处就是 SELECT 不需 要扫描完整的表，只需要检索到一条符合条件的记录即可返回。
4、拓展 在不同的 DBMS 中使用的关键字可能不同。在 MySQL、PostgreSQL、MariaDB 和 SQLite 中使用 LIMIT 关
键字，而且需要放到 SELECT 语句的最后面。
如果是SQLServer和Access，需要使用 TOP 关键字，比如:
SELECTTOP5name,hp_maxFROMherosORDERBYhp_maxDESC如果是 DB2，使用 FETCH FIRST 5 ROWS ONLY 这样的关键字:
SELECTname,hp_maxFROMherosORDERBYhp_maxDESCFETCHFIRST5ROWSONLY如果是Oracle，你需要基于 ROWNUM 来统计行数:
SELECTrownum,last_name,salaryFROMemployeesWHERErownum&lt;5ORDERBYsalaryDESC;需要说明的是，这条语句是先取出来前 5 条数据行，然后再按照 hp_max 从高到低的顺序进行排序。但这样产生的结果和上述方法的并不一样。我会在后面讲到子查询，你可以使用得到与上述方法一致的结果。
SELECTrownum,last_name,salaryFROM(SELECTlast_name,salaryFROMemployeesORDERBYsalaryDESC)WHERErownum&lt;10;二、多表查询 多表查询，也称为关联查询，指两个或更多个表一起完成查询操作。
前提条件:这些一起查询的表之间是有关系的(一对一、一对多)，它们之间一定是有关联字段，这个 关联字段可能建立了外键，也可能没有建立外键。比如:员工表和部门表，这两个表依靠“部门编号”进 行关联。
1、笛卡尔积 a1 a2 b1 b2
a aa 1 11
b bb 2 22
a aa 1 11
a aa 2 22
b bb 1 11
b bb 2 22
2、内外连接 内连接：合并具有同一列的两个以上的表的行, 结果集中不包含一个表与另一个表不匹配的行
SELECT字段列表FROMA表INNERJOINB表ON关联条件WHERE等其他子句;例子：
SELECTe.employee_id,e.last_name,e.department_id,d.department_id,d.location_idFROMemployeeseJOINdepartmentsdON(e.department_id=d.department_id);SELECTemployee_id,city,department_nameFROMemployeeseJOINdepartmentsdONd.department_id=e.department_idJOINlocationslONd.location_id=l.location_id;外连接：两个表在连接过程中除了返回满足连接条件的行以外还返回左(或右)表中不满足条件的行 ，这种连接称为左(或右) 外连接。没有匹配的行时, 结果表中相应的列为空(NULL)。
#实现查询结果是ASELECT字段列表FROMA表LEFTJOINB表ON关联条件WHERE等其他子句;例子：
SELECTe.last_name,e.department_id,d.department_nameFROMemployeeseLEFTOUTERJOINdepartmentsdON(e.department_id=d.department_id);如果是左外连接，则连接条件中左边的表也称为 主表 ，右边的表称为 从表 。
如果是右外连接，则连接条件中右边的表也称为 主表 ，左边的表称为 从表 。
3、联合查询 1） UNION
SELECTcolumn,...FROMtable1UNION[ALL]SELECTcolumn,...FROMtable2UNION ALL操作符返回两个查询的结果集的并集。对于两个结果集的重复部分，不去重。
注意：执行UNION ALL语句时所需要的资源比UNION语句少。如果明确知道合并数据后的结果数据 不存在重复数据，或者不需要去除重复的数据，则尽量使用UNION ALL语句，以提高数据查询的效 率。
案例：
查询部门编号>90或邮箱包含a的员工信息
#方式1SELECT*FROMemployeesWHEREemailLIKE'%a%'ORdepartment_id>90;#方式2SELECT*FROMemployeesWHEREemailLIKE'%a%'UNIONSELECT*FROMemployeesWHEREdepartment_id>90;查询中国用户中男性的信息以及美国用户中年男性的用户信息
SELECTid,cnameFROMt_chinamaleWHEREcsex='男'UNIONALLSELECTid,tnameFROMt_usmaleWHEREtGender='male';4、等值连接 vs 非等值连接 等值连接：就是 where a.dept_Id = b.id
非等值连接：就是between and
1）多个连接条件与 AND 操作符
2）区分重复的列名
多个表中有相同列时，必须在列名之前加上表名前缀。
在不同表中具有相同列名的列可以用 表名 加以区分。
SELECT employees.last_name, departments.department_name,employees.department_id FROM employees, departments WHERE employees.department_id = departments.department_id; 3）表的别名
使用别名可以简化查询。 列名前使用表名前缀可以提高查询效率。
SELECT e.employee_id, e.last_name, e.department_id, d.department_id, d.location_id FROM employees e , departments d WHERE e.department_id = d.department_id; 需要注意的是，如果我们使用了表的别名，在查询字段中、过滤条件中就只能使用别名进行代替， 不能使用原有的表名，否则就会报错。 阿里开发规范 : 【 强制 】对于数据库中表记录的查询和变更，只要涉及多个表，都需要在列名前加表的别名(或 表名)进行限定。 说明 :对多表进行查询记录、更新记录、删除记录时，如果对操作列没有限定表的别名(或表 名)，并且操作列在多个表中存在时，就会抛异常。 正例 :select t1.name from table_first as t1 , table_second as t2 where t1.id=t2.id; 反例 :在某业务中，由于多表关联查询语句没有加表的别名(或表名)的限制，正常运行两年 后，最近在 某个表中增加一个同名字段，在预发布环境做数据库变更后，线上查询语句出现出 1052 异常:Column 'name' in field list is ambiguous。 4）连接多个表
总结：连接 n个表,至少需要n-1个连接条件。比如，连接三个表，至少需要两个连接条件。
练习：查询出公司员工的 last_name,department_name, city
5、自连接 vs 非自连接 当table1和table2本质上是同一张表，只是用取别名的方式虚拟成两张表以代表不同的意义。
然后两 个表再进行内连接，外连接等查询。
1）内连接: 合并具有同一列的两个以上的表的行, 结果集中不包含一个表与另一个表不匹配的行
2）外连接: 两个表在连接过程中除了返回满足连接条件的行以外还返回左(或右)表中不满足条件的行 ，这种连接称为左(或右) 外连接。没有匹配的行时, 结果表中相应的列为空(NULL)。
如果是左外连接，则连接条件中左边的表也称为 主表 ，右边的表称为 从表 。
如果是右外连接，则连接条件中右边的表也称为 主表 ，左边的表称为 从表 。
三、单行函数 1、数值函数 1）基本函数 函数 用法 ABS(x) 返回x的绝对值 SIGN(X) 返回X的符号。正数返回1，负数返回-1，0返回0 PI() 返回圆周率的值 CEIL(x)，CEILING(x) 返回大于或等于某个值的最小整数 FLOOR(x) 返回小于或等于某个值的最大整数 LEAST(e1,e2,e3&hellip;) 返回列表中的最小值 GREATEST(e1,e2,e3&hellip;) 返回列表中的最大值 MOD(x,y) 返回X除以Y后的余数 RAND() 返回0~1的随机值 RAND(x) 返回0~1的随机值，其中x的值用作种子值，相同的X值会产生相同的随机数 ROUND(x) 返回一个对x的值进行四舍五入后，最接近于X的整数 ROUND(x,y) 返回一个对x的值进行四舍五入后最接近X的值，并保留到小数点后面Y位 TRUNCATE(x,y) 返回数字x截断为y位小数的结果 SQRT(x) 返回x的平方根。当X的值为负数时，返回NULL 2）角度与弧度互换函数 函数 用法 RADIANS(x) 将角度转化为弧度，其中，参数x为角度值 DEGREES(x) 将弧度转化为角度，其中，参数x为弧度值 3）三角函数 函数 用法 SIN(x) 返回x的正弦值，其中，参数x为弧度值 ASIN(x) 返回x的反正弦值，即获取正弦为x的值。如果x的值不在-1到1之间，则返回NULL COS(x) 返回x的余弦值，其中，参数x为弧度值 ACOS(x) 返回x的反余弦值，即获取余弦为x的值。如果x的值不在-1到1之间，则返回NULL TAN(x) 返回x的正切值，其中，参数x为弧度值 ATAN(x) 返回x的反正切值，即返回正切值为x的值 ATAN2(m,n) 返回两个参数的反正切值 COT(x) 返回x的余切值，其中，X为弧度值 ATAN2(M,N)函数返回两个参数的反正切值。
与ATAN(X)函数相比，ATAN2(M,N)需要两个参数，例如有两个点point(x1,y1)和point(x2,y2)，使用ATAN(X)函数计算反正切值为ATAN((y2-y1)/(x2-x1))，使用ATAN2(M,N)计 算反正切值则为ATAN2(y2-y1,x2-x1)。
由使用方式可以看出，当x2-x1等于0时，ATAN(X)函数会报错，而 ATAN2(M,N)函数则仍然可以计算。
4）指数与对数 函数 用法 POW(x,y)，POWER(X,Y) 返回x的y次方 EXP(X) 返回e的X次方，其中e是一个常数，2.718281828459045 LN(X)，LOG(X) 返回以e为底的X的对数，当X &lt;= 0 时，返回的结果为NULL LOG10(X) 返回以10为底的X的对数，当X &lt;= 0 时，返回的结果为NULL LOG2(X) 返回以2为底的X的对数，当X &lt;= 0 时，返回NULL 5）进制间的转换 函数 用法 BIN(x) 返回x的二进制编码 HEX(x) 返回x的十六进制编码 OCT(x) 返回x的八进制编码 CONV(x,f1,f2) 返回f1进制数变成f2进制数 2、字符串函数 3、日期和时间函数 4、流程控制函数 5、加密与解密函数 6、MySQL信息函数 7、其他函数 看笔记吧
四、数据类型 1、SET类型 SET表示一个字符串对象，可以包含0个或多个成员，但成员个数的上限为 64 。设置字段值时，可以取 取值范围内的 0 个或多个值。
当SET类型包含的成员个数不同时，其所占用的存储空间也是不同的，具体如下:
SET类型在存储数据时成员个数越多，其占用的存储空间越大。注意:SET类型在选取成员时，可以一次 选择多个成员，这一点与ENUM类型不同。
举例: 创建表:
CREATE TABLE test_set( s SET ('A', 'B', 'C') ); 向表中插入数据:
INSERTINTOtest_set(s)VALUES('A'),('A,B');#插入重复的SET类型成员时，MySQL会自动删除重复的成员INSERTINTOtest_set(s)VALUES('A,B,C,A');#向SET类型的字段插入SET成员中不存在的值时，MySQL会抛出错误。INSERTINTOtest_set(s)VALUES('A,B,C,D');SELECT*FROMtest_set;举例:
CREATETABLEtemp_mul(genderENUM('男','女'),hobbySET('吃饭','睡觉','打豆豆','写代码'));INSERTINTOtemp_mulVALUES('男','睡觉,打豆豆');#成功#Datatruncatedforcolumn'gender'atrow1INSERTINTOtemp_mulVALUES('男,女','睡觉,写代码');#失败#Datatruncatedforcolumn'gender'atrow1INSERTINTOtemp_mulVALUES('妖','睡觉,写代码');#失败INSERTINTOtemp_mulVALUES('男','睡觉,写代码,吃饭');#成功</content></entry><entry><title>MySql基础入门安装教程</title><url>https://zhang4014439175.github.io/post/mysql%E5%AE%89%E8%A3%85/</url><categories><category>MySql</category></categories><tags><tag>MySql</tag><tag>Sql</tag></tags><content type="html">  MySQL是一种关系型数据库管理系统，关系数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。MySQL所使用的 SQL 语言是用于访问数据库的最常用标准化语言。MySQL 软件采用了双授权政策，分为社区版和商业版，由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，一般中小型网站的开发都选择 MySQL 作为网站数据库。
一、MySQL数据库的介绍和安装 1.MySQL数据库介绍 小型的数据库 开源免费(6版本之前免费) 所属于Oracle公司 2.MySQL数据库安装 通过secureCRT工具连接Linux系统
上传 mysql 的安装包
alt + p -------> put d:/setup/mysql-5.7.27-1.el7.x86_64.rpm-bundle.tar 解压 mysql 的安装包 mkdir mysql tar -xvf mysql-5.7.27-1.el7.x86_64.rpm-bundle.tar -C mysql/ 安装客户端 cd mysql/ rpm -ivh mysql-community-client-5.7.27-1.el7.x86_64.rpm --force --nodeps 安装服务端 rpm -ivh mysql-community-server-5.7.27-1.el7.x86_64.rpm --force --nodeps 修改mysql默认字符集 vi /etc/my.cnf 添加如下内容： [mysqld] character-set-server=utf8 collation-server=utf8_general_ci -- 需要在最下方填写 [client] default-character-set=utf8 启动mysql服务 service mysqld start 登录mysql mysql -u root -p 敲回车，输入密码 初始密码查看：cat /var/log/mysqld.log 在root@localhost: 后面的就是初始密码 修改mysql登录密码 set global validate_password_policy=0; set global validate_password_length=1; set password=password('密码'); 授予远程连接权限 //授权 grant all privileges on *.* to 'root' @'%' identified by '密码'; //刷新 flush privileges; 关闭Linux系统防火墙 systemctl stop firewalld.service 3.MySQL数据库登录 sqlyog工具登录mysql</content></entry><entry><title>MySql基础（一）</title><url>https://zhang4014439175.github.io/post/mysql%E5%9F%BA%E7%A1%8001/</url><categories><category>MySql</category></categories><tags><tag>MySql</tag><tag>Sql</tag></tags><content type="html">  MySQL是一种关系型数据库管理系统，关系数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。MySQL所使用的 SQL 语言是用于访问数据库的最常用标准化语言。MySQL 软件采用了双授权政策，分为社区版和商业版，由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，一般中小型网站的开发都选择 MySQL 作为网站数据库。
一、数据库的基本概念 1.为什么要学数据库？ 之前我们如果想将一些数据实现永久化存储，可以怎么做呢？没错。使用IO流的技术将数据保存到本地文件中 但是接下来我有这样一个需求：将下面的user.txt文件中的王五年龄修改为35 张三 23 男 李四 24 男 王五 25 女 赵六 26 女 周七 27 男 我们要如何实现呢？ 可以采用字符缓冲流，将每一行数据读取出来，封装为User对象。将多个User对象保存到集合中 然后遍历集合，将王五对象的年龄修改为35,再重新将集合中的对象信息写回到文件中 这一套操作太麻烦了，而现在我们有一种更加方便的方式来完成这个需求了，这种方式就是数据库！ 2.什么是数据库？ 用于存储和管理数据的仓库 英文单词为：DataBase，简称DB 3.数据库的好处？ 可以持久化存储数据 方便存储和管理数据 使用了统一的方式操作数据库 &ndash; SQL 4.常见的数据库有哪些？ 二、SQL语句 1.数据库、数据表、数据的关系介绍 数据库 用于存储和管理数据的仓库 一个库中可以包含多个数据表 数据表 数据库最重要的组成部分之一 它由纵向的列和横向的行组成(类似excel表格) 可以指定列名、数据类型、约束等 一个表中可以存储多条数据 数据 想要永久化存储的数据 2.SQL介绍 什么是SQL
Structured Query Language：结构化查询语言 其实就是定义了操作所有关系型数据库的规则。每一种数据库操作的方式可能会存在一些不一样的地方，我们称为“方言”。 SQL通用语法
SQL 语句可以单行或多行书写，以分号结尾。 可使用空格和缩进来增强语句的可读性。 MySQL 数据库的 SQL 语句不区分大小写，关键字建议使用大写。 数据库的注释： 单行注释：&ndash; 注释内容 #注释内容(mysql特有) 多行注释：/* 注释内容 */ SQL分类
DDL(Data Definition Language)数据定义语言 用来定义数据库对象：数据库，表，列等。关键字：create, drop,alter 等 DML(Data Manipulation Language)数据操作语言 用来对数据库中表的数据进行增删改。关键字：insert, delete, update 等 DQL(Data Query Language)数据查询语言 用来查询数据库中表的记录(数据)。关键字：select, where 等 DCL(Data Control Language)数据控制语言(了解) 用来定义数据库的访问权限和安全级别，及创建用户。关键字：GRANT， REVOKE 等 3.DDL-操作数据库 R(Retrieve)：查询
查询所有数据库 -- 查询所有数据库 SHOWDATABASES; 查询某个数据库的创建语句 -- 标准语法 SHOWCREATEDATABASE数据库名称;-- 查看mysql数据库的创建格式 SHOWCREATEDATABASEmysql; C(Create)：创建
创建数据库 -- 标准语法 CREATEDATABASE数据库名称;-- 创建db1数据库 CREATEDATABASEdb1;-- 创建一个已存在的数据库会报错 -- 错误代码：1007 Can't create database 'db1'; database exists CREATEDATABASEdb1; 创建数据库(判断，如果不存在则创建) -- 标准语法 CREATEDATABASEIFNOTEXISTS数据库名称;-- 创建数据库db2(判断，如果不存在则创建) CREATEDATABASEIFNOTEXISTSdb2; 创建数据库、并指定字符集 -- 标准语法 CREATEDATABASE数据库名称CHARACTERSET字符集名称;-- 创建数据库db3、并指定字符集utf8 CREATEDATABASEdb3CHARACTERSETutf8;-- 查看db3数据库的字符集 SHOWCREATEDATABASEdb3; 练习：创建db4数据库、如果不存在则创建，指定字符集为gbk -- 创建db4数据库、如果不存在则创建，指定字符集为gbk CREATEDATABASEIFNOTEXISTSdb4CHARACTERSETgbk;-- 查看db4数据库的字符集 SHOWCREATEDATABASEdb4; U(Update)：修改
修改数据库的字符集 -- 标准语法 ALTERDATABASE数据库名称CHARACTERSET字符集名称;-- 修改数据库db4的字符集为utf8 ALTERDATABASEdb4CHARACTERSETutf8;-- 查看db4数据库的字符集 SHOWCREATEDATABASEdb4; D(Delete)：删除
删除数据库 -- 标准语法 DROPDATABASE数据库名称;-- 删除db1数据库 DROPDATABASEdb1;-- 删除一个不存在的数据库会报错 -- 错误代码：1008 Can't drop database 'db1'; database doesn't exist DROPDATABASEdb1; 删除数据库(判断，如果存在则删除) -- 标准语法 DROPDATABASEIFEXISTS数据库名称;-- 删除数据库db2，如果存在 DROPDATABASEIFEXISTSdb2; 使用数据库
查询当前正在使用的数据库名称 -- 查询当前正在使用的数据库 SELECTDATABASE(); 使用数据库 -- 标准语法 USE数据库名称；-- 使用db4数据库 USEdb4; 4.DDL-操作数据表 R(Retrieve)：查询
查询数据库中所有的数据表 -- 使用mysql数据库 USEmysql;-- 查询库中所有的表 SHOWTABLES; 查询表结构 -- 标准语法 DESC表名;-- 查询user表结构 DESCuser; 查询表字符集 -- 标准语法 SHOWTABLESTATUSFROM库名LIKE'表名';-- 查看mysql数据库中user表字符集 SHOWTABLESTATUSFROMmysqlLIKE'user'; C(Create)：创建
创建数据表
标准语法 CREATETABLE表名(列名1数据类型1,列名2数据类型2,....列名n数据类型n);-- 注意：最后一列，不需要加逗号 数据类型 1.int：整数类型*ageint2.double:小数类型*scoredouble(5,2)*pricedouble3.date:日期，只包含年月日yyyy-MM-dd4.datetime:日期，包含年月日时分秒yyyy-MM-ddHH:mm:ss5.timestamp:时间戳类型包含年月日时分秒yyyy-MM-ddHH:mm:ss*如果将来不给这个字段赋值，或赋值为null，则默认使用当前的系统时间，来自动赋值6.varchar：字符串*namevarchar(20):姓名最大20个字符*zhangsan8个字符张三2个字符 创建数据表 -- 使用db3数据库 USEdb3;-- 创建一个product商品表 CREATETABLEproduct(idINT,-- 商品编号 NAMEVARCHAR(30),-- 商品名称 priceDOUBLE,-- 商品价格 stockINT,-- 商品库存 insert_timeDATE-- 上架时间 ); 复制表 -- 标准语法 CREATETABLE表名LIKE被复制的表名;-- 复制product表到product2表 CREATETABLEproduct2LIKEproduct; U(Update)：修改
修改表名 -- 标准语法 ALTERTABLE表名RENAMETO新的表名;-- 修改product2表名为product3 ALTERTABLEproduct2RENAMETOproduct3; 修改表的字符集 -- 标准语法 ALTERTABLE表名CHARACTERSET字符集名称;-- 查看db3数据库中product3数据表字符集 SHOWTABLESTATUSFROMdb3LIKE'product3';-- 修改product3数据表字符集为gbk ALTERTABLEproduct3CHARACTERSETgbk;-- 查看db3数据库中product3数据表字符集 SHOWTABLESTATUSFROMdb3LIKE'product3'; 添加一列 -- 标准语法 ALTERTABLE表名ADD列名数据类型;-- 给product3表添加一列color ALTERTABLEproduct3ADDcolorVARCHAR(10); 修改列名称和数据类型 -- 修改数据类型 标准语法 ALTERTABLE表名MODIFY列名新数据类型;-- 将color数据类型修改为int ALTERTABLEproduct3MODIFYcolorINT;-- 查看product3表详细信息 DESCproduct3;-- 修改列名和数据类型 标准语法 ALTERTABLE表名CHANGE列名新列名新数据类型;-- 将color修改为address,数据类型为varchar ALTERTABLEproduct3CHANGEcoloraddressVARCHAR(30);-- 查看product3表详细信息 DESCproduct3; 删除列 -- 标准语法 ALTERTABLE表名DROP列名;-- 删除address列 ALTERTABLEproduct3DROPaddress; D(Delete)：删除
删除数据表 -- 标准语法 DROPTABLE表名;-- 删除product3表 DROPTABLEproduct3;-- 删除不存在的表，会报错 -- 错误代码：1051 Unknown table 'product3' DROPTABLEproduct3; 删除数据表(判断，如果存在则删除) -- 标准语法 DROPTABLEIFEXISTS表名;-- 删除product3表，如果存在则删除 DROPTABLEIFEXISTSproduct3; 5.DML-INSERT语句 新增表数据语法
新增格式1：给指定列添加数据 -- 标准语法 INSERTINTO表名(列名1,列名2,...)VALUES(值1,值2,...);-- 向product表添加一条数据 INSERTINTOproduct(id,NAME,price,stock,insert_time)VALUES(1,'手机',1999,22,'2099-09-09');-- 向product表添加指定列数据 INSERTINTOproduct(id,NAME,price)VALUES(2,'电脑',4999);-- 查看表中所有数据 SELECT*FROMproduct; 新增格式2：默认给全部列添加数据 -- 标准语法 INSERTINTO表名VALUES(值1,值2,值3,...);-- 默认给全部列添加数据 INSERTINTOproductVALUES(3,'电视',2999,18,'2099-06-06');-- 查看表中所有数据 SELECT*FROMproduct; 新增格式3：批量添加数据 -- 默认添加所有列数据 标准语法 INSERTINTO表名VALUES(值1,值2,值3,...),(值1,值2,值3,...),(值1,值2,值3,...);-- 批量添加数据 INSERTINTOproductVALUES(4,'冰箱',999,26,'2099-08-08'),(5,'洗衣机',1999,32,'2099-05-10');-- 查看表中所有数据 SELECT*FROMproduct;-- 给指定列添加数据 标准语法 INSERTINTO表名(列名1,列名2,...)VALUES(值1,值2,...),(值1,值2,...),(值1,值2,...);-- 批量添加指定列数据 INSERTINTOproduct(id,NAME,price)VALUES(6,'微波炉',499),(7,'电磁炉',899);-- 查看表中所有数据 SELECT*FROMproduct; 注意事项
列名和值的数量以及数据类型要对应 除了数字类型，其他数据类型的数据都需要加引号(单引双引都可以，推荐单引) 6.DML-UPDATE语句 修改表数据语法 -- 标准语法 UPDATE表名SET列名1=值1,列名2=值2,...[where条件];-- 修改手机的价格为3500 UPDATEproductSETprice=3500WHERENAME='手机';-- 查看所有数据 SELECT*FROMproduct;-- 修改电视的价格为1800、库存为36 UPDATEproductSETprice=1800,stock=36WHERENAME='电视';-- 修改电磁炉的库存为10 UPDATEproductSETstock=10WHEREid=7; 注意事项 修改语句中必须加条件 如果不加条件，则将所有数据都修改 7.DML-DELETE语句 删除表数据语法 -- 标准语法 DELETEFROM表名[WHERE条件];-- 删除product表中的微波炉信息 DELETEFROMproductWHERENAME='微波炉';-- 删除product表中库存为10的商品信息 DELETEFROMproductWHEREstock=10;-- 查看所有商品信息 SELECT*FROMproduct; 注意事项 删除语句中必须加条件 如果不加条件，则将所有数据删除 8.DQL-单表查询 数据准备(直接复制执行即可) -- 创建db1数据库 CREATEDATABASEdb1;-- 使用db1数据库 USEdb1;-- 创建数据表 CREATETABLEproduct(idINT,-- 商品编号 NAMEVARCHAR(20),-- 商品名称 priceDOUBLE,-- 商品价格 brandVARCHAR(10),-- 商品品牌 stockINT,-- 商品库存 insert_timeDATE-- 添加时间 );-- 添加数据 INSERTINTOproductVALUES(1,'华为手机',3999,'华为',23,'2088-03-10'),(2,'小米手机',2999,'小米',30,'2088-05-15'),(3,'苹果手机',5999,'苹果',18,'2088-08-20'),(4,'华为电脑',6999,'华为',14,'2088-06-16'),(5,'小米电脑',4999,'小米',26,'2088-07-08'),(6,'苹果电脑',8999,'苹果',15,'2088-10-25'),(7,'联想电脑',7999,'联想',NULL,'2088-11-11'); 查询语法 select字段列表from表名列表where条件列表groupby分组字段having分组之后的条件orderby排序limit分页限定 查询全部 -- 标准语法 SELECT*FROM表名;-- 查询product表所有数据 SELECT*FROMproduct; 查询部分
多个字段查询 -- 标准语法 SELECT列名1,列名2,...FROM表名;-- 查询名称、价格、品牌 SELECTNAME,price,brandFROMproduct; 去除重复查询 注意：只有全部重复的才可以去除 -- 标准语法 SELECTDISTINCT列名1,列名2,...FROM表名;-- 查询品牌 SELECTbrandFROMproduct;-- 查询品牌，去除重复 SELECTDISTINCTbrandFROMproduct; 计算列的值(四则运算) -- 标准语法 SELECT列名1运算符(+-*/)列名2FROM表名;/* 计算列的值 标准语法： SELECT 列名1 运算符(+ - * /) 列名2 FROM 表名; 如果某一列为null，可以进行替换 ifnull(表达式1,表达式2) 表达式1：想替换的列 表达式2：想替换的值 */-- 查询商品名称和库存，库存数量在原有基础上加10 SELECTNAME,stock+10FROMproduct;-- 查询商品名称和库存，库存数量在原有基础上加10。进行null值判断 SELECTNAME,IFNULL(stock,0)+10FROMproduct; 起别名 -- 标准语法 SELECT列名1,列名2,...AS别名FROM表名;-- 查询商品名称和库存，库存数量在原有基础上加10。进行null值判断。起别名为getSum SELECTNAME,IFNULL(stock,0)+10ASgetsumFROMproduct;SELECTNAME,IFNULL(stock,0)+10getsumFROMproduct; 条件查询
条件分类 符号 功能 > 大于 &lt; 小于 >= 大于等于 &lt;= 小于等于 = 等于 &lt;> 或 != 不等于 BETWEEN &hellip; AND &hellip; 在某个范围之内(都包含) IN(&hellip;) 多选一 LIKE 占位符 模糊查询 _单个任意字符 %多个任意字符 IS NULL 是NULL IS NOT NULL 不是NULL AND 或 &amp;&amp; 并且 OR 或 || 或者 NOT 或 ! 非，不是 条件查询语法 -- 标准语法 SELECT列名FROM表名WHERE条件;-- 查询库存大于20的商品信息 SELECT*FROMproductWHEREstock>20;-- 查询品牌为华为的商品信息 SELECT*FROMproductWHEREbrand='华为';-- 查询金额在4000 ~ 6000之间的商品信息 SELECT*FROMproductWHEREprice>=4000ANDprice&lt;=6000;SELECT*FROMproductWHEREpriceBETWEEN4000AND6000;-- 查询库存为14、30、23的商品信息 SELECT*FROMproductWHEREstock=14ORstock=30ORstock=23;SELECT*FROMproductWHEREstockIN(14,30,23);-- 查询库存为null的商品信息 SELECT*FROMproductWHEREstockISNULL;-- 查询库存不为null的商品信息 SELECT*FROMproductWHEREstockISNOTNULL;-- 查询名称以小米为开头的商品信息 SELECT*FROMproductWHERENAMELIKE'小米%';-- 查询名称第二个字是为的商品信息 SELECT*FROMproductWHERENAMELIKE'_为%';-- 查询名称为四个字符的商品信息 SELECT*FROMproductWHERENAMELIKE'____';-- 查询名称中包含电脑的商品信息 SELECT*FROMproductWHERENAMELIKE'%电脑%'; 聚合函数
将一列数据作为一个整体，进行纵向的计算 聚合函数分类 函数名 功能 count(列名) 统计数量(一般选用不为null的列) max(列名) 最大值 min(列名) 最小值 sum(列名) 求和 avg(列名) 平均值 聚合函数语法 -- 标准语法 SELECT函数名(列名)FROM表名[WHERE条件];-- 计算product表中总记录条数 SELECTCOUNT(*)FROMproduct;-- 获取最高价格 SELECTMAX(price)FROMproduct;-- 获取最高价格的商品名称 SELECTNAME,priceFROMproductWHEREprice=(SELECTMAX(price)FROMproduct);-- 获取最低库存 SELECTMIN(stock)FROMproduct;-- 获取最低库存的商品名称 SELECTNAME,stockFROMproductWHEREstock=(SELECTMIN(stock)FROMproduct);-- 获取总库存数量 SELECTSUM(stock)FROMproduct;-- 获取品牌为苹果的总库存数量 SELECTSUM(stock)FROMproductWHEREbrand='苹果';-- 获取品牌为小米的平均商品价格 SELECTAVG(price)FROMproductWHEREbrand='小米'; 排序查询
排序分类 注意：多个排序条件，当前边的条件值一样时，才会判断第二条件 关键词 功能 ORDER BY 列名1 排序方式1,列名2 排序方式2 对指定列排序，ASC升序(默认的) DESC降序 排序语法 -- 标准语法 SELECT列名FROM表名[WHERE条件]ORDERBY列名1排序方式1,列名2排序方式2;-- 按照库存升序排序 SELECT*FROMproductORDERBYstockASC;-- 查询名称中包含手机的商品信息。按照金额降序排序 SELECT*FROMproductWHERENAMELIKE'%手机%'ORDERBYpriceDESC;-- 按照金额升序排序，如果金额相同，按照库存降序排列 SELECT*FROMproductORDERBYpriceASC,stockDESC; 分组查询
-- 标准语法 SELECT列名FROM表名[WHERE条件]GROUPBY分组列名[HAVING分组后条件过滤][ORDERBY排序列名排序方式];-- 按照品牌分组，获取每组商品的总金额 SELECTbrand,SUM(price)FROMproductGROUPBYbrand;-- 对金额大于4000元的商品，按照品牌分组,获取每组商品的总金额 SELECTbrand,SUM(price)FROMproductWHEREprice>4000GROUPBYbrand;-- 对金额大于4000元的商品，按照品牌分组，获取每组商品的总金额，只显示总金额大于7000元的 SELECTbrand,SUM(price)ASgetSumFROMproductWHEREprice>4000GROUPBYbrandHAVINGgetSum>7000;-- 对金额大于4000元的商品，按照品牌分组，获取每组商品的总金额，只显示总金额大于7000元的、并按照总金额的降序排列 SELECTbrand,SUM(price)ASgetSumFROMproductWHEREprice>4000GROUPBYbrandHAVINGgetSum>7000ORDERBYgetSumDESC; 分页查询 -- 标准语法 SELECT列名FROM表名[WHERE条件]GROUPBY分组列名[HAVING分组后条件过滤][ORDERBY排序列名排序方式]LIMIT开始索引,查询条数;-- 公式：开始索引 = (当前页码-1) * 每页显示的条数 -- 每页显示2条数据 SELECT*FROMproductLIMIT0,2;-- 第一页 开始索引=(1-1) * 2 SELECT*FROMproductLIMIT2,2;-- 第二页 开始索引=(2-1) * 2 SELECT*FROMproductLIMIT4,2;-- 第三页 开始索引=(3-1) * 2 SELECT*FROMproductLIMIT6,2;-- 第四页 开始索引=(4-1) * 2 分页查询图解 三、约束 1.约束的概念和分类 约束的概念 对表中的数据进行限定，保证数据的正确性、有效性、完整性！ 约束的分类 约束 说明 PRIMARY KEY 主键约束 PRIMARY KEY AUTO_INCREMENT 主键、自动增长 UNIQUE 唯一约束 NOT NULL 非空约束 FOREIGN KEY 外键约束 FOREIGN KEY ON UPDATE CASCADE 外键级联更新 FOREIGN KEY ON DELETE CASCADE 外键级联删除 2.主键约束 主键约束特点 主键约束包含：非空和唯一两个功能 一张表只能有一个列作为主键 主键一般用于表中数据的唯一标识 建表时添加主键约束 -- 标准语法 CREATETABLE表名(列名数据类型PRIMARYKEY,列名数据类型,...);-- 创建student表 CREATETABLEstudent(idINTPRIMARYKEY-- 给id添加主键约束 );-- 添加数据 INSERTINTOstudentVALUES(1),(2);-- 主键默认唯一，添加重复数据，会报错 INSERTINTOstudentVALUES(2);-- 主键默认非空，不能添加null的数据 INSERTINTOstudentVALUES(NULL);-- 查询student表 SELECT*FROMstudent;-- 查询student表详细 DESCstudent; 删除主键 -- 标准语法 ALTERTABLE表名DROPPRIMARYKEY;-- 删除主键 ALTERTABLEstudentDROPPRIMARYKEY; 建表后单独添加主键 -- 标准语法 ALTERTABLE表名MODIFY列名数据类型PRIMARYKEY;-- 添加主键 ALTERTABLEstudentMODIFYidINTPRIMARYKEY;3.主键自动增长约束 建表时添加主键自增约束 -- 标准语法 CREATETABLE表名(列名数据类型PRIMARYKEYAUTO_INCREMENT,列名数据类型,...);-- 创建student2表 CREATETABLEstudent2(idINTPRIMARYKEYAUTO_INCREMENT-- 给id添加主键自增约束 );-- 添加数据 INSERTINTOstudent2VALUES(1),(2);-- 添加null值，会自动增长 INSERTINTOstudent2VALUES(NULL),(NULL);-- 查询student2表 SELECT*FROMstudent2;-- student2表详细 DESCstudent2; 删除自动增长 -- 标准语法 ALTERTABLE表名MODIFY列名数据类型;-- 删除自动增长 ALTERTABLEstudent2MODIFYidINT; 建表后单独添加自动增长 -- 标准语法 ALTERTABLE表名MODIFY列名数据类型AUTO_INCREMENT;-- 添加自动增长 ALTERTABLEstudent2MODIFYidINTAUTO_INCREMENT;4.唯一约束 建表时添加唯一约束 -- 标准语法 CREATETABLE表名(列名数据类型UNIQUE,列名数据类型,...);-- 创建student3表 CREATETABLEstudent3(idINTPRIMARYKEYAUTO_INCREMENT,telVARCHAR(20)UNIQUE-- 给tel列添加唯一约束 );-- 添加数据 INSERTINTOstudent3VALUES(NULL,'18888888888'),(NULL,'18666666666');-- 添加重复数据，会报错 INSERTINTOstudent3VALUES(NULL,'18666666666');-- 查询student3数据表 SELECT*FROMstudent3;-- student3表详细 DESCstudent3; 删除唯一约束 -- 标准语法 ALTERTABLE表名DROPINDEX列名;-- 删除唯一约束 ALTERTABLEstudent3DROPINDEXtel; 建表后单独添加唯一约束 -- 标准语法 ALTERTABLE表名MODIFY列名数据类型UNIQUE;-- 添加唯一约束 ALTERTABLEstudent3MODIFYtelVARCHAR(20)UNIQUE;5.非空约束 建表时添加非空约束 -- 标准语法 CREATETABLE表名(列名数据类型NOTNULL,列名数据类型,...);-- 创建student4表 CREATETABLEstudent4(idINTPRIMARYKEYAUTO_INCREMENT,NAMEVARCHAR(20)NOTNULL-- 给name添加非空约束 );-- 添加数据 INSERTINTOstudent4VALUES(NULL,'张三'),(NULL,'李四');-- 添加null值，会报错 INSERTINTOstudent4VALUES(NULL,NULL); 删除非空约束 -- 标准语法 ALTERTABLE表名MODIFY列名数据类型;-- 删除非空约束 ALTERTABLEstudent4MODIFYNAMEVARCHAR(20); 建表后单独添加非空约束
-- 标准语法 ALTERTABLE表名MODIFY列名数据类型NOTNULL;-- 添加非空约束 ALTERTABLEstudent4MODIFYNAMEVARCHAR(20)NOTNULL;</content></entry><entry><title>Java框架-MybatisPlus</title><url>https://zhang4014439175.github.io/post/mybatis-plus/</url><categories><category>Java框架</category></categories><tags><tag>Java</tag><tag>mybatis</tag><tag>框架</tag></tags><content type="html"> 一、条件构造 子查询
queryWrapper.inSql(&ldquo;id&rdquo;, &ldquo;select id from t_user where id &lt;= 3&rdquo;);
组装参数条件
queryWrapper .like(StringUtils.isNotBlank(username), "username", "a") .ge(ageBegin != null, "age", ageBegin) .le(ageEnd != null, "age", ageEnd); 二、分页 1、添加配置类 @Configuration @MapperScan("com.atguigu.mybatisplus.mapper") //可以将主类中的注解移到此处 public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); return interceptor; } } 2、测试 @Test public void testPage(){ //limit (当前也页码 - 1) * 每页条数 //设置分页参数 current当前页码， pageSize每页大小 Page&lt;User> page = new Page&lt;>(1, 5); userMapper.selectPage(page, null); //获取分页数据 List&lt;User> list = page.getRecords(); list.forEach(System.out::println); System.out.println("当前页:"+page.getCurrent()); System.out.println("每页显示的条数:"+page.getSize()); System.out.println("总记录数:"+page.getTotal()); System.out.println("总页数:"+page.getPages()); System.out.println("是否有上一页:"+page.hasPrevious()); System.out.println("是否有下一页:"+page.hasNext()); } 3、自定义分页 /** * 根据年龄查询用户列表，分页显示 * @param page 分页对象,xml中可以从里面进行取值,传递参数 Page 即自动分页,必须放在第一位 * @param age 年龄 * @return */ IPage&lt;User> selectPageVo(@Param("page") Page&lt;User> page, @Param("age") Integer age); 三、乐观锁 1、乐观锁配置 @Configuration @MapperScan("com.atguigu.mybatisplus.mapper") //可以将主类中的注解移到此处 public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); //添加乐观锁插件 interceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor()); return interceptor; } } 2、添加@version注解 @Data public class Product { private Long id; private String name; private Integer price; @Version private Integer version; } 四、通用枚举 1、创建通用枚举 public enum SexEnum { MALE(1, "男"), FEMALE(2, "女"); @EnumValue private Integer sex; private String sexName; SexEnum(Integer sex, String sexName) { this.sex = sex; this.sexName = sexName; } } 2、配置扫描通用枚举 mybatis-plus:configuration:# 配置MyBatis日志log-impl:org.apache.ibatis.logging.stdout.StdOutImplglobal-config:db-config:# 配置MyBatis-Plus操作表的默认前缀 table-prefix:t_# 配置MyBatis-Plus的主键策略 id-type:auto# 配置扫描通用枚举type-enums-package:com.atguigu.mybatisplus.enums五、代码生成器 1、引入依赖 &lt;dependency> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>mybatis-plus-generator&lt;/artifactId> &lt;version>3.5.1&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.freemarker&lt;/groupId> &lt;artifactId>freemarker&lt;/artifactId> &lt;version>2.3.31&lt;/version> &lt;/dependency> 2、快速生成 public static void main(String[] args) { FastAutoGenerator.create("jdbc:mysql://127.0.0.1:3306/mybatis_plus?characterEncoding=utf-8&amp;userSSL=false", "root", "123456") .globalConfig(builder -> { builder.author("atguigu") // 设置作者 //.enableSwagger() // 开启 swagger 模式 .fileOverride() // 覆盖已生成文件 .outputDir("D://mybatis_plus"); // 指定输出目录 }) .packageConfig(builder -> { builder.parent("com.atguigu") // 设置父包名 .moduleName("mybatisplus") // 设置父包模块名 .pathInfo(Collections.singletonMap(OutputFile.mapperXml, "D://mybatis_plus")); // 设置mapperXml生成路径 }) .strategyConfig(builder -> { builder.addInclude("t_user") // 设置需要生成的表名 .addTablePrefix("t_", "c_"); // 设置过滤表前缀 }) .templateEngine(new FreemarkerTemplateEngine()) // 使用Freemarker 引擎模板，默认的是Velocity引擎模板 .execute(); } 六、多数据源 适用于多种场景:纯粹多库、 读写分离、 一主多从、 混合模式等 目前我们就来模拟一个纯粹多库的一个场景，其他场景类似
场景说明:
我们创建两个库，分别为:mybatis_plus(以前的库不动)与mybatis_plus_1(新建)，将 mybatis_plus库的product表移动到mybatis_plus_1库，这样每个库一张表，通过一个测试用例 分别获取用户数据与商品数据，如果获取到说明多库模拟成功
1、引入依赖 &lt;dependency> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>dynamic-datasource-spring-boot-starter&lt;/artifactId> &lt;version>3.5.0&lt;/version> &lt;/dependency> 2、配置多数据源 spring:# 配置数据源信息 datasource:dynamic:# 设置默认的数据源或者数据源组,默认值即为masterprimary:master# 严格匹配数据源,默认false.true未匹配到指定数据源时抛异常,false使用默认数据源 strict:falsedatasource:master:url:jdbc:mysql://localhost:3306/mybatis_plus?characterEncoding=utf-8&amp;useSSL=falsedriver-class-name:com.mysql.cj.jdbc.Driverusername:rootpassword:123456slave_1:url:jdbc:mysql://localhost:3306/mybatis_plus_1?characterEncoding=utf-8&amp;useSSL=falsedriver-class-name:com.mysql.cj.jdbc.Driverusername:rootpassword:1234563、创建用户service @DS("master") //指定所操作的数据源 @Service public class UserServiceImpl extends ServiceImpl&lt;UserMapper, User> implements UserService { } 七、MyBatisX插件 MyBatis-Plus为我们提供了强大的mapper和service模板，能够大大的提高开发效率
但是在真正开发过程中，MyBatis-Plus并不能为我们解决所有问题，例如一些复杂的SQL，多表 联查，我们就需要自己去编写代码和SQL语句，我们该如何快速的解决这个问题呢，这个时候可 以使用MyBatisX插件
MyBatisX一款基于 IDEA 的快速开发插件，为效率而生。
MyBatisX插件用法:https://baomidou.com/pages/ba5b24/
八、一些配置操作 1、逻辑删除 和 主键自增
mybatis-plus:mapper-locations:classpath*:/mapper/**/*.xmlglobal-config:db-config:id-type:autologic-delete-value:1logic-not-delete-value:0mybatis-plus:configuration:log-impl:org.apache.ibatis.logging.stdout.StdOutImplglobal-config:db-config:table-prefix:id-type:auto</content></entry><entry><title>Java框架-MybatisPlus</title><url>https://zhang4014439175.github.io/post/mybatis%E4%B8%80/</url><categories><category>Java框架</category></categories><tags><tag>Java</tag><tag>mybatis</tag><tag>框架</tag></tags><content type="html"> 一、特性 MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架 2) MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集
MyBatis可以使用简单的XML或注解用于配置和原始映射，将接口和Java的POJO(Plain Old Java Objects，普通的Java对象)映射成数据库中的记录
MyBatis 是一个 半自动的ORM(Object Relation Mapping)框架
二、实战 1、核心配置文件 pom文件
&lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis&lt;/artifactId> &lt;version>3.5.9&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>junit&lt;/groupId> &lt;artifactId>junit&lt;/artifactId> &lt;version>4.13.2&lt;/version> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>8.0.28&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>log4j&lt;/groupId> &lt;artifactId>log4j&lt;/artifactId> &lt;version>1.2.17&lt;/version> &lt;/dependency> &lt;?xml version="1.0" encoding="UTF-8" ?> &lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"> &lt;configuration> &lt;!--设置连接数据库的环境--> &lt;environments default="development"> &lt;environment id="development"> &lt;transactionManager type="JDBC"/> &lt;dataSource type="POOLED"> &lt;property name="driver" value="com.mysql.jdbc.Driver"/> &lt;property name="url" value="jdbc:mysql://59.110.161.137:3306/lizi"/> &lt;property name="username" value="root"/> &lt;property name="password" value="tysf2019."/> &lt;/dataSource> &lt;/environment> &lt;/environments> &lt;!--引入映射文件--> &lt;mappers> &lt;mapper resource="mappers/UserMapper.xml"/> &lt;/mappers> &lt;/configuration> 1、mybatis-config.xml核心配置文件
&lt;configuration> &lt;environment> &lt;/environment> //引入映射文件 &lt;mappers> &lt;mapper resource="org/mybatis/example/BlogMapper.xml"/> &lt;/mappers> &lt;/configuration> 2、创建mapper接口
mybatis中的mapper接口相当于以前的dao，但是区别在于，mapper仅仅是接口，我们不需要提供实现类
public interface UserMapper { int insertUser(); } 2、mapper配置文件 &lt;?xml version="1.0" encoding="UTF-8" ?> &lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"> &lt;mapper namespace="com.lizi.mybatis.mapper.UserMapper"> &lt;!--int insertUser();--> &lt;insert id="insertUser"> insert into user values(null,'张三','123',23,'女') &lt;/insert> &lt;/mapper> 3、两个一致 1）映射文件的namespace要和mapper接口的全类名保持一致。
2）映射文件中SQL语句的id要和mapper接口中的方法保持一致
4、测试 public class MyBatisTest { @Test public void testMybatis() throws IOException { //加载核心配置文件 InputStream is = Resources.getResourceAsStream("mybatis-config.xml"); SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); //true设置自动提交 SqlSession sqlSession = sqlSessionFactory.openSession(); UserMapper userMapper = sqlSession.getMapper(UserMapper.class); userMapper.insertUser(); sqlSession.commit(); } } //读取MyBatis的核心配置文件 InputStream is = Resources.getResourceAsStream("mybatis-config.xml"); //创建SqlSessionFactoryBuilder对象 SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); //通过核心配置文件所对应的字节输入流创建工厂类SqlSessionFactory，生产SqlSession对象 SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); //创建SqlSession对象，此时通过SqlSession对象所操作的sql都必须手动提交或回滚事务 //SqlSession sqlSession = sqlSessionFactory.openSession(); //创建SqlSession对象，此时通过SqlSession对象所操作的sql都会自动提交 SqlSession sqlSession = sqlSessionFactory.openSession(true); //通过代理模式创建UserMapper接口的代理实现类对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //调用UserMapper接口中的方法，就可以根据UserMapper的全类名匹配元素文件，通过调用的方法名匹配 映射文件中的SQL标签，并执行标签中的SQL语句 int result = userMapper.insertUser(); //sqlSession.commit(); 5、log4j配置 &lt;?xml version="1.0" encoding="UTF-8" ?> &lt;!DOCTYPE log4j:configuration SYSTEM "log4j.dtd"> &lt;log4j:configuration xmlns:log4j="http://jakarta.apache.org/log4j/"> &lt;appender name="STDOUT" class="org.apache.log4j.ConsoleAppender"> &lt;param name="Encoding" value="UTF-8" /> &lt;layout class="org.apache.log4j.PatternLayout"> &lt;param name="ConversionPattern" value="%-5p %d{MM-dd HH:mm:ss,SSS} %m (%F:%L) \n" /> &lt;/layout> &lt;/appender> &lt;logger name="java.sql"> &lt;level value="debug" /> &lt;/logger> &lt;logger name="org.apache.ibatis"> &lt;level value="info" /> &lt;/logger> &lt;root> &lt;level value="debug" /> &lt;appender-ref ref="STDOUT" /> &lt;/root> &lt;/log4j:configuration> 日志的级别
FATAL(致命) > ERROR(错误) > WARN(警告) > INFO(信息) > DEBUG(调试) 从左到右打印的内容越来越详细
6、映射配置 resultType 默认映射配置
resultMap 自定义映射配置
三、配置文件详解 
&lt;?xml version="1.0" encoding="UTF-8" ?> &lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"> &lt;configuration> &lt;!--设置连接数据库的环境--> &lt;environments default="development"> &lt;environment id="development"> &lt;!--使用最原始的jdbc来管理事务--> &lt;transactionManager type="JDBC"/> &lt;dataSource type="POOLED"> &lt;property name="driver" value="com.mysql.cj.jdbc.Driver"/> &lt;property name="url" value="jdbc:mysql://59.110.161.137:3306/lizi"/> &lt;property name="username" value="root"/> &lt;property name="password" value="tysf2019."/> &lt;/dataSource> &lt;/environment> &lt;/environments> &lt;!--引入映射文件--> &lt;mappers> &lt;mapper resource="mapper/UserMapper.xml"/> &lt;/mappers> &lt;/configuration> 1、environment environments：配置多个连接数据库的环境
environment：配置某个具体的环境
id： 表示连接数据库环境的唯一标识 transactionManager： 设置事务管理方式 type: 设置事务管理方式， type="JDBC|MANAGED" type="JDBC": 设置当前环境的事务管理都必须手动处理 type="MANAGED": 设置事务被管理，例如spring中的AOP &lt;environment id="development"> &lt;!--使用最原始的jdbc来管理事务--> &lt;transactionManager type="JDBC"/> dataSource:设置数据源 属性: type: 设置数据源的类型，type="POOLED|UNPOOLED|JNDI" type="POOLED": 使用数据库连接池，即会将创建的连接进行缓存，下次使用可以从 缓存中直接获取，不需要重新创建 type="UNPOOLED":不使用数据库连接池，即每次使用连接都需要重新创建 type="JNDI": 调用上下文中的数据源 &lt;dataSource type="POOLED"> &lt;!--设置驱动类的全类名--> &lt;!--设置连接数据库的连接地址--> &lt;!--设置连接数据库的用户名--> &lt;!--设置连接数据库的密码--> &lt;property name="driver" value="com.mysql.cj.jdbc.Driver"/> &lt;property name="url" value="jdbc:mysql://59.110.161.137:3306/lizi"/> &lt;property name="username" value="root"/> &lt;property name="password" value="tysf2019."/> &lt;/dataSource> &lt;/environment> 2、jdbc.properties driver=com.mysql.cj.jdbc.Driver url=jdbc:mysql://59.110.161.137:3306/lizi username=root password=tysf2019. 3、核心配置文件加载顺序 configuration（配置） properties（属性） settings（设置） typeAliases（类型别名） typeHandlers（类型处理器） objectFactory（对象工厂） plugins（插件） environments（环境配置） environment（环境变量） transactionManager（事务管理器） dataSource（数据源） databaseIdProvider（数据库厂商标识） mappers（映射器） 4、typeAlias别名 &lt;typeAliases> &lt;typeAlias type="com.lizi.mybatis.pojo.User" alias="User"/> 默认别名为类名，所以alias可写可不写 &lt;/typeAliases> package
&lt;typeAliases> &lt;typeAlias type="com.lizi.mybatis.pojo.User" alias="User"/> &lt;package name="com.lizi.mybatis.pojo"/> &lt;/typeAliases> 5、mappers &lt;mappers> &lt;mapper resource="mapper/UserMapper.xml"/> &lt;package name="com" &lt;/mappers> 6、SqlSessionUtils import org.apache.ibatis.io.Resources; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import java.io.IOException; import java.io.InputStream; public class SqlSessionUtils { public static SqlSession getSqlSession() { SqlSession sqlSession = null; try { InputStream is = Resources.getResourceAsStream("mybatis-config.xml"); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(is); sqlSession = sqlSessionFactory.openSession(true); }catch (IOException e) { e.printStackTrace(); } return sqlSession; } } 四、MyBatis获取参数值的两种方式(重点) MyBatis获取参数值的两种方式:${}和#{}
${} 的本质就是字符串拼接，
#{} 的本质就是占位符赋值
${}使用字符串拼接的方式拼接sql，若为字符串类型或日期类型的字段进行赋值时，需要手动加单引号;
#{}使用占位符赋值的方式拼接sql，此时为字符串类型或日期类型的字段进行赋值时，可以自动添加单引号
1、单个字面量类型的参数 若mapper接口中的方法参数为单个的字面量类型
此时可以使用${}和#{}以任意的名称获取参数的值，注意${}需要手动加单引号
2、多个字面量类型的参数 若mapper接口中的方法参数为多个时
此时MyBatis会自动将这些参数放在一个map集合中，以arg0,arg1&hellip;为键，以参数为值;以 param1,param2&hellip;为键，以参数为值;
因此只需要通过${}和#{}访问map集合的键就可以获取相对应的 值，注意${}需要手动加单引号
3、map集合类型的参数 若mapper接口中的方法需要的参数为多个时，此时可以手动创建map集合，将这些数据放在map中
只需要通过${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号
4、实体类类型的参数 若mapper接口中的方法参数为实体类对象时 此时可以使用${}和#{}，通过访问实体类对象中的属性名获取属性值，注意${}需要手动加单引号
5、使用@Param标识参数 可以通过@Param注解标识mapper接口中的方法参数
此时，会将这些参数放在map集合中，以@Param注解的value属性值为键，以参数为值;以 param1,param2&hellip;为键，以参数为值;只需要通过${}和#{}访问map集合的键就可以获取相对应的值， 注意${}需要手动加单引号
ParamNameResolver源码 五、SQL查询 1、map的两种方式 //方式一 List&lt;Map&lt;String, String>> getUserMap(); //方式二 @MapKey("user_id") Map&lt;Integer, Object> getUserMap(); 2、模糊查询 模糊查询需要用${}，因为#{}会被替换成？，导致like后面&rsquo;%?%'
&lt;!--List&lt;User> testMohu(@Param("mohu") String mohu);--> &lt;select id="testMohu" resultType="User"> &lt;!-- 方式一 --> select * from t_user where username like '%${mohu}%' &lt;!-- 方式二 --> select * from t_user where username like concat('%',#{mohu},'%') &lt;!-- 方式三 --> select * from t_user where username like "%"#{mohu}"%" &lt;/select> 3、批量删除 /** * 批量删除 * @param ids * @return */ int deleteMore(@Param("ids") String ids); &lt;!--int deleteMore(@Param("ids") String ids);--> &lt;delete id="deleteMore"> delete from t_user where id in (${ids}) &lt;/delete> 4、动态设置表名 /** * 动态设置表名，查询所有的用户信息 * @param tableName * @return */ List&lt;User> getAllUser(@Param("tableName") String tableName); &lt;!--List&lt;User> getAllUser(@Param("tableName") String tableName);--> &lt;select id="getAllUser" resultType="User"> select * from ${tableName} &lt;/select> 5、添加功能获取自增的主键 t_clazz(clazz_id,clazz_name)
t_student(student_id,student_name,clazz_id)
1、添加班级信息
2、获取新添加的班级的id
3、为班级分配学生，即将某学的班级id修改为新添加的班级的id
/** * 添加用户信息 * @param user * @return * useGeneratedKeys:设置使用自增的主键 * keyProperty:因为增删改有统一的返回值是受影响的行数，因此只能将获取的自增的主键放在传输的参 数user对象的某个属性中 */ int insertUser(User user); &lt;!--int insertUser(User user);--> &lt;insert id="insertUser" useGeneratedKeys="true" keyProperty="id"> insert into t_user values(null,#{username},#{password},#{age},#{sex}) &lt;/insert> 六、自定义映射resultMap 1、resultMap处理字段和属性的映射关系 1.1、方式一：
​ 自己直接写好对应的别名
1.2、方式二：
​ mybatis-config.xml配置文件中
​ 可以在MyBatis的核心配置文件中设置一个全局配置信息mapUnderscoreToCamelCase，可 以在查询表中数据时，自动将_类型的字段名转换为驼峰
&lt;settings> &lt;setting name="mapUnderscoreToCamelCase" value="true"/> &lt;/settings> 1.3、方式三：
​ 若字段名和实体类中的属性名不一致，则可以通过resultMap设置自定义映射
&lt;!-- resultMap:设置自定义映射 属性: id:表示自定义映射的唯一标识 type:查询的数据要映射的实体类的类型 子标签: id:设置主键的映射关系 result:设置普通字段的映射关系 association:设置多对一的映射关系 collection:设置一对多的映射关系 属性: property:设置映射关系中实体类中的属性名 column:设置映射关系中表中的字段名 --> &lt;resultMap id="userMap" type="User"> &lt;id property="id" column="id">&lt;/id> &lt;result property="userName" column="user_name">&lt;/result> &lt;result property="password" column="password">&lt;/result> &lt;result property="age" column="age">&lt;/result> &lt;result property="sex" column="sex">&lt;/result> &lt;/resultMap> &lt;!--List&lt;User> testMohu(@Param("mohu") String mohu);--> &lt;select id="testMohu" resultMap="userMap"> &lt;!--select * from t_user where username like '%${mohu}%'--> select id,user_name,password,age,sex from t_user where user_name like concat('%',#{mohu},'%') &lt;/select> 2、多对一映射处理 2.1、级联方式处理映射关系
&lt;resultMap id="empDeptMap" type="Emp"> &lt;id column="eid" property="eid">&lt;/id> &lt;result column="ename" property="ename">&lt;/result> &lt;result column="age" property="age">&lt;/result> &lt;result column="sex" property="sex">&lt;/result> &lt;result column="did" property="dept.did">&lt;/result> &lt;result column="dname" property="dept.dname">&lt;/result> &lt;/resultMap> &lt;!--Emp getEmpAndDeptByEid(@Param("eid") int eid);--> &lt;select id="getEmpAndDeptByEid" resultMap="empDeptMap"> select emp.*,dept.* from t_emp emp left join t_dept dept on emp.did = dept.did where emp.eid = #{eid} &lt;/select> 2.2、使用association处理映射关系
&lt;resultMap id="empDeptMap" type="Emp"> &lt;id column="eid" property="eid">&lt;/id> &lt;result column="ename" property="ename">&lt;/result> &lt;result column="age" property="age">&lt;/result> &lt;result column="sex" property="sex">&lt;/result> &lt;association property="dept" javaType="Dept"> &lt;id column="did" property="did">&lt;/id> &lt;result column="dname" property="dname">&lt;/result> &lt;/association> &lt;/resultMap> &lt;!--Emp getEmpAndDeptByEid(@Param("eid") int eid);--> &lt;select id="getEmpAndDeptByEid" resultMap="empDeptMap"> select emp.*,dept.* from t_emp emp left join t_dept dept on emp.did = dept.did where emp.eid = #{eid} &lt;/select> 2.3、使用分布查询多对一
1）先查询员工信息
2）查询部门信息
3）通过association将部门SQL的id配置到员工信息的resultMap中
/** * 通过分步查询查询员工信息 * @param eid * @return */ Emp getEmpByStep(@Param("eid") int eid); /** * 分步查询的第二步:根据员工所对应的did查询部门信息 * @param did * @return */ Dept getEmpDeptByStep(@Param("did") int did); &lt;resultMap id="empDeptStepMap" type="Emp"> &lt;id column="eid" property="eid">&lt;/id> &lt;result column="ename" property="ename">&lt;/result> &lt;result column="age" property="age">&lt;/result> &lt;result column="sex" property="sex">&lt;/result> &lt;!--select:设置分步查询，查询某个属性的值的sql的标识(namespace.sqlId) column:将sql以及查询结果中的某个字段设置为分步查询的条件 --> &lt;association property="dept" select="com.atguigu.MyBatis.mapper.DeptMapper.getEmpDeptByStep" column="did"> &lt;/association> &lt;/resultMap> &lt;!--Emp getEmpByStep(@Param("eid") int eid);--> &lt;select id="getEmpByStep" resultMap="empDeptStepMap"> select * from t_emp where eid = #{eid} &lt;/select> &lt;!--Dept getEmpDeptByStep(@Param("did") int did);--> &lt;select id="getEmpDeptByStep" resultType="Dept"> select * from t_dept where did = #{did} &lt;/select> 3、延迟加载 开启延迟加载后
1）如过获取Emp.getEmpName()就只会查询员工信息
2）如果获取Emp.getDeptName()就会进行第二个SQL，来查询部门信息
&lt;settings> &lt;setting name="mapUnderscoreToCamelCase" value="true"/> &lt;setting name="lazyloadingEnabled" value="true"/> &lt;/settings> 3）如果lazyloadingEnabled为true，在resultMap的association单独设置fetchType=&ldquo;eager&rdquo;，就可以避免懒加载
&lt;association property="dept" select="com.atguigu.MyBatis.mapper.DeptMapper.getEmpDeptByStep" column="did" fetchType="eager"> &lt;/association> 4、一对多映射处理 1、collection
/** * 根据部门id查新部门以及部门中的员工信息 * @param did * @return */ Dept getDeptEmpByDid(@Param("did") int did); &lt;resultMap id="deptEmpMap" type="Dept"> &lt;id property="did" column="did">&lt;/id> &lt;result property="dname" column="dname">&lt;/result> &lt;!-- ofType: 设置collection标签所处理的集合属性中存储数据的类型 collection: 处理一对多的映射关系 --> &lt;collection property="emps" ofType="Emp"> &lt;id property="eid" column="eid">&lt;/id> &lt;result property="ename" column="ename">&lt;/result> &lt;result property="age" column="age">&lt;/result> &lt;result property="sex" column="sex">&lt;/result> &lt;/collection> &lt;/resultMap> &lt;!--Dept getDeptEmpByDid(@Param("did") int did);--> &lt;select id="getDeptEmpByDid" resultMap="deptEmpMap"> select dept.*, emp.* from t_dept dept left join t_emp emp on dept.did = emp.did where dept.did = #{did} &lt;/select> 2、分步查询
/** * 分步查询部门和部门中的员工 * @param did * @return */ Dept getDeptByStep(@Param("did") int did); /** * 根据部门id查询员工信息 * @param did * @return */ List&lt;Emp> getEmpListByDid(@Param("did") int did); &lt;resultMap id="deptEmpStep" type="Dept"> &lt;id property="did" column="did">&lt;/id> &lt;result property="dname" column="dname">&lt;/result> &lt;collection property="emps" fetchType="eager" select="com.atguigu.MyBatis.mapper.EmpMapper.getEmpListByDid" column="did" fetchType="eager"> &lt;/collection> &lt;/resultMap> &lt;!--Dept getDeptByStep(@Param("did") int did);--> &lt;select id="getDeptByStep" resultMap="deptEmpStep"> select * from t_dept where did = #{did} &lt;/select> &lt;!--List&lt;Emp> getEmpListByDid(@Param("did") int did);--> &lt;select id="getEmpListByDid" resultType="Emp"> select * from t_emp where did = #{did} &lt;/select> 5、动态SQL Mybatis框架的动态SQL技术是一种根据特定条件动态拼装SQL语句的功能，它存在的意义是为了解决
拼接SQL语句字符串时的痛点问题。
5.1、if
if标签可通过test属性的表达式进行判断，若表达式的结果为true，则标签中的内容会执行;
反之标签中的内容不会执行
&lt;!--List&lt;Emp> getEmpListByMoreTJ(Emp emp);--> &lt;select id="getEmpListByMoreTJ" resultType="Emp"> select * from t_emp where 1=1 &lt;if test="ename != '' and ename != null"> and ename = #{ename} &lt;/if> &lt;if test="age != '' and age != null"> and age = #{age} &lt;/if> &lt;if test="sex != '' and sex != null"> and sex = #{sex} &lt;/if> &lt;/select> 5.2、where
where和if一般结合使用:
若where标签中的if条件都不满足，则where标签没有任何功能，即不会添加where关键字
若where标签中的if条件满足，则where标签会自动添加where关键字，并将条件最前方多余的 and去掉
注意:where标签不能去掉条件最后多余的and
&lt;select id="getEmpListByMoreTJ2" resultType="Emp"> select * from t_emp &lt;where> &lt;if test="ename != '' and ename != null"> ename = #{ename} &lt;/if> &lt;if test="age != '' and age != null"> and age = #{age} &lt;/if> &lt;if test="sex != '' and sex != null"> and sex = #{sex} &lt;/if> &lt;/where> &lt;/select> 5.3、trim
trim用于去掉或添加标签中的内容 常用属性:
prefix：在trim标签中的内容的前面添加某些内容
suffix：在trim标签中的内容的后面添加某些内容
prefixOverrides：在trim标签中的内容的前面去掉某些内容
suffixOverrides：在trim标签中的内容的后面去掉某些内容
&lt;select id="getEmpListByMoreTJ" resultType="Emp"> select * from t_emp &lt;trim prefix="where" suffixOverrides="and"> &lt;if test="ename != '' and ename != null"> ename = #{ename} and &lt;/if> &lt;if test="age != '' and age != null"> age = #{age} and &lt;/if> &lt;if test="sex != '' and sex != null"> sex = #{sex} &lt;/if> &lt;/trim> &lt;/select> 5.4、choose、when、otherwise
choose、when、otherwise相当于if&hellip;else if..else
&lt;!--List&lt;Emp> getEmpListByChoose(Emp emp);--> &lt;select id="getEmpListByChoose" resultType="Emp"> select &lt;include refid="empColumns">&lt;/include> from t_emp &lt;where> &lt;choose> &lt;when test="ename != '' and ename != null"> ename = #{ename} &lt;/when> &lt;when test="age != '' and age != null"> age = #{age} &lt;/when> &lt;when test="sex != '' and sex != null"> sex = #{sex} &lt;/when> &lt;when test="email != '' and email != null"> email = #{email} &lt;/when> &lt;/choose> &lt;/where> &lt;/select> 5.5、foreach
插入
&lt;!--int insertMoreEmp(List&lt;Emp> emps);--> &lt;insert id="insertMoreEmp"> insert into t_emp values &lt;foreach collection="emps" item="emp" separator=","> (null,#{emp.ename},#{emp.age},#{emp.sex},#{emp.email},null) &lt;/foreach> &lt;/insert> 删除
方式一： &lt;!--int deleteMoreByArray(int[] eids);--> &lt;delete id="deleteMoreByArray"> delete from t_emp where &lt;foreach collection="eids" item="eid" separator="or"> eid = #{eid} &lt;/foreach> &lt;/delete> 方式二： &lt;!--int deleteMoreByArray(int[] eids);--> &lt;delete id="deleteMoreByArray"> delete from t_emp where eid in &lt;foreach collection="eids" item="eid" separator="," open="(" close=")"> #{eid} &lt;/foreach> &lt;/delete> 5.6、SQL片段
sql片段，可以记录一段公共sql片段，在使用的地方通过include标签进行引入
记录 &lt;sql id="empColumns"> eid,ename,age,sex,did &lt;/sql> 引入 select &lt;include refid="empColumns">&lt;/include> from t_emp 七、MyBatis的缓存 1、MyBatis的一级缓存 一级缓存是SqlSession级别的，通过同一个SqlSession查询的数据会被缓存，下次查询相同的数据，就 会从缓存中直接获取，不会从数据库重新访问
使一级缓存失效的四种情况:
不同的SqlSession对应不同的一级缓存
同一个SqlSession但是查询条件不同
同一个SqlSession两次查询期间执行了任何一次增删改操作
同一个SqlSession两次查询期间手动清空了缓存
2、MyBatis的二级缓存 二级缓存是SqlSessionFactory级别，通过同一个SqlSessionFactory创建的SqlSession查询的结果会被
缓存;此后若再次执行相同的查询语句，结果就会从缓存中获取
二级缓存开启的条件:
在核心配置文件setting标签中，设置全局配置属性cacheEnabled=&ldquo;true&rdquo;，默认为true，不需要设置
在映射文件中设置标签3、二级缓存的相关配置 在mapper配置文件中添加的cache标签可以设置一些属性:
eviction属性:缓存回收策略
LRU(Least Recently Used) – 最近最少使用的:移除最长时间不被使用的对象。
FIFO(First in First out) – 先进先出:按对象进入缓存的顺序来移除它们。
SOFT – 软引用:移除基于垃圾回收器状态和软引用规则的对象。
WEAK – 弱引用:更积极地移除基于垃圾收集器状态和弱引用规则的对象。
默认的是 LRU。
flushInterval属性:刷新间隔，单位毫秒
默认情况是不设置，也就是没有刷新间隔，缓存仅仅调用语句时刷新 size属性:引用数目，正整数 代表缓存最多可以存储多少个对象，太大容易导致内存溢出 readOnly属性:只读，true/false
true：只读缓存;会给所有调用者返回缓存对象的相同实例。因此这些对象不能被修改。这提供了 很重要的性能优势。
false：读写缓存;会返回缓存对象的拷贝(通过序列化)。这会慢一些，但是安全，因此默认是 false。
4、MyBatis缓存查询的顺序 先查询二级缓存，因为二级缓存中可能会有其他程序已经查出来的数据，可以拿来直接使用。
如果二级缓存没有命中，再查询一级缓存
如果一级缓存也没有命中，则查询数据库
SqlSession关闭之后，一级缓存中的数据会写入二级缓存
5、整合第三方缓存EHCache 5.1、添加依赖
&lt;!-- Mybatis EHCache整合包 --> &lt;dependency> &lt;groupId>org.mybatis.caches&lt;/groupId> &lt;artifactId>mybatis-ehcache&lt;/artifactId> &lt;version>1.2.1&lt;/version> &lt;/dependency> &lt;!-- slf4j日志门面的一个具体实现 --> &lt;dependency> &lt;groupId>ch.qos.logback&lt;/groupId> &lt;artifactId>logback-classic&lt;/artifactId> &lt;version>1.2.3&lt;/version> &lt;/dependency> &lt;cache type="org.mybatis.caches.ehcache.EhcacheCache"/> 5.2、各jar包功能
jar包名称 作用 mybatis-ehcache Mybatis和EHCache的整合包 ehcache EHCache核心包 slf4j-api SLF4J日志门面包 logback-classic 支持SLF4J门面接口的一个具体实现 5.3、创建EHCache的配置文件ehcache.xml
&lt;?xml version="1.0" encoding="utf-8" ?> &lt;ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../config/ehcache.xsd"> &lt;!-- 磁盘保存路径 --> &lt;diskStore path="D:\atguigu\ehcache"/> &lt;defaultCache maxElementsInMemory="1000" 缓存中最大条目数量 maxElementsOnDisk="10000000" 硬盘中最大条目数量 eternal="false" overflowToDisk="true" timeToIdleSeconds="120" timeToLiveSeconds="120" diskExpiryThreadIntervalSeconds="120" memoryStoreEvictionPolicy="LRU"> &lt;/defaultCache> &lt;/ehcache> 5.4、EHCache配置文件说明
属性名 是否必须 作用 maxElementsInMemory 是 在内存中缓存的element的最大数目 maxElementsOnDisk 是 在磁盘上缓存的element的最大数目，若是0表示无 穷大 eternal 是 设定缓存的elements是否永远不过期。 如果为 true，则缓存的数据始终有效， 如果为false那么还 要根据timeToIdleSeconds、timeToLiveSeconds 判断 overflowToDisk 是 设定当内存缓存溢出的时候是否将过期的element 缓存到磁盘上 timeToIdleSeconds 否 当缓存在EhCache中的数据前后两次访问的时间超 过timeToIdleSeconds的属性取值时， 这些数据便 会删除，默认值是0,也就是可闲置时间无穷大 timeToLiveSeconds 否 缓存element的有效生命期，默认是0.,也就是 element存活时间无穷大 diskSpoolBufferSizeMB 否 DiskStore(磁盘缓存)的缓存区大小。默认是 30MB。每个Cache都应该有自己的一个缓冲区 diskPersistent 否 在VM重启的时候是否启用磁盘保存EhCache中的数 据，默认是false。 diskExpiryThreadIntervalSeconds 否 磁盘缓存的清理线程运行间隔，默认是120秒。每 个120s， 相应的线程会进行一次EhCache中数据的 清理工作 memoryStoreEvictionPolicy 否 当内存缓存达到最大，有新的element加入的时候，移除缓存中element的策略。 默认是LRU(最近最少使用)，可选的有LFU(最不常使用)和 FIFO(先进先出) 5.5、加入logback日志
八、逆向工程 用的比较多的是奢华尊享版
&lt;!-- 具体插件，逆向工程的操作是以构建过程中插件形式出现的 --> &lt;plugin> &lt;groupId>org.mybatis.generator&lt;/groupId> &lt;artifactId>mybatis-generator-maven-plugin&lt;/artifactId> &lt;version>1.3.0&lt;/version> &lt;!-- 插件的依赖 --> &lt;dependencies> &lt;dependency> &lt;groupId>org.mybatis.generator&lt;/groupId> &lt;artifactId>mybatis-generator-core&lt;/artifactId> &lt;version>1.3.2&lt;/version> &lt;/dependency> &lt;!-- 数据库连接池 --> &lt;dependency> &lt;groupId>com.mchange&lt;/groupId> &lt;artifactId>c3p0&lt;/artifactId> &lt;version>0.9.2&lt;/version> &lt;/dependency> &lt;!-- MySQL驱动 --> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>5.1.8&lt;/version> &lt;/dependency> &lt;/dependencies> &lt;/plugin> 九、分页插件 列表分页
导航分页
1、依赖 &lt;dependency> &lt;groupId>com.github.pagehelper&lt;/groupId> &lt;artifactId>pagehelper&lt;/artifactId> &lt;version>5.2.0&lt;/version> &lt;/dependency> 2、配置分页插件 在MyBatis的核心配置文件中配置插件
&lt;plugins> &lt;!--设置分页插件--> &lt;plugin interceptor="com.github.pagehelper.PageInterceptor">&lt;/plugin> &lt;/plugins> 3、分页插件的使用 1）在查询功能之前开启分页功能
PageHelper.startPage(int pageNum, int pageSize) 2）在查询获取list集合之后，使用PageInfo获取分页相关数据
//list:分页之后的数据 //navigatePages:导航分页的页码数 PageInfo&lt;T> pageInfo = new PageInfo&lt;>(List&lt;T> list, int navigatePages) 3）分页相关数据
PageInfo{ pageNum=8, pageSize=4, size=2, startRow=29, endRow=30, total=30, pages=8, list=Page{ count=true, pageNum=8, pageSize=4, startRow=28, endRow=32, total=30, pages=8, reasonable=false, pageSizeZero=false }, prePage=7, nextPage=0, isFirstPage=false, isLastPage=true, hasPreviousPage=true, hasNextPage=false, navigatePages=5, navigateFirstPage=4, navigateLastPage=8, navigatepageNums=[4, 5, 6, 7, 8] } 常用数据: pageNum:当前页的页码 pageSize:每页显示的条数 size:当前页显示的真实条数 total:总记录数 pages:总页数 prePage:上一页的页码 nextPage:下一页的页码</content></entry><entry><title>关于我的</title><url>https://zhang4014439175.github.io/about.html</url><categories/><tags/><content type="html"> 职业：后端攻城师 —— 一个90后程序员，终身学习者。
评价：对技术充满热情，充满学习的动力。—— 只要投入时间去学，没有学不会的东西。
技能：主职业是后端（Java、Python）、运维、大数据的技术栈也有所涉及。
业余：业余时间学习过设计的知识，如果逮住合适的机会，也会培养全方位的技能。
娱乐：爱阅读，但读不进文学名著；军事政治爱好者，跑步锻炼忠实粉丝；喜欢 MMORPG 游戏，但现阶段还是要以赚钱为主，等退休了再玩个痛快。
心态：爱生活、爱阅读、爱学习、爱拼搏、爱大自然。 原则：常怀感恩的心。
社交：一个人走得快，一群人走得远。
理财：人生就像滚雪球，重要的是，找到那条又湿又长的雪道。
一、心路历程： 小学时候喜欢玩电脑，刚开始没有电脑的时候喜欢往别人家跑，老妈为了把我拴住于是买了第一台电脑。家里一台电脑经受了我的好多锤炼，主机、宽带处理问题都是自己搞。
高中时候自学很多软件，但是没有专研下去。上大学前学习艺术，于是填志愿去了视觉传达设计（保底也能去打印店作业）。但是对计算机有浓厚的兴趣，因此利用课余时间自学 Java 技术栈。
大三实习期间走出校门，转型到了 IT 行业。在老家山西干了一年Java，开始主做前端。前端能及时给出视觉反馈的特点，成了我热衷这个岗位的最大原因。
有着去大厂的梦想，不过条条大路通罗马，大厂是一条路但不是唯一的路，因而充实好自己最重要，有机会就努力抓住机会，没有机会就自己创造机会。
我是一个普通的程序员，一个平凡的 90 后，但我不想让自己的人生平庸，奥力给！</content></entry></search>